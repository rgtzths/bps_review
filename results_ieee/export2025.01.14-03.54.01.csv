"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Toward AI-Enabled Green 6G Networks: A Resource Management Perspective","N. Alhussien; T. Aaron Gulliver","Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada; Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada",IEEE Access,"1 Oct 2024","2024","12","","132972","132995","The development of 6G wireless networks is driven by the pressing need for reliable connectivity in the increasingly intelligent Internet of Things (IoT) ecosystem. The goal of these networks is to seamlessly connect individuals, devices, vehicles, and resources such as the cloud. However, the heterogeneity and complexity of 6G due to the proliferation of devices, diverse applications, and the need for green and sustainable communication networks, pose significant Resource Management (RM) challenges. Furthermore, the stringent requirements of 6G networks for Quality-of-Service (QoS), scalability, intelligence, and security can make traditional RM approaches ineffective, particularly considering Energy Efficiency (EE). In response to these challenges, Artificial Intelligence (AI) has been considered to provide green RM. AI techniques can be used to efficiently manage network resources, balance energy demands, optimize EE, and integrate Energy Harvesting (EH). This paper examines 6G networks from an AI perspective to optimize resource allocation, minimize energy consumption, and maximize network performance. The focus is on RM within these networks considering Radio Resource Management (RRM), Computing and Caching Resource Management (CCRM), and Communication Network Resource Management (CNRM). The emphasis is on RM within the Cellular Network Infrastructure (CNI) and Machine Type Communications (MTC). AI models for efficient resource utilization to enhance EE and network performance are investigated. It is shown that AI plays a pivotal role in achieving green RM within 6G networks. Future research directions are outlined for intelligent networks to meet the growing demands and emerging challenges.","2169-3536","","10.1109/ACCESS.2024.3460656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679787","6G;artificial intelligence (AI);computing and caching resource management (CCRM);communication network resource management (CNRM);energy efficiency (EE);green communications;key performance indicators (KPIs);quality-of-service (QoS);radio access network (RAN);resource management (RM);radio resource management (RRM)","6G mobile communication;Artificial intelligence;Resource management;Quality of service;Real-time systems;Green products;Throughput;Cache storage;Communication systems;Energy efficiency;Radio access networks","","","","128","CCBYNCND","13 Sep 2024","","","IEEE","IEEE Journals"
"Emerging Technologies for 6G Non-Terrestrial-Networks: From Academia to Industrial Applications","C. T. Nguyen; Y. M. Saputra; N. V. Huynh; T. N. Nguyen; D. T. Hoang; D. N. Nguyen; V. -Q. Pham; M. Voznak; S. Chatzinotas; D. -H. Tran","Institute of Fundamental and Applied Sciences, Duy Tan University, Ho Chi Minh City, Vietnam; Internet Engineering Technology, Department of Electrical Engineering and Informatics, Vocational College, Universitas Gadjah Mada, Yogyakarta, Indonesia; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, U.K.; Communication and Signal Processing Research Group, Faculty of Electrical and Electronics Engineering, Ton Duc Thang University, Ho Chi Minh City, Vietnam; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, Australia; Nokia Bell Labs, Murray Hill, NJ, USA; Department of Telecommunications, Faculty of Electrical Engineering and Computer Science, VSB-Technical University of Ostrava, Ostrava, Czechia; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; Nokia, Boulogne-Billancourt, France",IEEE Open Journal of the Communications Society,"15 Jul 2024","2024","5","","3852","3885","Terrestrial networks form the fundamental infrastructure of modern communication systems, serving more than 4 billion users globally. However, terrestrial networks are facing a wide range of challenges, from coverage and reliability to interference and congestion. As the demands of the 6G era are expected to be much higher, it is crucial to address these challenges to ensure a robust and efficient communication infrastructure for the future. To address these problems, Non-terrestrial Network (NTN) has emerged to be a promising solution. NTNs are communication networks that leverage airborne (e.g., unmanned aerial vehicles) and spaceborne vehicles (e.g., satellites) to facilitate ultra-reliable communications and connectivity with high data rates and low latency over expansive regions. This article aims to provide a comprehensive survey on the utilization of network slicing, Artificial Intelligence/Machine Learning (AI/ML), and Open Radio Access Network (ORAN) to address diverse challenges of NTNs from the perspectives of both academia and industry. Particularly, we first provide an in-depth tutorial on NTN and the key enabling technologies including network slicing, AI/ML, and ORAN. Then, we provide a comprehensive survey on how network slicing and AI/ML have been leveraged to overcome the challenges that NTNs are facing. Moreover, we present how ORAN can be utilized for NTNs. Finally, we highlight important challenges, open issues, and future research directions of NTN in the 6G era.","2644-125X","","10.1109/OJCOMS.2024.3418574","European Union through the REFRESH Project - Research Excellence for Region Sustainability and High-Tech Industries of the European Just Transition Fund(grant numbers:CZ.10.03.01/00/22_003/0000048); Ministry of Education, Youth and Sports of the Czech Republic (MEYS CZ) through the Project SGS ID(grant numbers:SP 061/2024); VSB - Technical University of Ostrava; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570308","NTN;network slicing;AI/ML;ORAN;and 6G","Network slicing;Satellite broadcasting;Surveys;6G mobile communication;Autonomous aerial vehicles;Industries;Low latency communication","","5","","143","CCBYNCND","24 Jun 2024","","","IEEE","IEEE Journals"
"AI-Powered Optimization: Revolutionizing 6G Networks for Efficiency and Performance","K. Tamilarasi; S. Pavithra; R. Rangarajan; V. Venkataraman; K. S. P","SCOPE, Vellore Institute of Technology, Chennai, India; SCOPE, Vellore Institute of Technology, Chennai, India; SCOPE, Vellore Institute of Technology, Chennai, India; SCOPE, Vellore Institute of Technology, Chennai, India; SCOPE, Vellore Institute of Technology, Chennai, India",2024 Third International Conference on Smart Technologies and Systems for Next Generation Computing (ICSTSN),"13 Sep 2024","2024","","","1","6","This paper investigates the efficiency and performance gains that may be realized by integrating AI into 6G networks. In addition to covering power distribution, channel estimations, and security in 5G and 6G, it looks at the synergies between AI algorithms, machine learning models, and new communication technologies. The study covers AI-based channel estimation, DL models for cell-free networks, and deep reinforcement learning for beam training. It focusses on the shift from 5G to 6G, spotlighting innovations such as meta-surfaces and phased antenna arrays. All things considered, the study shows how important AI will be in building intelligent, flexible, and responsive mobile networks in the future.","","979-8-3503-9156-5","10.1109/ICSTSN61422.2024.10670928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670928","Artificial Intelligence;6G;Beamforming;Entropy;Dynamic resource allocation;antenna arrays","6G mobile communication;Phased arrays;Training;Technological innovation;5G mobile communication;Channel estimation;Power distribution","","","","16","IEEE","13 Sep 2024","","","IEEE","IEEE Conferences"
"Influence of AI and MAS in Enhancing Energy Efficiency of 6G Communications","D. Negi; F. Prakash; A. Gupta","Department of Computer Science and Engineering, Tula's Institute, Dehradun, India; Department of Computer Science and Information Technology, Jain (Deemed to be University), Bangalore, India; Department of Electronical and Electronics Engineering, Noida Institute of Engineering and Technology, Greater Noida, Uttar Pradesh, India","2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)","23 Jul 2024","2024","","","234","238","Next-generation Internet of Things (IoT) is progressing rapidly due to the introduction of beyond 5G (B5G) and the approaching arrival of 6G, which have improved the dependability, productivity, and profitability of both industrial and personal operations. Nevertheless, data overload is frequently caused by the abundance of wireless sensors in commercial 6G devices. Data mining gathers useful information in order to solve this. Meanwhile, in the 6G architecture, edge computing enables automated equipment operations and intelligent decision-making in real-time. Even so, despite the drawbacks of sensor-based energy sources, the integration of many technologies has led to an increase in energy. Using a multi-agent system (MAS) approach, a system model for industrial wireless sensor networks in 6G applications has been presented in order to combat this. Sensor node clustering locates and forecasts the locations of principal nodes by employing distributed artificial intelligence (DAI). Convolutional neural networks (CNN) and back-propagation neural networks (BPNN) are used in optimisation. Allocating resources to individual nodes efficiently is made possible by the analysis of inter-cluster correlations. The outcomes of the simulation show how well the approach works to reduce resource waste, increase overall energy efficiency, and protect important data. This strategy improves network performance in industrial 6G applications while simultaneously addressing concerns about energy consumption.","","979-8-3503-6684-6","10.1109/IC3SE62002.2024.10593501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10593501","Artificial Intelligence (AI);Machine Learning (ML);Sixth Generation (6G);Technology Transformations and Communication Ecosystem","6G mobile communication;Wireless communication;Productivity;Wireless sensor networks;Profitability;Energy efficiency;Real-time systems","","","","43","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"6G-enabled Situation-Aware ML-assisted UTM (6G-SAMU)","B. Zarai; L. Nasraoui; R. Boussada; S. Boudjit","COSIM Research Lab, Higher School of Communications (SUP’COM), University of Carthage, Tunisia; COSIM Research Lab, Higher School of Communications (SUP’COM), University of Carthage, Tunisia; National School of Computer Science (ENSI), University of Manouba, Tunisia; L2TI, Institut Galilée, University of Sorbonne Paris Nord, France",2024 International Wireless Communications and Mobile Computing (IWCMC),"17 Jul 2024","2024","","","1797","1802","In Unmanned Aerial System (UAS) Traffic Management (UTM) environment, small UASs generally fly at lower altitudes than large manned aircraft and their transmission power is very limited. They also fly shorter distances and more densely populated in the airspace than their manned counterparts. Therefore, a finer control and more frequent updates are necessary for their traffic control. To cope with the special requirements in UTM, we here explore and compare the potential of three machine learning models to help safe UAS operation, built on the 3GPP ecosystem model, through awareness about weather conditions. The proposed algorithm operates in two steps, wherein the first step it predicts the wind speed that it exploits during the second step to allow or stop a flight depending on the characteristics of the drone. The prediction process also covers two modes: i) premature 24 -hour prediction for an early decision, and ii) One-hour prediction for a refined final decision. Depending on the weather conditions (stable or frequently changing), the proposed algorithm can use either the premature or the hourly mode.","2376-6506","979-8-3503-6126-1","10.1109/IWCMC61514.2024.10592449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10592449","6G;situational awareness;UAS;UTM;Machine Learning;wind speed;UAV operation planning","6G mobile communication;Wireless communication;Time-frequency analysis;Wind speed;Biological system modeling;Atmospheric modeling;Traffic control","","","","32","IEEE","17 Jul 2024","","","IEEE","IEEE Conferences"
"A Multi-Level Deep RL-Based Network Slicing and Resource Management for O-RAN-Based 6G Cell-Free Networks","N. Ghafouri; J. S. Vardakas; K. Ramantas; C. Verikoukis","Iquadrat Informatica, Barcelona, Spain; Iquadrat Informatica S. L., Barcelona, Spain; Iquadrat Informatica, Barcelona, Spain; ISI/ATHINA, Greece, CEID, University of Patras, Patra, Greece",IEEE Transactions on Vehicular Technology,"7 Nov 2024","2024","73","11","17472","17484","With the deployment of the fifth generation (5G) of cellular networks, the focus of the information society has switched to the next era in which the limitations of 5G will be addressed, and the emerging services and applications will be satisfied. The sixth generation (6G) of wireless networks is envisioned to answer all demands of the next decade, which is only possible with advances in network design and management. This paper first presents a 6G-based network architecture that deploys emerging technologies, including Open-Radio Access Network (O-RAN) and Cell-Free massive Multiple-Input-Multiple-Output (CF mMIMO). Then, a hierarchical network slicing and resource management approach compatible with the presented architecture is defined. The proposed novel Reinforcement Learning (RL)-based scheme benefits from the openness of O-RAN to provide two levels of centralized multi-agent decision-making and decentralized single-agent execution for choosing proper service types by following the objective of maximizing the system capacity while guaranteeing the defined Quality of Service (QoS). To demonstrate the performance of the management method, Deep RL (DRL)-based algorithms for each level are proposed. Finally, the presented simulation results illustrate the effectiveness of the proposed solution in terms of peak data rate, user-experienced data rate, and latency.","1939-9359","","10.1109/TVT.2024.3415656","Research Program H2020 MARSAL(grant numbers:GA 101017171); H.F.R.I project ENABLE-6G(grant numbers:ID:16294); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10561624","6G networks;open ran;cell-free networks;network slicing;reinforcement learning","6G mobile communication;Network slicing;5G mobile communication;Resource management;Quality of service;Base stations;Monitoring","","1","","67","IEEE","18 Jun 2024","","","IEEE","IEEE Journals"
"Machine Learning-Based Resource Allocation Algorithms for 6G Networks","S. Anjum; D. Upadhyay; K. Singh; P. Upadhyay","Department of CSE, Noida Institute of Engineering and Technology; Computer Science and Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Department of CSE, Ajay Kumar Garg Engineering College, Ghaziabad, UP, India; Department of Computer Science and Engineering, School of Engineering and Technology, Sharda University, Gautam Budh Nagar, India",2024 2nd International Conference on Disruptive Technologies (ICDT),"11 Apr 2024","2024","","","1086","1091","Machine Learning-Based Resource Allocation Algorithms (MLRA) have emerged as a viable solution to the challenges posed by the next generation (6G) of network infrastructure. Compared to traditional algorithms, MLRA are more adaptive and provide a better utilization of available resources. The algorithms are able to determine the optimal parameters for resource allocation based on observed network behaviour. As 6G networks become increasingly used, MLRA will be crucial in ensuring that resources are efficiently and effectively allocated. The algorithms can identify when unutilized resources are available and quickly reallocate them to more successful users or applications. 6G networks are expected to provide gigabit speeds and up to 1000x bandwidth increase. This requires intelligent resource allocation algorithms which can quickly and accurately respond to changing user behaviour and demand. MLRA will be critical in enabling this shift and allowing users to benefit from the features and performance of 6G networks.","","979-8-3503-7105-5","10.1109/ICDT61202.2024.10489587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10489587","Deep Learning;Reinforcement Learning;Quantum Computing;Autonomic Computing;Artificial Intelligence","6G mobile communication;Energy consumption;Machine learning algorithms;Heuristic algorithms;Scalability;Machine learning;Dynamic scheduling","","4","","15","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Leveraging LLMs to eXplain DRL Decisions for Transparent 6G Network Slicing","M. Ameur; B. Brik; A. Ksentini","EURECOM, Sophia-Antipolis, France; Computer Science Department, College of Computing and Informatics, Sharjah University, Sharjah, UAE; EURECOM, Sophia-Antipolis, France",2024 IEEE 10th International Conference on Network Softwarization (NetSoft),"10 Jul 2024","2024","","","204","212","The emergence of 6G networks heralds a transformative era in network slicing, facilitating tailored service delivery and optimal resource utilization. Despite its promise, network slice optimization heavily relies on Deep Reinforcement Learning (DRL) models, often criticized for their black-box decision-making processes. This paper introduces a novel Composable eXplainable Reinforcement Learning (XRL) framework customized for distributed systems like 6G Network Slicing. The proposed framework leverages Large Language Models (LLMs) and Prompt Engineering techniques to elucidate DRL algorithms’ decision-making mechanisms, with a specific emphasis on user profiles. The latter transforms the inherently opaque nature of DRL into an interpretable textual format accessible not only to eXplainable AI (XAI) experts but also to diverse network slice provider stakeholders, engineers, leaders, and beyond. Experimental results underscore the efficacy of the proposed Composable XRL framework, showcasing substantial improvements in transparency and comprehensibility of DRL decisions within the context of 6G network slicing.","2693-9789","979-8-3503-6958-8","10.1109/NetSoft60951.2024.10588921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10588921","Explainable Reinforcement Learning;Composable XRL;LLMs;Admission Control;6G Network Slicing","6G mobile communication;Regulators;Network slicing;Decision making;Closed box;Transforms;Stakeholders","","","","16","IEEE","10 Jul 2024","","","IEEE","IEEE Conferences"
"Explainable and Robust Artificial Intelligence for Trustworthy Resource Management in 6G Networks","N. Khan; S. Coleri; A. Abdallah; A. Celik; A. M. Eltawil","Koc University, Turkey; Koc University, Turkey; King Abdullah University of Science and Technology, Saudi Arabia; King Abdullah University of Science and Technology, Saudi Arabia; King Abdullah University of Science and Technology, Saudi Arabia",IEEE Communications Magazine,"8 Apr 2024","2024","62","4","50","56","Artificial intelligence (AI) is expected to be an integral part of radio resource management (RRM) in sixth-generation (6G) networks. However, the opaque nature of complex deep learning (DL) models lacks explainability and robustness, posing a significant hindrance to adoption in practice. Furthermore, wireless communication experts and stakeholders, concerned about potential vulnerabilities, such as data privacy issues or biased decision-making, express reluctance to fully embrace these AI technologies. To this end, this article sheds light on the importance and means of achieving explainability and robustness toward trustworthy AI-based RRM solutions for 6G networks. We outline a range of explainable and robust AI techniques for feature visualization and attribution; model simplification and interpretability; model compression; and sensitivity analysis, then explain how they can be leveraged for RRM. Two case studies are presented to demonstrate the application of explainability and robustness in wireless network design. The former case focuses on exploiting explainable AI methods to simplify the model by reducing the input size of deep reinforcement learning agents for scalable RRM of vehicular networks. On the other hand, the latter case highlights the importance of providing interpretable explanations of credible and confident decisions of a DL-based beam alignment solution in massive multiple-input multiple-output systems. Analyses of these cases provide a generic explainability pipeline and a credibility assessment tool for checking model robustness that can be applied to any pre-trained DL-based RRM method. Overall, the proposed framework offers a promising avenue for improving the practicality and trustworthiness of AI-empowered RRM.","1558-1896","","10.1109/MCOM.001.2300172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10292755","","Robustness;Artificial intelligence;Data models;Analytical models;6G mobile communication;Complexity theory;Predictive models;Resource management;Explainable AI;Trusted computing","","10","","15","IEEE","23 Oct 2023","","","IEEE","IEEE Magazines"
"Deep Learning Based Advanced Estimation of Wireless Channels State Information for 6G Communication","A. Yogaraj; T. R. D. Kumar; A. Mohammed Ovaiz; K. Kamesh; V. Mohan Krishna; D. S. Aswin","Department of Electronics and Communication Engineering, Vel Tech High Tech Dr Rangarajan Dr Sakunthala Engineering College, Chennai; Department of Electronics and Communication Engineering, Vel Tech High Tech Dr Rangarajan Dr Sakunthala Engineering College, Chennai; Department of Electronics and Communication Engineering, Vel Tech High Tech Dr Rangarajan Dr Sakunthala Engineering College, Chennai; Department of Electronics and Communication Engineering, Vel Tech High Tech Dr Rangarajan Dr Sakunthala Engineering College, Chennai; Department of Electronics and Communication Engineering, Vel Tech High Tech Dr Rangarajan Dr Sakunthala Engineering College, Chennai; Department of Electronics and Communication Engineering, Vel Tech High Tech Dr Rangarajan Dr Sakunthala Engineering College, Chennai","2024 International Conference on Recent Advances in Electrical, Electronics, Ubiquitous Communication, and Computational Intelligence (RAEEUCCI)","12 Jun 2024","2024","","","1","6","The last few decades have seen an exponential increase in the demand for wireless connectivity. A channel estimator is a successful strategy for transferring data over wireless channels and is remarkably proficient. There will be an enormous rise in the pilot overhead for channel estimation because the dimension of the channels to be estimated is much greater than in traditional systems. It is the main issue created in channel estimation. Therefore, the deep learning-based advanced estimation of wireless channel state information for 6G communication is proposed in this research. A proposed Deep Learning (DL)-based channel estimation algorithm using the Deep Neural Network (DNN). Deep Learning (DL) is widely recognized for its capacity to offer an extensive selection of regulation strategies for various protocol levels and comprehensive assessment for intricate wireless networks containing large volumes of data. This paper aims to address important problems and potential fixes in Channel State Information (CSI) feedback and DL-based wireless channel estimation, covering the choice of DL model, acquisition of training data, and 6G neural network structure. The DL-based channel estimator is used to refine the estimated channel output, which is then used to enrich the total effectiveness and dependability of the communication system. The suggested method is appropriate for real-world communication scenarios because it not only provides increased channel estimation accuracy but also depicts specificity in response to shifting channel issues.","","979-8-3503-5453-9","10.1109/RAEEUCCI61380.2024.10547841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10547841","6G;AI (Artificial Intelligent);Deep Neural Network (DNN);DL (Deep Learning) Based Channel Estimator;CSI (Channel State Information)","Wireless communication;6G mobile communication;Deep learning;Transmitters;Wireless networks;Channel estimation;Estimation","","","","15","IEEE","12 Jun 2024","","","IEEE","IEEE Conferences"
"SliceOps: Explainable MLOps for Streamlined Automation-Native 6G Networks","F. Rezazadeh; H. Chergui; L. Alonso; C. Verikoukis","Telecommunications Technological Center of Catalonia, Spain; i2CAT Foundation, Spain; Technical University of Catalonia, Spain; University of Patras and ATHENA/ISI, Greece",IEEE Wireless Communications,"1 Oct 2024","2024","31","5","224","230","Sixth-generation (6G) network slicing is the backbone of future communications systems. It inaugurates the era of extreme ultra-reliable and low-latency communication (xURLLC), and pervades the digitalization of the various vertical immersive use cases. Since 6G inherently underpins artificial intelligence (AI), we propose a systematic and standalone slice termed SliceOps that is natively embedded in the 6G architecture, which gathers and manages the whole AI lifecycle through monitoring, re-training, and deploying the machine learning (ML) models as a service for the 6G slices. By leveraging machine learning operations (MLOps) in conjunction with eXplainable AI (XAI), SliceOps strives to cope with the opaqueness of black-box AI using explanation-guided reinforcement learning (XRL) to fulfill transparency, trustworthiness, and interpretability in the network slicing ecosystem. This article starts by elaborating on the architectural and algorithmic aspects of SliceOps. Then, the deployed cloud-native SliceOps working is exemplified via a latency-aware resource allocation problem. The deep RL (DRL)-based SliceOps agents within slices provide AI services aiming to allocate optimal radio resources and impede service quality degradation. Simulation results demonstrate the effectiveness of SliceOps-driven slicing. Afterward the article discusses the SliceOps challenges and limitations. Finally, the key open research directions corresponding to the proposed approach are identified.","1558-0687","","10.1109/MWC.007.2300144","MINECO(grant numbers:TSI-063000-2021-1 0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475843","","Artificial intelligence;Data models;6G mobile communication;Training;Network slicing;Monitoring;Load modeling","","6","","15","IEEE","19 Mar 2024","","","IEEE","IEEE Magazines"
"Revolutionizing Connectivity: Unveiling Next-Gen Efficiency with 6G's Ultra-Reliable Low Latency Communications Resource Allocation","S. N; J. L. G.R","Department of ECE, School of Engineering, VISTAS, Chennai, Tamil Nadu, India; Department of ECE, School of Engineering, VISTAS, Pallavaram, Chennai, Tamil Nadu, India",2024 First International Conference on Pioneering Developments in Computer Science & Digital Technologies (IC2SDT),"4 Oct 2024","2024","","","451","455","In the imminent era of 6G, this comprehensive review paper navigates the landscape of Efficient Resource Allocation in Ultra-Reliable Low Latency Communications (URLLC) with a particular focus on limitations and advancements in deep learning methodologies, specifically Deep-Q-Learning (DQL). As the demand for unprecedented connectivity experiences intensifies, the study addresses the challenges and opportunities associated with 6G URLLC, emphasizing the critical role of DQL in optimizing resource allocation. The paper critically evaluates the current state of DQL applications in URLLC, providing a nuanced understanding of its limitations in diverse scenarios. It explores the interplay between DQL and other resource allocation techniques, shedding light on synergies and potential areas for improvement. The limitations discussed include issues related to scalability, convergence, and adaptability to dynamic network conditions. Amidst the review of existing methodologies, the paper proposes potential enhancements to DQL, such as hybrid approaches integrating traditional optimization techniques, to overcome its limitations effectively. The study also highlights the importance of benchmarking and standardization in evaluating the performance of DQL-based resource allocation schemes, ensuring a fair comparison across different scenarios.","","979-8-3503-6501-6","10.1109/IC2SDT62152.2024.10696571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696571","Low Latency Communications;Efficient Resource Allocation;Deep Learning;Deep-Q-Learning","6G mobile communication;Deep learning;Reviews;Navigation;Scalability;Standardization;Ultra reliable low latency communication;Resource management;Optimization;Convergence","","","","10","IEEE","4 Oct 2024","","","IEEE","IEEE Conferences"
"FeDRL-D2D: Federated Deep Reinforcement Learning- Empowered Resource Allocation Scheme for Energy Efficiency Maximization in D2D-Assisted 6G Networks","H. Muhammad Fahad Noman; K. Dimyati; K. Ariffin Noordin; E. Hanafi; A. Abdrabou","Department of Electrical Engineering, Advanced Communication Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Electrical Engineering, Advanced Communication Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Electrical Engineering, Advanced Communication Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Electrical Engineering, Advanced Communication Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia; Electrical and Communication Engineering Department, College of Engineering, UAE University, Al Ain, United Arab Emirates",IEEE Access,"14 Aug 2024","2024","12","","109775","109792","Device-to-device (D2D)-assisted 6G networks are expected to support the proliferation of ubiquitous mobile applications by enhancing system capacity and overall energy efficiency towards a connected-sustainable world. However, the stringent quality of service (QoS) requirements for ultra-massive connectivity, limited network resources, and interference management are the significant challenges to deploying multiple device-to-device pairs (DDPs) without disrupting cellular users. Hence, intelligent resource management and power control are indispensable for alleviating interference among DDPs to optimize overall system performance and global energy efficiency. Considering this, we present a Federated DRL-based method for energy-efficient resource management in a D2D-assisted heterogeneous network (HetNet). We formulate a joint optimization problem of power control and channel allocation to maximize the system’s energy efficiency under QoS constraints for cellular user equipment (CUEs) and DDPs. The proposed scheme employs federated learning for a decentralized training paradigm to address user privacy, and a double-deep Q-network (DDQN) is used for intelligent resource management. The proposed DDQN method uses two separate Q-networks for action selection and target estimation to rationalize the transmit power and dynamic channel selection in which DDPs as agents could reuse the uplink channels of CUEs. Simulation results depict that the proposed method improves the overall system energy efficiency by 41.52% and achieves a better sum rate of 11.65%, 24.78%, and 47.29% than multi-agent actor-critic (MAAC), distributed deep-deterministic policy gradient (D3PG), and deep Q network (DQN) scheduling, respectively. Moreover, the proposed scheme achieves a 5.88%, 15.79%, and 27.27% reduction in cellular outage probability compared to MAAC, D3PG, and DQN scheduling, respectively, which makes it a robust solution for energy-efficient resource allocation in D2D-assisted 6G networks.","2169-3536","","10.1109/ACCESS.2024.3434619","Ministry of Higher Education Malaysia under the Fundamental Research Grant Scheme(grant numbers:FRGS/1/2020/TK0/UM/02/30); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10613769","6G;device-to-device communications;double deep Q-network (DDQN);energy efficiency;federated-deep reinforcement learning (F-DRL);resource allocation","Resource management;Energy efficiency;Optimization;Device-to-device communication;6G mobile communication;Throughput;Wireless networks","","","","55","CCBYNCND","29 Jul 2024","","","IEEE","IEEE Journals"
"Resource Optimization and Forecasting of Mobile Ad-hoc Network using Particle Swarm Optimization along with Ensemble ML Modeling in 6G","S. K. Dash; J. P; R. Dutta; A. Mukhopadhyay","Department of Computer Science, Amrita School of Computing Mysuru Campus, Amrita Vishwa Vidyapeetham, India; Department of Computer Science, Amrita School of Computing Mysuru Campus, Amrita Vishwa Vidyapeetham, India; Department of Computer Science, Amrita School of Computing Mysuru Campus, Amrita Vishwa Vidyapeetham, India; Department of Computer Science, Amrita School of Computing Mysuru Campus, Amrita Vishwa Vidyapeetham, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","10","In the evolution towards 6G networks, Mobile ad-hoc networks (MANETs) emerge as vital components, offering adaptability in dynamic environments. However, efficient resource management remains a challenge. This study delves into resource optimization and forecasting techniques within 6G MANETs, particularly focusing on bandwidth and congestion parameters. We utilize innovative machine learning models, including Artificial Neural Networks (ANN), Particle Swarm Optimization (PSO), and ensemble methods, to enhance resource utilization effectively. Moreover, we employ Recurrent Neural Networks (RNN) and Adaptive Neuro-Fuzzy Inference Systems (AN-FIS) to forecast temporal variations in network conditions. Leveraging historical network data, our models generate accurate and precise forecasts. By integrating optimization and forecasting techniques, this research contributes to enhancing network scalability and performance, thus directly aligning with the objectives of UN Sustainable Development Goal 9: Industry, Innovation, and Infrastructure.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10724085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724085","Resource Optimization;ANN;RNN;AN-FIS;PSO;Ensemble ML;6G","6G mobile communication;Recurrent neural networks;Artificial neural networks;Predictive models;Ad hoc networks;Resource management;Forecasting;Particle swarm optimization;Optimization;Mobile computing","","","","57","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Reinforcement Learning Based Resource Management for 6G-Enabled mIoT With Hypergraph Interference Model","J. Huang; C. Yang; S. Zhang; F. Yang; O. Alfarraj; V. Frascolla; S. Mumtaz; K. Yu","School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, China; School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, China; School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, China; School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, China; Computer Science Department, Community College, King Saud University, Riyadh, Saudi Arabia; Intel Deutschland GmbH, Neubiberg, Germany; Department of Applied Informatics, Silesian University of Technology, Gliwice, Poland; Computer Science Department, Community College, King Saud University, Riyadh, Saudi Arabia",IEEE Transactions on Communications,"18 Jul 2024","2024","72","7","4179","4192","For the future 6G-enabled massive Internet of Things (mIoT), how to effectively manage spectrum resources to support huge data traffic under the large-scale overlapping caused by the dense deployment of massive devices is the imperative challenge. In this paper, a novel hypergraph interference model is designed, and two reinforcement learning (RL)-based resource management algorithms in the 6G-enabled mIoT are proposed to enhance the network throughput and avoid overlapping interference. Then, based on the hypergraph interference model, the resource management problem of execution network throughput maximization is theoretically formulated under large-scale overlapping interference scenarios. To handle this problem, we convert it into a Markov decision process (MDP) model and then deal with this MDP model through the advantage actor-critic (A2C)-based resource management algorithm and asynchronous advantage actor-critic (A3C)-based resource management algorithm, which aim to maximize network throughput of the spectrum resource allocation among massive devices. The simulation results verify that the proposed algorithms can not only avoid large-scale overlapping interference but also improve the network throughput.","1558-0857","","10.1109/TCOMM.2024.3372892","Distinguished Scientist Fellowship Program (DSFP) at King Saud University, Riyadh, Saudi Arabia; National Natural Science Foundation of China(grant numbers:62301094); Chongqing Natural Science Foundation Innovation and Development Joint Fund(grant numbers:CSTB2023NSCQ-LMX0014); Science and Technology Research Program of Chongqing Education Commission of China(grant numbers:KJQN202201157,KJQN202301135); 6G-SENSES project from the Smart Networks and Services Joint Undertaking (SNS JU) under the European Union’s Horizon Europe research and innovation programme(grant numbers:101139282); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458122","Internet of Things (IoT);resource management;hypergraph;Markov decision process (MDP);reinforcement learning (RL)","Interference;Resource management;Internet of Things;6G mobile communication;Throughput;Optimization;Energy efficiency","","9","","37","IEEE","4 Mar 2024","","","IEEE","IEEE Journals"
"AI-Enabled Priority and Auction-Based Spectrum Management for 6G","M. Khadem; F. Zeinali; N. Mokari; H. Saeedi","Department of Electrical Engineering, Tarbiat Modares University, Tehran, Iran; Department of Electrical Engineering, Tarbiat Modares University, Tehran, Iran; Department of Electrical Engineering, Tarbiat Modares University, Tehran, Iran; College of Engineering and Technology, University of Doha for Science and Technology, Doha, Qatar",2024 IEEE Wireless Communications and Networking Conference (WCNC),"3 Jul 2024","2024","","","1","6","In this paper, we present a quality of service (QoS)-aware priority-based spectrum management scheme to guarantee the minimum required bit rate of vertical sector players (VSPs) in the 5G and beyond generation, including the 6th generation (6G). VSPs are considered as spectrum leasers to optimize the overall spectrum efficiency of the network from the perspective of the mobile network operator (MNO) as the spectrum licensee and auctioneer. We exploit a modified Vickrey-Clarke-Groves (VCG) auction mechanism to allocate the spectrum to them where the QoS and the truthfulness of bidders are considered as two important parameters for prioritization of VSPs. The simulation is done with the help of deep deterministic policy gradient (DDPG) as a deep reinforcement learning (DRL)-based algorithm. Simulation results demonstrate that deploying the DDPG algorithm results in significant advantages. In particular, the efficiency of the proposed spectrum management scheme is about %85 compared to the %35 efficiency in traditional auction methods.","1558-2612","979-8-3503-0358-2","10.1109/WCNC57260.2024.10570588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570588","Vertical sector player (VSP);Vickrey-Clarke-Groves(VCG);Quality of Service (QoS);Mobile network operator (MNO);Guaranteed bit rate (GBR);Deep reinforcement learning (DRL)","6G mobile communication;5G mobile communication;Simulation;Bit rate;Quality of service;Deep reinforcement learning;Complexity theory","","2","","14","IEEE","3 Jul 2024","","","IEEE","IEEE Conferences"
"AI-Assisted E2E Network Slicing for Integrated Sensing and Communication in 6G Networks","M. A. Hossain; A. Xiang; A. Kiani; T. Saboorian; J. Kaippallimalil; N. Ansari","Department of Electrical and Computer Engineering, Advanced Networking Laboratory, New Jersey Institute of Technology, Newark, NJ, USA; FutureWei Technologies, Inc., Plano, TX, USA; FutureWei Technologies, Inc., Plano, TX, USA; FutureWei Technologies, Inc., Plano, TX, USA; FutureWei Technologies, Inc., Plano, TX, USA; Department of Electrical and Computer Engineering, Advanced Networking Laboratory, New Jersey Institute of Technology, Newark, NJ, USA",IEEE Internet of Things Journal,"8 Mar 2024","2024","11","6","10627","10634","In the realm of modern wireless networks, the integration of wireless sensing and communication systems is pivotal, especially in the context of the forthcoming 6G Internet of Things (IoT) paradigm. The popularity of integrated sensing and communication (ISAC) stems from its potential to amplify the utilization of existing network infrastructures. This study introduces an innovative fusion of joint communication and sensing (JCAS), a framework of ISAC, combined with end-to-end (E2E) network slicing (NS) techniques. The aim is to meet user Quality-of-Service (QoS) expectations within the ambit of 6G IoT applications. The prime objective is to optimize resource allocation for communication and sensing services within a bespoke network slice tailored for 6G IoT scenarios. This is achieved by minimizing E2E system latency, essential for real-time decision making in 6G IoT environments. The optimization challenge is tackled by using deep reinforcement learning (DRL) in the form of a deep  $Q$  network (DQN) algorithm, which is adept at addressing nonlinear integer programming (NLIP) issues intrinsic to 6G IoT settings. Comprehensive simulations validate the approach, demonstrating its effectiveness in the context of 6G IoT networks. The amalgamation of ISAC with E2E NS emerges as a potent strategy for furnishing enhanced services customized for 6G IoT applications, successfully fulfilling consumers’ QoS requisites. This integrated approach holds substantial promise as a robust solution for addressing the exacting demands of forthcoming wireless networks, particularly those underpinned by the strides in 6G IoT technologies.","2327-4662","","10.1109/JIOT.2023.3326761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10290888","6G networks;AI;deep reinforcement learning (DRL);integrated sensing and communication (ISAC);Internet of Things (IoT) network;network slicing (NS);resource optimization","Sensors;6G mobile communication;Internet of Things;Resource management;Quality of service;Network slicing;Wireless networks","","4","","23","IEEE","23 Oct 2023","","","IEEE","IEEE Journals"
"Advanced Deep Learning Models for 6G: Overview, Opportunities, and Challenges","L. Jiao; Y. Shao; L. Sun; F. Liu; S. Yang; W. Ma; L. Li; X. Liu; B. Hou; X. Zhang; R. Shang; Y. Li; S. Wang; X. Tang; Y. Guo","Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China",IEEE Access,"1 Oct 2024","2024","12","","133245","133314","The advent of the sixth generation of mobile communications (6G) ushers in an era of heightened demand for advanced network intelligence to tackle the challenges of an expanding network landscape and increasing service demands. Deep Learning (DL), as a crucial technique for instilling intelligence into 6G, has demonstrated powerful and promising development. This paper provides a comprehensive overview of the pivotal role of DL in 6G, exploring the myriad opportunities and challenges that arise. Firstly, we present a detailed vision for DL in 6G, emphasizing areas such as adaptive resource allocation, intelligent network management, robust signal processing, ubiquitous edge intelligence, and endogenous security. Secondly, this paper reviews how DL models leverage their unique learning capabilities to solve complex service demands in 6G. The models discussed include Convolutional Neural Networks (CNN), Generative Adversarial Networks (GAN), Graph Neural Networks (GNN), Deep Reinforcement Learning (DRL), Transformer, Federated Learning (FL), and Meta Learning. Additionally, we examine the specific challenges each DL model faces within the 6G context. Moreover, we delve into the rapidly evolving field of Artificial Intelligence Generated Content (AIGC), examining its development and impact within the 6G framework. Finally, this paper culminates in a detailed discussion of ten critical open problems in integrating DL with 6G, setting the stage for future research and development in this field.","2169-3536","","10.1109/ACCESS.2024.3418900","Key Scientific Technological Innovation Research Project by Ministry of Education; National Natural Science Foundation of China(grant numbers:U22B2054); National Natural Science Foundation of China(grant numbers:62076192,61902298,61573267,61906150,62276199); Higher Education Discipline Innovation Project; Program for Cheung Kong Scholars and Innovative Research Team in University(grant numbers:IRT 15R53); ST Innovation Project from the Chinese Ministry of Education, the Key Research and Development Program in Shaanxi Province of China(grant numbers:2019ZDLGY03-06); China Postdoctoral Fund(grant numbers:2022T150506); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570412","Deep learning;6G;network intelligence;artificial intelligence generated content (AIGC);open problems","6G mobile communication;Resource management;Adaptation models;Artificial intelligence;Transformers;Deep learning;Intelligent networks;Content management","","1","","660","CCBYNCND","25 Jun 2024","","","IEEE","IEEE Journals"
"Joint optimization of UAV trajectory planning, video cache placement and transcoding in UAV-assisted 6G networks: a PPO-L based approach","X. Ren; X. Chen; L. Jiao; X. Dai; Z. Dong","School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China",2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"10 Jul 2024","2024","","","1310","1315","In the context of integrated aerial-terrestrial networks, the use of unmanned aerial vehicles (UAVs) as aerial base stations (ABS) to provide additional edge computing and communication capabilities to ground users (GDs) is envisioned as a promising solution. Meanwhile, with the rapid development of 6G networks, there has been an explosive growth in GD demand for videos. Edge caching has been proposed to reduce redundant video transmission in the network and minimize GD waiting latency. In this paper, we investigate a video adaptive caching solution in UAV-assisted aerial-ground networks. Our objective is to minimize GD waiting latency by jointly optimizing caching decisions for both UAVs and base stations (BSs), as well as the trajectories of the UAVs. Due to the complexity of the proposed problem, which is difficult to solve by traditional optimisation methods, and the highly dynamic nature of video requests, we propose a reinforcement learning algorithm based on proximal policy optimisation and a long short-term memory neural network (PPO-L) to solve the problem. We use a real-world YouTube video request dataset as our simulation experiment dataset. Through a large number of simulation experiments and performance comparisons with other algorithms, we demonstrate the superiority of the proposed algorithm. The simulation results demonstrate that the proposed algorithm significantly improves performance in system experiments compared to other algorithms.","2768-1904","979-8-3503-4918-4","10.1109/CSCWD61410.2024.10580096","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10580096","Trajectory planning;adaptive bitrate video caching;deep reinforcement learning;long short-term memory neural network","6G mobile communication;Base stations;Simulation;Heuristic algorithms;Neural networks;Reinforcement learning;Autonomous aerial vehicles","","","","14","IEEE","10 Jul 2024","","","IEEE","IEEE Conferences"
"How to Allocate Resources in Cloud-Native Networks Towards 6G","J. Wu; Y. Gao; L. Wang; J. Zhang; D. O. Wu","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong",IEEE Network,"9 May 2024","2024","38","2","240","246","The cloud-native computing is a promising solution for optimizing mobile networks, as it can improve the networks’ flexibility and scalability. However, it also brings new challenges to resource allocation, such as real-time performance and a smaller portion of the allocation. In this article, we develop a cloud-native network architecture which enables dynamic and flexible resource allocations. To address the challenges of real-time and fragmented allocation, we propose a resource allocation algorithm based on deep reinforcement learning towards a 6G wireless network. The proposed algorithm monitors the state of the whole network and trains the allocation policy, which can optimize the utility while meeting service level agreements of the network slices. We further validate the algorithm’s performance in the simulation environment and the experimental cloud-native network testbed. Furthermore, we highlight a suite of open research challenges in resource allocation in the cloud-native network towards 6G.","1558-156X","","10.1109/MNET002.2300017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10121544","","Cloud computing;Resource management;6G mobile communication;5G mobile communication;Wireless networks;Computer architecture;Reinforcement learning;Mobile computing","","6","","15","IEEE","8 May 2023","","","IEEE","IEEE Magazines"
"AI-Native Blockchain for Multi-Domain Resource Trading in 6G","G. Sun; H. N. Abishu; Y. H. Yacob; C. Huan; W. Jiang","University of Electronic Science and Technology of China, China; University of Electronic Science and Technology of China, China; University of Electronic Science and Technology of China, China; University of Electronic Science and Technology of China, China; Technische University, Germany",IEEE Communications Magazine,"2 Jul 2024","2024","62","7","44","51","Recently, resource trading has been regarded as a promising solution to deal with the resource scarcity of Internet-of-Things devices (IoTDs) to meet the performance requirements of sixth-generation (6G) networks. As 6G networks evolve to support diverse applications across multiple domains, trading of resources becomes essential to ensure efficient allocation and utilization of resources. However, ensuring transaction security and trust among traders and determining the best trading strategy for mobile virtual network operators (MVNOs) and IoTDs are challenging tasks. In this article, we first explore the resource trading literature and the types of resources IoTDs want to trade. Second, we investigate the trading strategies and pricing models for resource trading in 6G. Third, we present an artificial intelligence (AI)-native blockchain for multidomain resource trading (ABMRT) framework combining blockchain, AI approaches, and trading models that involve multiple MVNOs and IoTDs with varying service demands. The proposed framework is designed to support the diversified resource requirements of the IoTDs in a multidomain trading scenario. Finally, we discuss some challenges and future directions of resource trading in 6G networks.","1558-1896","","10.1109/MCOM.001.2300340","Natural Science Foundation of China(grant numbers:61806040,61771098); Department of Science and Technology of Sichuan Province(grant numbers:2020YFQ0025,DZKJ-DX2021020005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10582867","","6G mobile communication;Performance evaluation;Heuristic algorithms;Pricing;Blockchains;Security;Resource management;Artificial intelligence","","","","13","IEEE","2 Jul 2024","","","IEEE","IEEE Magazines"
"Split Federated Learning for 6G Enabled-Networks: Requirements, Challenges, and Future Directions","H. Hafi; B. Brik; P. A. Frangoudis; A. Ksentini; M. Bagaa","Faculty of New Information and Communication Technologies, Abdelhamid Mehri University, Constantine, Algeria; Computer Science Department, College of Computing and Informatics, Sharjah University, Sharjah, United Arab Emirates; Distributed Systems Group, TU Wien, Vienna, Austria; Communication Systems Department, EURECOM, Sophia-Antipolis, France; Department of Electrical and Computer Engineering, Université du Québec à Trois-Rivières, Trois-Rivières, Canada",IEEE Access,"22 Jan 2024","2024","12","","9890","9930","Sixth-generation (6G) networks anticipate intelligently supporting a wide range of smart services and innovative applications. Such a context urges a heavy usage of Machine Learning (ML) techniques, particularly Deep Learning (DL), to foster innovation and ease the deployment of intelligent network functions/operations, which are able to fulfill the various requirements of the envisioned 6G services. The revolution of 6G networks is driven by massive data availability, moving from centralized and big data towards small and distributed data. This trend has motivated the adoption of distributed and collaborative ML/DL techniques. Specifically, collaborative ML/DL consists of deploying a set of distributed agents that collaboratively train learning models without sharing their data, thus improving data privacy and reducing the time/communication overhead. This work provides a comprehensive study on how collaborative learning can be effectively deployed over 6G wireless networks. In particular, our study focuses on Split Federated Learning (SFL), a technique that recently emerged promising better performance compared with existing collaborative learning approaches. We first provide an overview of three emerging collaborative learning paradigms, including federated learning, split learning, and split federated learning, as well as of 6G networks along with their main vision and timeline of key developments. We then highlight the need for split federated learning towards the upcoming 6G networks in every aspect, including 6G technologies (e.g., intelligent physical layer, intelligent edge computing, zero-touch network management, intelligent resource management) and 6G use cases (e.g., smart grid 2.0, Industry 5.0, connected and autonomous systems). Furthermore, we review existing datasets along with frameworks that can help in implementing SFL for 6G networks. We finally identify key technical challenges, open issues, and future research directions related to SFL-enabled 6G networks.","2169-3536","","10.1109/ACCESS.2024.3351600","European Union’s Horizon 2020 Research and Innovation Program under the Agile and Cognitive Cloud edge Continuum management (AC3) Project(grant numbers:101093129); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10385040","6G networks;wireless communication;federated deep learning;split deep learning;split federated learning","6G mobile communication;Federated learning;Artificial intelligence;Surveys;Training;Wireless networks;Market research;Smart devices","","16","","240","CCBYNCND","9 Jan 2024","","","IEEE","IEEE Journals"
"Intelligible Protocol Learning for Resource Allocation in 6G O-RAN Slicing","F. Rezazadeh; H. Chergui; S. Siddiqui; J. Mangues; H. Song; W. Saad; M. Bennis","Telecommunications Technological Center of Catalonia, Spain; i2CAT Foundation, Spain; i2CAT Foundation, Spain; Telecommunications Technological Center of Catalonia, Spain; University of Maryland, Baltimore County, USA; Virginia Tech, USA; University of Oulu, Finland",IEEE Wireless Communications,"2 Oct 2024","2024","31","5","192","199","An adaptive standardized protocol is essential for addressing inter-slice resource contention and conflict in network slicing. Traditional protocol standardization is a cumbersome task that yields hardcoded predefined protocols, resulting in increased costs and delayed rollout. Going beyond these limitations, this article proposes a novel multi-agent deep reinforcement learning (MADRL) communication framework called standalone explainable protocol (STEP) for future sixth-generation (6G) open radio access network (O-RAN) slicing. As new conditions arise and affect network operation, resource orchestration agents adapt their communication messages to promote the emergence of a protocol on-the-fly, which enables the mitigation of conflict and resource contention between network slices. STEP weaves together the notion of information bottleneck (IB) theory with deep Q-network (DQN) learning concepts. By incorporating a stochastic bottleneck layer - inspired by variational autoencoders (VAEs) - STEP imposes an information-theoretic constraint for emergent inter-agent communication. This ensures that agents exchange concise and meaningful information, preventing resource waste and enhancing the overall system performance. The learned protocols enhance interpretability, laying a robust foundation for standardizing next-generation 6G networks. By considering an O-RAN compliant network slicing resource allocation problem, a conflict resolution protocol is developed. In particular, the results demonstrate that, on average, STEP reduces inter-slice conflicts by up to 6.06× compared to a predefined protocol method. Furthermore, in comparison with an MADRL baseline, STEP achieves 1.4× and 3.5× lower resource underutilization and latency, respectively.","1558-0687","","10.1109/MWC.015.2300552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10702574","","6G mobile communication;Protocols;Network slicing;System performance;Prevention and mitigation;Open RAN;Standardization;Resource management;Next generation networking;Information theory","","3","","15","IEEE","2 Oct 2024","","","IEEE","IEEE Magazines"
"Parallel Attention-Based Transformer for Channel Estimation in RIS-Aided 6G Wireless Communications","J. Guo; G. Liu; Q. Wu; P. Fan","Provincial Key Lab of Information Coding and Transmission, Southwest Jiaotong University, Chengdu, China; Provincial Key Lab of Information Coding and Transmission, Southwest Jiaotong University, Chengdu, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Provincial Key Lab of Information Coding and Transmission, Southwest Jiaotong University, Chengdu, China",IEEE Transactions on Vehicular Technology,"7 Nov 2024","2024","73","11","15927","15940","Accurate and fast channel estimation is one of the challenging problems in achieving practical reconfigurable intelligent surface (RIS)-aided wireless communication. However, a RIS-assisted communication system typically involves cascaded channels with intricate large-scale data distribution. Hence, practical implementation of the optimal minimum mean square error (MMSE) estimator may be infeasible due to its excessive complexity. In addition, most of the existing artificial intelligence (AI)-based channel estimation methods generally rely on convolutional neural networks, which only guarantee the estimation accuracy without considering the estimation time. To address these problems, an efficient parallel Transformer (EPformer) is proposed to achieve efficient channel estimation by jointly considering both estimation accuracy and estimation time. Firstly, the channel estimation problem is formulated as a parallel super-resolution (PSR) problem, given that the elements on the RIS are typically distributed in a two-dimensional manner. Then, the multi-head attention mechanism is employed to extract the deep channel features from the input data in parallel. To further enhance the estimation accuracy, the super-resolution block (SRB) is designed to denoise the noisy channel matrices. Finally, the encoder-to-decoder paradigm is developed to enhance the estimation performance. Extensive simulation results are provided to demonstrate the superiority of the proposed channel estimation scheme.","1939-9359","","10.1109/TVT.2024.3425433","National Natural Science Foundation of China(grant numbers:62271419,U2268201); National Natural Science Foundation of China(grant numbers:61971359,62361136810); Sichuan Science and Technology Program(grant numbers:2023ZHCG0010,2023YFH0012,2023YFG0312); NSFC Project(grant numbers:62371289,62331022,62020106001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10591410","6G;artificial intelligence;attention mechanism;channel estimation;reconfigurable intelligent surface (RIS)","Channel estimation;Estimation;Communication systems;Accuracy;Wireless communication;Transformers;Superresolution","","2","","41","IEEE","9 Jul 2024","","","IEEE","IEEE Journals"
"Deep Reciprocity Calibration for TDD mmWave Massive MIMO Systems Toward 6G","S. Xu; Z. Zhang; Y. Xu; C. Li; L. Yang","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; School of Information Science and Engineering, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China",IEEE Transactions on Wireless Communications,"10 Oct 2024","2024","23","10","13285","13299","Ideally, the bi-directional channel in time division duplex (TDD) millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems exhibits reciprocity. However, the involvement of low-cost and non-ideal radio frequency (RF) chains disrupts this reciprocity. Consequently, prior to fully leveraging the advantage of channel reciprocity, it is essential to implement channel calibration. Despite numerous over-the-air calibration methods, such as Argos, the typical least square (LS) are proposed in the literature, none of their criteria directly focus on the calibration performance. To address this gap, we propose a novel deep learning based approach that aims to optimize the calibration performance and introduce device-level intelligence toward 6G networks. To be specific, two cascaded modules are designed in a model-assisted end-to-end manner. Firstly, we propose the double-CNN-based channel denoising module for joint bi-directional channel estimation by exploiting the characteristics of mmWave channel. Secondly, the deep calibration learning module is meticulously designed to obtain the calibration coefficients with the aid of assisted model. This traceable assisted model is established by leveraging the expert knowledge of calibration process, based on which the MetrNet and the CaliNet are designed. Numerical results demonstrate the superior performance of our proposed method compared to existing calibration methods. Particularly, additional simulations and analysis are conducted to verify the effectiveness of the two properly designed modules.","1558-2248","","10.1109/TWC.2024.3400616","Natural Science Foundation on Frontier Leading Technology Basic Research Project of Jiangsu(grant numbers:BK20222001); National Natural Science Foundation of China(grant numbers:62171119,61971128,U1936201,62371119); Key Research and Development Plan of Jiangsu Province(grant numbers:BE2021013-3); Zhi Shan Young Scholar Program, Southeast University; Postgraduate Research and Practice Innovation Program of Jiangsu Province(grant numbers:KYCX23_0257); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10536041","TDD;channel reciprocity calibration;mmWave channel;deep neural network","Calibration;Channel estimation;Radio frequency;Bidirectional control;Millimeter wave communication;Signal to noise ratio;Antenna measurements","","2","","48","IEEE","21 May 2024","","","IEEE","IEEE Journals"
"Distributed Intelligence for Automated 6G Network Management Using Reinforcement Learning","S. Majumdar; S. Schwarzmann; R. Trivisonno; G. Carle","Munich Research Center, Huawei Technologies, Germany; Munich Research Center, Huawei Technologies, Germany; Munich Research Center, Huawei Technologies, Germany; Dept. of Informatics, Technical University of Munich, Germany",NOMS 2024-2024 IEEE Network Operations and Management Symposium,"2 Jul 2024","2024","","","1","4","The deployment of network elements in 6G is expected to be significantly more distributed than the existing 5G deployments. Distributed management paradigms are compatible with such distributed network deployments. Further, owing to their ability to solve complex problems by evaluating the impact of actions on the environment, intelligent solutions based on Reinforcement Learning (RL) for distributed management are promising. However, there are still several unsolved challenges before distributed intelligence could be seamlessly integrated in 6G. This work defines relevant research questions, reports on the progress made in the PhD project and presents the next steps and future directions for the advancement of this topic.","2374-9709","979-8-3503-2793-9","10.1109/NOMS59830.2024.10575318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10575318","6G;network management;distributed intelligence;network architecture;reinforcement learning","6G mobile communication;5G mobile communication;Reinforcement learning;Distributed management","","","","12","IEEE","2 Jul 2024","","","IEEE","IEEE Conferences"
"Empowering Traffic Steering in 6G Open RAN With Deep Reinforcement Learning","F. Kavehmadavani; V. -D. Nguyen; T. X. Vu; S. Chatzinotas","Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; College of Engineering and Computer Science and the Center for Environmental Intelligence, VinUniversity, Gia Lam, Hanoi, Vietnam; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Wireless Communications,"10 Oct 2024","2024","23","10","12782","12798","The sixth-generation (6G) wireless network landscape is evolving toward enhanced programmability, virtualization, and intelligence to support heterogeneous use cases. The O-RAN Alliance is pivotal in this transition, introducing a disaggregated architecture and open interfaces within the 6G network. Our paper explores an intelligent traffic steering (TS) scheme within the Open radio access network (RAN) architecture, aimed at improving overall system performance. Our novel TS algorithm efficiently manages diverse services, improving shared infrastructure performance amid unpredictable demand fluctuations. To address challenges like varying channel conditions, dynamic traffic demands, we propose a multi-layer optimization framework tailored to different timescales. Techniques such as long-short-term memory (LSTM), heuristics, and multi-agent deep reinforcement learning (MADRL) are employed within the non-real-time (non-RT) RAN intelligent controller (RIC). These techniques collaborate to make decisions on a larger timescale, defining custom control applications such as the intelligent TS-xAPP deployed at the near-real-time (near-RT) RIC. Meanwhile, optimization on a smaller timescale occurs at the RAN layer after receiving inferences/policies from RICs to address dynamic environments. The simulation results confirm the system’s effectiveness in intelligently steering traffic through a slice-aware scheme, improving eMBB throughput by an average of 99.42% over slice isolation.","1558-2248","","10.1109/TWC.2024.3396273","European Research Council (ERC) Actively Enhanced Cognition-based Framework for Design of Complex Systems (AGNOSTIC) project(grant numbers:H2020/ERC2020POC/957570/DREAM); Luxembourg National Research Fund, via project Risk-aware and Distributed Multiagent Reinforcement Learning for Resources and Control Management in Multilayer Ground-Air-Space Networks (RUTINE)(grant numbers:C22/IS/17220888); VinUniversity Seed Grant Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10528242","Deep reinforcement learning;open radio access network;traffic steering;network intelligence;traffic prediction;intelligent radio resource management","Ultra reliable low latency communication;Resource management;Throughput;Optimization;Quality of service;5G mobile communication;Long short term memory","","","","46","CCBY","9 May 2024","","","IEEE","IEEE Journals"
"Dynamic Neural Network-Based Resource Management for Mobile Edge Computing in 6G Networks","L. Ma; N. Cheng; C. Zhou; X. Wang; N. Lu; N. Zhang; K. Aldubaikhy; A. Alqasir","State Key Laboratory of ISN and the School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of ISN and the School of Telecommunications Engineering, Xidian University, Xi’an, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; State Key Laboratory of ISN and the School of Telecommunications Engineering, Xidian University, Xi’an, China; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical Engineering, Qassim University, Buraydah, Saudi Arabia; Department of Electrical Engineering, Qassim University, Buraydah, Saudi Arabia",IEEE Transactions on Cognitive Communications and Networking,"6 Jun 2024","2024","10","3","953","967","Mobile edge computing (MEC) can be used to reduce the task delay for users with limited computing resources. However, in 6G networks, the diversity of tasks is greatly increased. For those extremely delay-sensitive small-size computing tasks, the inference delay of neural network (NN)-based algorithms such as resource allocation and task offloading cannot be ignored. As a hyperparameter, the inference cost of NN is usually difficult to adjust. Dynamic neural network (DyNN) is an emerging technique that improves the model efficiency by adjusting the network architecture on-demand according to the sample characteristics during inference. In this paper, we propose a DyNN-based resource management method for MEC that dynamically adjusts the depth and width of the NN according to the features of the task, improving computational efficiency and achieving a balance between inference delay and the management performance of computational and communication resources. Furthermore, to reduce the training cost of DyNN, a new training method is proposed in this paper, where all the blocks in DyNN are gradually trained in the order of size. Simulation results demonstrate that the proposed DyNN-based resource management method outperforms the traditional optimization algorithm and the static-NN-based method.","2332-7731","","10.1109/TCCN.2023.3346824","National Key Research and Development Program of China(grant numbers:2020YFB1807700); National Natural Science Foundation of China (NSFC)(grant numbers:62071356); Fundamental Research Funds for the Central Universities, and the Innovation Fund of Xidian University(grant numbers:YJSJ23012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10373580","Mobile edge computing;inference delay;dynamic neural network;training cost","Delays;Task analysis;Artificial neural networks;Resource management;Training;Inference algorithms;Heuristic algorithms","","3","","33","IEEE","25 Dec 2023","","","IEEE","IEEE Journals"
"Intelligent Hierarchical NOMA-Based Network Slicing in Cell-Free RAN for 6G Systems","F. Ye; J. Li; P. Zhu; D. Wang; X. You","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China",IEEE Transactions on Wireless Communications,"9 May 2024","2024","23","5","4724","4737","In order to cope with the demand of explosively increasing service diversity and quality, network slicing has become the key technology of next-generation mobile communication. Mobile edge computing (MEC) can provide multi-dimensional resources and network functions at the edge of the network and reduce the delay of wireless networks. At the same time, non-orthogonal multiple access (NOMA) allows traffic to share resources and improve the spectral efficiency and energy efficiency of wireless networks. In this paper, we propose a hierarchical NOMA-based network slicing architecture in the 6G novel full-spectrum scalable cell-free radio access network with MECs and conduct joint allocation of communication, computing and caching resources at different resource granularity to meet the requirements of latency-critical applications with different latency. In order to realize the hierarchical joint resource allocation to improve system efficiency, we propose to address the optimal computing resource allocation and cache placement problem firstly through conventional optimization methods to reduce the action space and then use the multi-agent deep reinforcement learning algorithm for solving other complex coupling strategies. Simulation results further verify the effectiveness of the proposed intelligent network slicing scheme.","1558-2248","","10.1109/TWC.2023.3321717","National Key Research and Development Program of China(grant numbers:2020YFB1806600); National Natural Science Foundation of China (NSFC)(grant numbers:61971127); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10278091","Network slicing;NOMA;MEC;cell-free radio access network;deep reinforcement learning","Resource management;Network slicing;NOMA;Computer architecture;Computational modeling;Task analysis;Quality of service","","3","","44","IEEE","10 Oct 2023","","","IEEE","IEEE Journals"
"Optimization Techniques for Reconfigurable Intelligent Surfaces in 6G","M. Dheshmuk; S. B. Kumbalavati","Dept. of Electronics and Communication, Basaveshwar Engineering College, Bagalkote; Dept. of Electronics and Communication Engineering, Basaveshwar Engineering College, Bagalkote Affiliated to Visvesvaraya Technological University, Belagavi",2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC),"2 Oct 2024","2024","","","772","776","The new age digital services and applications, deeper penetration of smartphones, billions of devices getting associated to internet has increased the hunger for high-speed data. This demand will keep exploding, rise exponentially as the days progresses ahead. In order to satisfy the soaring data traffic demands, communication has evolved all the way from 1G to 5G i.e. from first generation to fifth generation. After a span of few years, there will be a migration to sixth generation (6G). Several innovative techniques are expected to be part of 6G, though the specifications are not yet laid out. In this paper, several research areas of 6G are discussed like artificial intelligence, Reconfigurable Intelligent Surfaces (RIS), Quantum communication, channel estimation. Reconfigurable intelligent surfaces have a very prominent role to play in 6G. A survey of most recent works found in literature is done and the challenges involved in deploying RIS, future research outlook in RIS has been discussed.","2996-5357","979-8-3503-7994-5","10.1109/ICESC60852.2024.10690066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690066","Reconfigurable Intelligent Surfaces (RIS);Sixth Generation (6G);Artificial Intelligence;Wireless Information and Energy Transfer (WIET);Non-Orthogonal multiple access (NOMA);Joint Communication and Sensing (JCAS)","6G mobile communication;Surveys;Energy exchange;Channel estimation;Reconfigurable intelligent surfaces;Sensors;Artificial intelligence;Smart phones;Optimization;Quantum communication","","","","34","IEEE","2 Oct 2024","","","IEEE","IEEE Conferences"
"Explainable AI for 6G Use Cases: Technical Aspects and Research Challenges","S. Wang; M. A. Qureshi; L. Miralles-Pechuán; T. Huynh-The; T. R. Gadekallu; M. Liyanage","School of Computer Science, University College Dublin, Dublin 4, Ireland; ADAPT Centre, Explainable Analytics Group, Faculty of Business, Technological University Dublin, Dublin 2, Ireland; School of Computing, Technological University Dublin, Dublin 7, Ireland; Department of Computer and Communications Engineering, Ho Chi Minh City University of Technology and Education, Ho Chi Minh City, Vietnam; Division of Research and Development, Lovely Professional University, Phagwara, India; School of Computer Science, University College Dublin, Dublin 4, Ireland",IEEE Open Journal of the Communications Society,"1 May 2024","2024","5","","2490","2540","Around 2020, 5G began its commercialization journey, and discussions about the next-generation networks (such as 6G) emerged. Researchers predict that 6G networks will have higher bandwidth, coverage, reliability, energy efficiency, and lower latency, and will be an integrated “human-centric” network system powered by artificial intelligence (AI). This 6G network will lead to many real-time automated decisions, ranging from network resource allocation to collision avoidance for self-driving cars. However, there is a risk of losing control over decision-making due to the high-speed, data-intensive AI decision-making that may go beyond designers’ and users’ comprehension. To mitigate this risk, explainable AI (XAI) methods can be used to enhance the transparency of the black-box AI decision-making process. This paper surveys the application of XAI towards the upcoming 6G age, including 6G technologies (such as intelligent radio and zero-touch network management) and 6G use cases (such as industry 5.0). Additionally, the paper summarizes the lessons learned from recent attempts and outlines important research challenges in applying XAI for 6G use cases soon.","2644-125X","","10.1109/OJCOMS.2024.3386872","European Commission in SPATIAL(grant numbers:101021808); Academy of Finland in 6Genesis(grant numbers:318927); Science Foundation Ireland through CONNECT Phase 2 Project(grant numbers:13/RC/2077_P2); ADAPT Centre Phase 2 Project(grant numbers:13/RC/2106_P2); Industry Fellowship(grant numbers:21/IRDIF/9839); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10499970","B5G;6G;AI;XAI;explainability","6G mobile communication;Artificial intelligence;5G mobile communication;Explainable AI;Resource management;Security;Closed box","","15","","303","CCBYNCND","16 Apr 2024","","","IEEE","IEEE Journals"
"Big Data Analytics Model Using Artificial Intelligence (AI) and 6G Technologies for Healthcare","I. Ahmad Khan; A. Salam; F. Ullah; F. Amin; S. Tabrez; S. Faisal; G. Sang Choi","Department of Computer Science, Bacha Khan University, Charsadda, Pakistan; Department of Computer Science, Abdul Wali Khan University, Mardan, Pakistan; Department of Computer Science, Bacha Khan University, Charsadda, Pakistan; School of Computer Science and Engineering, Yeungnam University, Gyeongsan, Republic of Korea; Department of Computer Science, Bacha Khan University, Charsadda, Pakistan; Department of Computer Science, Abdul Wali Khan University, Mardan, Pakistan; School of Computer Science and Engineering, Yeungnam University, Gyeongsan, Republic of Korea",IEEE Access,"19 Jul 2024","2024","12","","97924","97937","Artificial Intelligence (AI) and 6G technologies promise to revolutionize the healthcare domain by enhancing the accuracy and diagnosis the patient monitoring in a real-time environment. The integration of AI and 6G technologies holds substantial promise for transforming healthcare systems. AI’s capabilities in complex data analysis, combined with the high speed and reliable 6G networks significantly improve the healthcare domain. However, the integration and application aspects of both technologies are still evolving. Thus, to fill this gap. Herein, we propose an advanced big data analytics model. Our proposed model has several phases, for instance, data collection, data selection and preprocessing, and analytical phase. Each phase has different functions applied to the preprocessed data and finally, the results are shown to the user. We have carried out several experiments and the network performance and efficiency are measured in terms of latency throughput and reliability (in terms of error rate). The achieved experimental result validate that the proposed model processed a large amount of data in a very short time. The reliability of the proposed model is better than earlier models and the execution time is efficient and also applicable in healthcare.","2169-3536","","10.1109/ACCESS.2024.3427333","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:NRF-2021R1A6A1A03039493); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10596294","Big data;artificial intelligence;6G technology;telemedicine","Artificial intelligence;Medical services;6G mobile communication;Data models;Analytical models;Big Data;Real-time systems;Telemedicine;Medical services","","1","","28","CCBYNCND","12 Jul 2024","","","IEEE","IEEE Journals"
"Quality of AI Service Assurance in 6G Native Artificial Intelligence Networks","Q. Wang; M. Hua; T. Chen; G. Liu; J. Deng; N. Li","China Mobile Research Institute, Beijing, China; China Mobile Research Institute, Beijing, China; ZGC Institute of Ubiquitous-X Innovation and Applications, Beijing, China; ZGC Institute of Ubiquitous-X Innovation and Applications, Beijing, China; ZGC Institute of Ubiquitous-X Innovation and Applications, Beijing, China; ZGC Institute of Ubiquitous-X Innovation and Applications, Beijing, China","2024 IEEE International Conference on Sensing, Diagnostics, Prognostics, and Control (SDPC)","15 Oct 2024","2024","","","70","75","In 6G, the proliferation of artificial intelligence (AI) applications requires networks to provide ubiquitous AI services, as well as communication, computation, connection and data resources. Network slicing enables network to be divided into logically isolated slices that share underlying resources and are customized to meet the different quality of AI service (QoAIS) requirements of a large number of users. State-of-the-art proposals have not taken into account the match between user QoAIS requirements and actual network capabilities. Besides, due to the time-varying states and huge operating spaces, users may suffer from violations of service level agreements. This paper first introduces a novel QoAIS mapping method, and then optimizes resource allocation and AI services orchestration for network slicing to guarantee QoAIS requirements. Finally, taking advantages of both the Markov decision process (MDP) and deep deterministic policy gradient (DDPG), a MDP-based DDPG algorithm is designed. Simulation results reveal that the proposed algorithm can effectively reduce latency and energy consumption compared with benchmarks.","","979-8-3503-8885-5","10.1109/SDPC62810.2024.10707758","National Key R&D Program of China(grant numbers:2022YFB29021 00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707758","6G;native AI;federated learning;transfer learning;quality of AI service","6G mobile communication;Energy consumption;Network slicing;Simulation;Markov decision processes;Sensors;Resource management;Proposals;Artificial intelligence;Service level agreements","","","","10","IEEE","15 Oct 2024","","","IEEE","IEEE Conferences"
"Beyond Complexity Limits: Machine Learning for Sidelink-Assisted mmWave Multicasting in 6G","N. Chukhno; O. Chukhno; S. Pizzi; A. Molinaro; A. Iera; G. Araniti","Tampere University, Tampere, Finland; DIIES Department, University Mediterranea of Reggio Calabria, Reggio Calabria, Italy; DIIES Department, University Mediterranea of Reggio Calabria, Reggio Calabria, Italy; DIIES Department, University Mediterranea of Reggio Calabria, Reggio Calabria, Italy; CNIT, Parma, Italy; DIIES Department, University Mediterranea of Reggio Calabria, Reggio Calabria, Italy",IEEE Transactions on Broadcasting,"16 Sep 2024","2024","70","3","1076","1090","The latest technological developments have fueled revolutionary changes and improvements in wireless communication systems. Among them, mmWave spectrum exploitation stands out for its ability to deliver ultra-high data rates. However, its full adoption beyond fifth generation multicast systems (5G+/6G) remains hampered, mainly due to mobility robustness issues. In this work, we propose a solution to address the problem of efficient sidelink-assisted multicasting in mobile multimode systems, specifically by considering the possibility of jointly utilizing sidelink/device-to-device (D2D), unicast, and multicast transmissions to improve service delivery. To overcome the complexity problem in finding the optimal solution for user-mode binding, we introduce a pre-optimization step called multicast group formation (MGF). Through a clustering technique based on unsupervised machine learning, MGF allows to reduce the complexity of solving the sidelink-assisted multiple modes mmWave (SA3M) problem. A detailed analysis of the impact of various system parameters on performance is conducted, and numerical evidence of the complexity/performance trade-off and its dependence on mobility patterns and user distribution is provided. Particularly, our proposed solution achieves a network throughput improvement of up to 32% over state-of-the-art schemes while ensuring the lowest computational time. Finally, the results demonstrate that an effective balance between power consumption and latency can be achieved through appropriate adjustments of transmit power and bandwidth.","1557-9611","","10.1109/TBC.2024.3382959","European Union’s Horizon 2020 Research and Innovation Programme under the Marie Skłodowska Curie Grant Agreement (A-WEAR: A network for dynamic wearable applications with privacy constraints)(grant numbers:813278); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10513425","6G;millimeter wave;multicast;unicast;sidelink;radio resource management;mobility;machine learning","Millimeter wave communication;Device-to-device communication;Multicast communication;Complexity theory;Unicast;Machine learning;Optimal scheduling","","1","","43","CCBYNCND","30 Apr 2024","","","IEEE","IEEE Journals"
"Digital-Twin-Driven End-to-End Network Slicing Toward 6G","M. Yaqoob; R. Trestian; M. Tatipamula; H. X. Nguyen","Middlesex University, London, U.K.; Middlesex University, London, U.K.; Ericsson Group Function Technologies and Architectures, Santa Clara, CA, USA; Middlesex University, London, U.K.",IEEE Internet Computing,"24 Apr 2024","2024","28","2","47","55","The diverse use-case requirements and strict expectations of latency on shared infrastructure, from future networks, calls for networking paradigms that can provide efficiency and flexibility. Network slicing is a network paradigm introduced with 5G, which is a key in realizing diverse service requirements and meeting expectations of future 6G networks. A network digital twin (NDT) model can benefit the management and orchestration of a network slicing lifecycle and provide a clear visual representation of the physical entities of a network slicing model while enabling experimentation with different resource allocation schemes without actually affecting the physical network. An NDT bridges the gap between the physical world and the digital world by having constant bidirectional communication. Hence, in this article, we make a case for NDTs as a key enabler of network slicing in 6G networks while integrating an artificial intelligence-based network slicing strategy to enable end-to-end quality-of-service provisioning.","1941-0131","","10.1109/MIC.2023.3332252","Engineering and Physical Sciences Research Council U.K.–India Future Networks Initiative(grant numbers:EP/W016524/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316185","","6G mobile communication;Artificial intelligence;Network slicing;Digital twins;Computer architecture;Virtualization;Telecommunication traffic;User centered design;Network slicing","","4","","15","IEEE","13 Nov 2023","","","IEEE","IEEE Magazines"
"An Automated Machine Learning Approach for 6G Radio Resource Allocation","R. Tirkey; P. Bhambu; B. N. Krishna Reddy","Department of Pharmacy, ARKA JAIN University, Jamshedpur, Jharkhand, India; Department of Computer Science and Engineering, Vivekananda Global University, Jaipur, India; Department of Management, School of Mangement - UG, JAIN (Deemed to be University), Bangalore, Karnataka, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","6","this technical abstract examines an automated system gaining knowledge of the method for 6 G radio aid allocation. In 6G networks, the need for efficient, useful resource efficiency can be elevated due to the anticipated better statistics prices enabled by using the usage of mm Wave frequencies. To address this project, the authors suggest an automated device gaining knowledge of methods that could optimize radio aid allocation while also supplying flexibility in phrases of generation, architecture, and network parameters. The proposed approach is based totally on the simultaneous optimization of deep reinforcement mastering and conventional optimization algorithms. The middle idea is to leverage the benefits of each process to locate the greatest radio aid allocation scheme for exclusive deployment scenarios. The authors also examine the performance advantages of their technique in a simulated 6 G community in the evaluation of existing techniques. The outcomes display that the proposed technique is capable of improving system throughput and providing latency profits by way of as much as 5% and eight% respectively. For this reason, this automated machine learning technique may be a promising answer for radio useful resource allocation in 6G networks.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10725181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10725181","Statistics;Frequencies;Parameters;Algorithms;Reinforcement;Optimization;Architecture","6G mobile communication;Knowledge engineering;Computer architecture;Throughput;Resource management;Optimization","","","","12","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Optimization Design in RIS-Assisted Integrated Satellite-UAV-Served 6G IoT: A Deep Reinforcement Learning Approach","M. Wu; K. Guo; X. Li; A. Nauman; K. An; J. Wang","Space Engineering University, China; Space Engineering University, China; Henan Polytechnic University, China; Yeungnam University, South Korea; National University of Defense Technology, China; Central China Normal University, China",IEEE Internet of Things Magazine,"11 Jan 2024","2024","7","1","12","18","Satellite networks have been emerged as a critical part of the next-generation wireless networks. However, the high transmission latency, highly dynamic channel conditions and energy resource constraints of Internet of Things (IoT) devices pose a challenge to performance improvements. To tackle above issues, technologies such as integrated satellite-unmanned aerial vehicle-terrestrial networks (IS-UAV-TNs), deep reinforcement learning (DRL), reconfigurable intelligent surface (RIS) are highly anticipated in 6G IoT. In this article, we consider the application of RIS to IS-UAV-TNs to reshape wireless channels by controlling the phase shift of the scattering elements. The dynamic configuration of the RIS reflection unit poses a high-dimensional problem, making beamforming optimization challenging. We focus on discussing the optimization method of integrating DRL in RIS-assisted IS-UAV-TNs, which offers flexibility in scenarios where precise channel state information (CSI) is unknown. To illustrate the advantage of the DRL framework in RIS-assisted IS-UAV-TNs, we design a representative communication scenario, where the results are provided according to the considered scenario. Finally, potential future research directions and challenges are presented.","2576-3199","","10.1109/IOTM.001.2300111","National Science Foundation of China(grant numbers:62001517,62101205); Natural Science Foundation of Hubei Province(grant numbers:2021CFB248); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10397572","","Deep learning;6G mobile communication;Satellites;Array signal processing;Wireless networks;Scattering;Reinforcement learning","","8","","15","IEEE","11 Jan 2024","","","IEEE","IEEE Magazines"
"Semantic Communication: Implication for Resource Optimization in 6G Networks","S. Sharif; F. Khandaker; W. Ejaz","Dept. of Electrical Engineering, Lakehead University, Barrie, ON, Canada; Dept. of Comp. Science & Technology, Algoma University, Brampton, ON, Canada; Dept. of Electrical Engineering, Lakehead University, Barrie, ON, Canada",2024 IEEE International Conference on Advanced Telecommunication and Networking Technologies (ATNT),"23 Oct 2024","2024","1","","1","4","This paper explores the evolution of communication systems, highlighting the transition from traditional methods to digital forms with the introduction of Semantic Communication (SemCom). We examine SemCom's role in enhancing efficiency in 6G networks by optimizing resource usage. We present a case study as a practical implication of SemCom in traffic management, specifically its use in prioritizing emergency vehicles in smart traffic systems. Additionally, we identify key areas for future research, including inference approaches, resource optimization, AI integration, and data security within SemCom. Our analysis underscores the potential of SemCom to revolutionize communication systems and its critical role in developing next-generation networks.","","979-8-3503-5350-1","10.1109/ATNT61688.2024.10719121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10719121","Internet of Things (IoT);resource optimization;semantic communication;traditional communication;6G network","6G mobile communication;Data security;Real-time systems;Safety;Time factors;Telecommunication network reliability;Resource management;Internet of Things;Optimization;Next generation networking","","","","15","IEEE","23 Oct 2024","","","IEEE","IEEE Conferences"
"A Novel Approach for Scalable and Sustainable 6G Networks","L. Blanco; E. Zeydan; S. Barrachina-Muñoz; F. Rezazadeh; L. Vettori; J. Mangues-Bafalluy","Space and Resilient Communications and Systems (SRCOM) Research Unit, Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Barcelona, Spain; Services as Networks (SaS) Research Unit, Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Barcelona, Spain; Services as Networks (SaS) Research Unit, Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Barcelona, Spain; Services as Networks (SaS) Research Unit, Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Barcelona, Spain; Packet Optical Networks and Services (PONS) Research Unit, Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Barcelona, Spain; Services as Networks (SaS) Research Unit, Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Barcelona, Spain",IEEE Open Journal of the Communications Society,"27 Mar 2024","2024","5","","1673","1692","Hierarchical, distributed, scalable and Artificial Intelligence (AI)-based management of a massive number of network slices in different domains with the goal of zero-touch management is a major challenge for 6G networks. In this paper, we first propose a new vision for distributed network management and orchestration based on existing standardization architectures. This vision aims to embed AI/Machine Learning (ML) into the AI/ML architectures of Standardization Development Organizations (SDOs) such as the 3rd Generation Partnership Project (3GPP), the European Telecommunications Standards Institute (ETSI) and the International Telecommunication Union (ITU). Our second contribution is a numerical comparison of the benefits of the proposed distributed management and orchestration approach in terms of energy savings through Federated Learning (FL). The experimental topology includes a sophisticated infrastructure with VR streaming clients and servers, a monitoring system (MS), core network elements, aggregation server for federated learning (FL) and analytics engines (AEs). The deployment uses Kubernetes (K8s) and a top orchestrator that works together with an AI/ML model tailored to the envisioned use case. Experimental studies emulating the demanding Virtual Reality (VR) video streaming have demonstrated the effectiveness of the MonB5G framework in optimizing resource management, reducing overhead and improving energy efficiency. In particular, when convergence is achieved, the monitoring overhead is reduced by more than 11 times compared to the centralised SLA-constrained algorithm, along with data-driven management systems. This led to a more than 10-fold improvement in energy efficiency. At the end of the paper, we also discuss experimental results, VR video streaming specific challenges, scalability considerations and lessons learned throughout the implementation.","2644-125X","","10.1109/OJCOMS.2024.3372426","H2020 MonB5G Project(grant numbers:871780); Spanish Ministry of Economy and Competitiveness (MINECO)—Program UNICO I+D(grant numbers:TSI-063000-2021-54,TSI-063000-2021-55); “ERDF A way of making Europe” Project funded by MCIN/AEI/10.13039/501100011033(grant numbers:PID2021-126431OB-I00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10457850","Cloud native;monitoring;decision making;artificial intelligence;network management","Cloud computing;Computer architecture;Streaming media;Monitoring;Energy efficiency;6G mobile communication;3GPP","","2","","49","CCBYNCND","1 Mar 2024","","","IEEE","IEEE Journals"
"Improved Resource Allocation in 6G Networks Through Artificial Intelligence","R. Gupta; P. Kumar Sagar; S. Malhotra; K. Kulshreshtha","Computer Science & Engineering, SRM Institute of Science and Technology, Modinagar, UP, India; Computer Science & Engineering, Raj Kumar Goel Institute of Technology, Ghaziabad, UP, India; Computer Science & Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Department of Computer Engineering & Applications, GLA University, Mathura, Up, India",2024 2nd International Conference on Disruptive Technologies (ICDT),"11 Apr 2024","2024","","","1208","1213","This paper proposes a unique resource allocation technique for 6G networks the use of synthetic intelligence (AI). To assist the evolution of cellular networks, aid allocation mechanisms must be designed to successfully allocate network assets and assist the large wide variety of to be had offerings. Thus far, this has been implemented with the aid of traditional algorithms which possess an upper restrict on their talents. AI-based useful resource allocation offers superior adaptively and scalability to such algorithms, through gaining knowledge of from historic records and feedback from the person terminals. On this paper, an improved aid allocation algorithm primarily based on the integration of AI technology is proposed, underneath the perspective of optimizing both electricity performance and network overall performance. The proposed set of rules relies on a deep Q-learning framework, taking gain from deep neural networks to dynamically examine the most reliable resource allocation strategy. Simulation consequences display an improvement in network performance and energy performance in comparison to traditional optimization schemes.","","979-8-3503-7105-5","10.1109/ICDT61202.2024.10489785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10489785","propose;technique;mechanisms;dynamically;schemes","6G mobile communication;Performance evaluation;Q-learning;System performance;Scalability;Heuristic algorithms;Resource management","","","","27","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Channel Estimation for Reconfigurable Intelligent Surface-aided 6G NOMA Systems using CNN-based Quantum LSTM Model","N. Q. T. Thoong; A. A. Cheema; S. R. Khosravirad; O. A. Dobre; T. Q. Duong","Faculty of Engineering and Applied Science, Memorial University, St. John’s, Canada; School of Engineering, Ulster University, Belfast, UK; Nokia Bell Labs, Murray Hill, NJ, USA; Faculty of Engineering and Applied Science, Memorial University, St. John’s, Canada; Faculty of Engineering and Applied Science, Memorial University, St. John’s, Canada",2024 IEEE 100th Vehicular Technology Conference (VTC2024-Fall),"28 Nov 2024","2024","","","1","5","With the rapid development of communication applications, the integration of reconfigurable intelligent surface (RIS) and non-orthogonal multiple access (NOMA) techniques has emerged as a promising approach to enhance connectivity and data transmission rate in future wireless networks. To successfully deploy RIS-NOMA aided 6G network, an accurate channel estimation is a crucial task. Quantum machine learning (QML) is a novel approach showing potential computational advantages in various problems of 6G wireless communications. However, its application, particularly in channel estimation, remains largely theoretical rather than adopted in practice. We propose a hybrid quantum-classical neural network model based on convolutional neural network (CNN) and quantum long short-term memory (QLSTM) for channel estimation in RIS-aided 6G NOMA system. Our results show that the proposed CNN-QLSTM model has a better channel prediction compared to its classical counterpart with regard to root mean square error (RMSE) and mean absolute error (MAE).","2577-2465","979-8-3315-1778-6","10.1109/VTC2024-Fall63153.2024.10757552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10757552","Channel estimation;CNN-QLSTM;QLSTM;NOMA;RIS;6G","6G mobile communication;NOMA;Computational modeling;Channel estimation;Machine learning;Predictive models;Reconfigurable intelligent surfaces;Convolutional neural networks;Integrated circuit modeling;Long short term memory","","","","21","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"Designing Robust Spectrum Allocation Algorithms for 6G Cellular Networks","A. Chauhan; R. David; R. Chakraborty","Department of Agri-Business Management, Vivekananda Global University, Jaipur, India; Department of Civil Engineering, School of Engineering and Technology, JAIN (Deemed to be University), Bangalore, Karnataka, India; Department of Computer Science & IT, ARKA JAIN University, Jamshedpur, Jharkhand, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","6","This paper explores the idea of the sturdy spectrum allocation algorithms for 6G cell networks. It proposes a framework based on a multi-goal optimization procedure to design disbursed spectrum allocation algorithms for the target 6G device. The proposed framework includes two elements, specifically, the modelling of goals and the optimization technique. For the modelling of goals, the paper discusses the characteristics of 6G networks relevant to spectrum allocation, consisting of conversation parameters, dynamic spectrum conditions, and bendy utilization of sources. Moreover, the paper also introduces a hard and fast mathematical optimization model for the spectrum allocation hassle. Subsequently, the paper considers the optimization manner, which includes multi-goal optimization algorithms, dispensed optimization algorithms, and simulations. The paper explores the overall performance of the proposed algorithms in a series of simulation experiments and the usage of community scenarios that replicate the traits of the 6G device. The consequences display that the proposed algorithms can efficiently enhance the overall performance of the spectrum allocation process in 6G mobile networks.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10724324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724324","Spectrum;Optimization;Mathematical;Algorithms;Consequences;Networks","6G mobile communication;Performance evaluation;Machine learning algorithms;Heuristic algorithms;Optimization models;Oral communication;Machine learning;Reliability engineering;Resource management;Optimization","","","","12","IEEE","4 Nov 2024","","","IEEE","IEEE Conferences"
"Role of AI and Open RAN in 6G Networks: Performance Impact and Key Technologies","Y. S. Junejo; F. K. Shaikh; B. S. Chowdhry; W. Ejaz","Dept. of Electrical Engineering, Lakehead University, Barrie, ON, Canada; Telecommunication Engineering, Mehran University of Engg. & Tech., Jamshoro, Pakistan; Telecommunication Engineering, Mehran University of Engg. & Tech., Jamshoro, Pakistan; Dept. of Electrical Engineering, Lakehead University, Barrie, ON, Canada",2024 IEEE International Conference on Advanced Telecommunication and Networking Technologies (ATNT),"23 Oct 2024","2024","1","","1","4","Integrating artificial intelligence (AI) and open radio access network (RAN) into sixth-generation (6G) networks has led to significant transformation and advancement in the wireless communications industry, especially for cellular networks. It offers enhanced network performance, which is essential for future networks. This paper examines the impact of AI and O-RAN integration in the 6G architecture and possibly the latest 6G technologies, providing insight into how these technologies can benefit from the AI-based open 6G RAN architecture. We discuss the challenges of transitioning from traditional to future RAN, including interoperability, mobility, performance issues, complexity, and regulatory standards, and propose the possible future directions to these challenges.","","979-8-3503-5350-1","10.1109/ATNT61688.2024.10719225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10719225","Open 6G RAN;AI-RAN;6G Enabling Technologies","6G mobile communication;Wireless communication;Industries;Cellular networks;Open RAN;Communications technology;Complexity theory;Artificial intelligence;Standards;Interoperability","","","","12","IEEE","23 Oct 2024","","","IEEE","IEEE Conferences"
"Multi-Process Federated Learning With Stacking for Securing 6G-V2X Network Slicing at Cross-Borders","A. Boualouache; A. A. Jolfaei; T. Engel","Faculty of Science, Technology and Medicine (FSTM), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Faculty of Science, Technology and Medicine (FSTM), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Faculty of Science, Technology and Medicine (FSTM), University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Intelligent Transportation Systems,"29 Aug 2024","2024","25","9","10941","10952","Being part of the 6G ecosystem vision, Connected and Automated Vehicles (CAVs) will enjoy sophisticated tailored services offering road safety and entertainment for users. As one of the 6G cornerstones, Network Slicing (NS) allows the creation of various customized 6G-V2X (Vehicle-to-Everything) use cases on the same physical infrastructure. However, 6G-NS advances can open up breaches to cyber-attacks aiming to break 6G-V2X Network slices to inflict maximum damage on CAVs and their users. Crossing borders, where CAVs leave their V2X-NS (V2X Network Slice) in the Home Mobile Network Operator (H-MNO) toward a similar V2X-NS in the Visited MNO (V-MNO), is an attractive opportunity to exploit by attackers. Detecting and mitigating attacks, in this case, becomes a priority, confronted by NS requirements and MNOs not ready to share their private data. To this end, this paper proposes a 3GPP-compliant privacy preservation collaborative learning scheme for 6G-NS security, focusing on V2X-NS cross-border areas. Our scheme leverages multi-process Federated Learning (FL) architecture to build efficient V2X-NS security-related models while preserving 6G V2X-NS isolation. In addition, it uses differential privacy-enabled stacking to build up attack detection knowledge at the V2X-NSs and MNOs levels while ensuring privacy preservation. We conducted an experimental study on the 5G-NIDD dataset, which is one of the most realistic publicly available 5G datasets. Our results demonstrate that multi-process FL with stacking can deliver high accuracy while ensuring isolation between 6G-V2X-NSs and privacy preservation between H-MNO and V-MNO.","1558-0016","","10.1109/TITS.2024.3367388","5G-INSIGHT Bilateral Project; Luxembourg National Research Fund (FNR)(grant numbers:14891397,ANR-20-CE25-0015-16); French National Research Agency (ANR); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10457521","6G-V2X;network slicing;security;machine learning;misbehaving detection systems;federated learning","6G mobile communication;Security;Network slicing;Privacy;Biological system modeling;5G mobile communication;Stacking","","3","","34","IEEE","1 Mar 2024","","","IEEE","IEEE Journals"
"Toward Autonomous Resource Management Architecture for 6G Satellite-Terrestrial Integrated Networks","F. Ding; C. Bao; D. Zhou; M. Sheng; Y. Shi; J. Li","State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, Shaanxi, China",IEEE Network,"9 May 2024","2024","38","2","113","121","Different from all existing mobile communication systems, the sixth-generation (6G) mobile communication system is expected to realize satellite-terrestrial integrated networks (STINs) and ubiquitous artificial intelligence (AI), which promotes that resource management (RM) realizes higher autonomy facing heterogeneous and high dynamic STIN and the 6G diverse service requirements. However, in what form will AI be applied in STIN’s RM to give full play to its capabilities? How to construct an AI-integrated STIN’s RM architecture to endow RM with higher autonomy and greater flexibility? In this article, AI is applied to STIN in an endogenous form, i.e., STIN has the ability to perceive and process information on service demands and resource states, and STIN can realize continuous optimization of service performance under unmanned conditions to play the role of AI more effectively. Further, this article combines the characteristics of AI and STIN to design an AI-centric threelevel closed-loop (Resource-Access-Service-Access-Resource) intelligent RM (RASAR) architecture for STIN. Specifically, the RASAR architecture abstracts the STIN’s RM into three independently deployable management functions and achieves satelliteterrestrial and access-bearer integrated resource management by designing the interfaces and the service performance feedback mechanism with the help of STIN’s transmission capability and computing power. In addition, the closed-loop implementation of RASAR architecture promotes the combination of AI selftraining and self-optimization of all levels to provide a solution for STIN’s autonomous RM. Finally, a case study is presented, followed by a discussion of open research issues that are essential for the RASAR architecture.","1558-156X","","10.1109/MNET.2024.3354308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10400511","","Computer architecture;Artificial intelligence;Resource management;6G mobile communication;Ions;Integrated circuits;Satellites;Autonomous systems;Space-air-ground integrated networks","","1","","15","IEEE","15 Jan 2024","","","IEEE","IEEE Magazines"
"Federated Learning-based Unicast/Multicast Service Delivery over 6G O-RAN Framework","C. C. González; E. F. Pupo; J. Montalban; E. Iradier; P. Angueira; M. Murroni","University of Cagliari, Sardinia, Italy; University of Cagliari, Sardinia, Italy; University of the Basque Country, Bilbao, Spain; University of the Basque Country, Bilbao, Spain; University of the Basque Country, Bilbao, Spain; University of Cagliari, Sardinia, Italy",2024 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB),"31 Jul 2024","2024","","","1","6","The path toward the envisioned International Mobile Telecommunications (IMT)-2030 requires seamless terrestrial and non-terrestrial networks (TNs-NTNs) convergence and shared unicast/multicast capability to face the critical 6G research verticals. The Multicast/Broadcast Services (MBS) paradigm over three-dimensional (3D) heterogeneous networks adds new degrees of freedom during coverage planning and service delivery. Embedding these technologies into an Open Radio Access Network (RAN), such as the softwarized and disaggregated architecture promoted by the O-RAN Alliance, enables native intelligent solutions with extreme flexibility. Hence, we propose a solution for shared unicast/multicast service delivery over a TN-airborne connectivity in the 6G O-RAN architecture. We present a dynamic TN-NTN selection and slice allocation algorithm based on Federated Double Deep Q-Network (FDDQN) inserted into a novel O-RAN scenario. The proposal is validated through link-level simulations, evaluating diverse network conditions and service constraints, several concurrent users, and the impact of slicing resource utilization.","2155-5052","979-8-3503-6426-2","10.1109/BMSB62888.2024.10608261","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10608261","6G;Federated Deep Reinforcement Learning;Multicast/Broadcast Services;O-RAN;TN-NTN","6G mobile communication;Three-dimensional displays;Heuristic algorithms;Simulation;Satellite broadcasting;Open RAN;Computer architecture","","","","25","IEEE","31 Jul 2024","","","IEEE","IEEE Conferences"
"Power Allocation Optimization Based on Multi-Agents Reinforcement Learning for 6G Cellular Networks","H. F. Alhashimi; M. N. Hindia; K. Dimyati; E. B. Hanafi; T. F. T. M. N. Izam","department of Electrical Engineering, Centre of Advanced Communication, Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya (UM), Kualalumpur, Malaysia; department of Electrical Engineering, Centre of Advanced Communication, Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya (UM), Kualalumpur, Malaysia; department of Electrical Engineering, Centre of Advanced Communication, Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya (UM), Kualalumpur, Malaysia; department of Electrical Engineering, Centre of Advanced Communication, Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya (UM), Kualalumpur, Malaysia; department of Electrical Engineering, Centre of Advanced Communication, Research and Innovation (ACRI), Faculty of Engineering, Universiti Malaya (UM), Kualalumpur, Malaysia",2024 Multimedia University Engineering Conference (MECON),"10 Dec 2024","2024","","","1","6","In 6G wireless networks, Multi-Tier Cellular Networks (MTCN) provide increased capacity and effective coverage. However, the performance of MTCN architecture is affected by interferences. MTCN interference management and power allocation have been addressed in several approaches. Nevertheless, guaranteeing Quality of Service (QoS) for User Equipments (UEs) is still challenging. Self-optimization capabilities of artificial intelligence-based power allocation algorithms in MTCN have shown their effectiveness. In this paper, a power allocation method based on Multi-Agent Reinforcement Learning (MARL) for relay-assisted MTCN is proposed. The presented MARL approach effectively distributes power resources to the Macrocell Base Station (MBS) and Small cell Base Station (SBS) to meet the minimum capacity needs of UEs. Modeling a cellular network as a multi-agent network involves assigning an agent to each base station. The reward functions of the proposed MARL consider the EE and QoS for each agent. The simulation results show the effectiveness and superiority of the suggested approach in comparison to the reference methods.","","979-8-3315-3074-7","10.1109/MECON62796.2024.10776446","Ministry of Higher Education (MoHE), Malaysia(grant numbers:FRGS/1/2020/TK0/UM/01/2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10776446","Multi-Agent Reinforcement Learning (MARL);Power Allocation;Interference Management;Multi-Tier Cellular Networks (MTCN);Quality of Service (QoS)","6G mobile communication;Base stations;Simulation;Wireless networks;Quality of service;Reinforcement learning;Computer architecture;Probability;Resource management;Optimization","","","","22","IEEE","10 Dec 2024","","","IEEE","IEEE Conferences"
"XAI-driven Model Design for Resource Utilization Forecasting in Cloud-native 6G Networks","L. Liatsas; G. M. Kibalya; A. Antonopoulos","Nearby Computing S.L, Barcelona, Spain; Nearby Computing S.L, Barcelona, Spain; Nearby Computing S.L, Barcelona, Spain",2024 IEEE International Mediterranean Conference on Communications and Networking (MeditCom),"12 Aug 2024","2024","","","566","571","As cloud-native 6th Generation (6G) networks emerge, the resource utilization forecasting becomes crucial for effective service and network orchestration. While Artificial Intelligence (AI) holds promise in this domain, the diverse nature of the 6G underlying infrastructure and services poses significant challenges on the customization and the efficient design of the AI models. In this paper, we introduce the adoption of eXplainable AI (XAI) to generate spatio-temporal insights on the predictions of advanced AI models. Additionally, we present DuCAT, a Dual Cumulative Attribution Thresholding (DuCAT) heuristic algorithm, for feature and time window size selection towards AI model reduction. Experimental results on a publicly available dataset of cloud resource traces demonstrate that our proposed approach can efficiently reduce the AI model’s complexity (up to 60% decrease in inference time) without compromising prediction accuracy, addressing critical requirements for agile and resource-efficient 6G networks.","","979-8-3503-0948-5","10.1109/MeditCom61057.2024.10621360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10621360","6G networks;cloud-native;explainable artificial intelligence;time series forecasting;workload prediction.","6G mobile communication;Explainable AI;Heuristic algorithms;Predictive models;Prediction algorithms;Reduced order systems;Inference algorithms","","","","17","IEEE","12 Aug 2024","","","IEEE","IEEE Conferences"
"Federated Deep Reinforcement Learning for Prediction-Based Network Slice Mobility in 6G Mobile Networks","Z. Ming; H. Yu; T. Taleb","Centre for Wireless Communications (CWC), University of Oulu, Oulu, Finland; ICTFicial Oy, Espoo, Finland; Ruhr University Bochum, Bochum, Germany",IEEE Transactions on Mobile Computing,"6 Nov 2024","2024","23","12","11937","11953","Network slices are generally coupled with services and face service continuity/unavailability concerns due to the high mobility and dynamic requests from users. Network slice mobility (NSM), which considers user mobility, service migration, and resource allocation from a holistic view, is witnessed as a key technology in enabling network slices to respond quickly to service degradation. Existing studies on NSM either ignored the trigger detection before NSM decision-making or didn't consider the prediction of future system information to improve the NSM performance, and the training of deep reinforcement learning (DRL) agents also faces challenges with incomplete observations. To cope with these challenges, we consider that network slices migrate periodically and utilize the prediction of system information to assist NSM decision-making. The periodical NSM problem is further transformed into a Markov decision process, and we creatively propose a prediction-based federated DRL framework to solve it. Particularly, the learning processes of the prediction model and DRL agents are performed in a federated learning paradigm. Based on extensive experiments, simulation results demonstrate that the proposed scheme outperforms the considered baseline schemes in improving long-term profit, reducing communication overhead, and saving transmission time.","1558-0660","","10.1109/TMC.2024.3404125","European Union's HE research and innovation program HORIZON-JUSNS-2023(grant numbers:101139172); European Union's HE research and innovation program HORIZON-JUSNS-2022(grant numbers:101096328); European Union's Horizon Europe; EU's key funding program for research and innovation(grant numbers:101069732); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10536643","Prediction-based network slice mobility;incomplete observation;deep reinforcement learning","Resource management;Decision making;6G mobile communication;Dynamic scheduling;Training;Quality of service;Long short term memory","","1","","51","CCBY","22 May 2024","","","IEEE","IEEE Journals"
"Joint Network Slicing, Routing, and In-Network Computing for Energy-Efficient 6G","Z. Sasan; M. Shokrnezhad; S. Khorsandi; T. Taleb","Amirkabir University of Technology, Tehran, Iran; Oulu University, Oulu, Finland; Amirkabir University of Technology, Tehran, Iran; Oulu University, Oulu, Finland",2024 IEEE Wireless Communications and Networking Conference (WCNC),"3 Jul 2024","2024","","","1","6","To address the evolving landscape of next-generation mobile networks, characterized by an increasing number of connected users, surging traffic demands, and the continuous emergence of new services, a novel communication paradigm is essential. One promising candidate is the integration of network slicing and in-network computing, offering resource isolation, deterministic networking, enhanced resource efficiency, network expansion, and energy conservation. Although prior research has explored resource allocation within network slicing, routing, and in-network computing independently, a comprehensive investigation into their joint approach has been lacking. This paper tackles the joint problem of network slicing, path selection, and the allocation of in-network and cloud computing resources, aiming to maximize the number of accepted users while minimizing energy consumption. First, we introduce a Mixed-Integer Linear Programming (MILP) formulation of the problem and analyze its complexity, proving that the problem is NP-hard. Next, a Water Filling-based Joint Slicing, Routing, and In-Network Computing (WF-JSRIN) heuristic algorithm is proposed to solve it. Finally, a comparative analysis was conducted among WF-JSRIN, a random allocation technique, and two optimal approaches, namely Opt-IN (utilizing in-network computation) and Opt-C (solely relying on cloud node resources). The results emphasize WF-JSRIN's efficiency in delivering highly efficient near-optimal solutions with significantly reduced execution times, solidifying its suitability for practical real-world applications.","1558-2612","979-8-3503-0358-2","10.1109/WCNC57260.2024.10571186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10571186","6G;Beyond 5G;Resource Allocation;Network Slicing;Routing;In-Network Computing","6G mobile communication;Cloud computing;Costs;Network slicing;Heuristic algorithms;Bandwidth;Routing","","1","","18","IEEE","3 Jul 2024","","","IEEE","IEEE Conferences"
"A Conceptual Framework for the Development of Autonomous Driving in 6G: the Role of AI and Edge Computing","M. -D. Cano; A. Guillen-Perez; I. Tasic; A. Villafranca","Department of Information Technologies and Communications, Universidad Politécnica de Cartagena, Cartagena, Spain; Department of Information Technologies and Communications, Universidad Politécnica de Cartagena, Cartagena, Spain; Department of Information Technologies and Communications, Universidad Politécnica de Cartagena, Cartagena, Spain; Department of Information Technologies and Communications, Universidad Politécnica de Cartagena, Cartagena, Spain","2023 8th International Conference on Control, Robotics and Cybernetics (CRC)","9 Apr 2024","2024","","","97","105","The scientific community is focusing on developing 6G solutions beyond the 5G communications network, which will use Artificial Intelligence (AI) solutions at all levels of the communications architecture. The potential benefits of AI will automate and optimize network operation, boost cognitive capability and use a fully AI-enabled architecture. This paper proposes a framework for solving the current problem of orchestrating cooperative control of autonomous vehicles using 6G, which identifies new challenges, requirements, and improvements to deploy future cooperative Connected Autonomous Vehicles (CAV) successfully. The proposed architecture would enable edge-decentralized cooperative control of CAV using AI techniques and specialized AI hardware at different levels of the 6G communication architecture. The framework proposes vehicle management and control tasks to be performed in nodes called Vehicle Edge Nodes (VEN), which would be trained in a fine-grained way the diverse vehicle control systems and infer them, keeping latency to a minimum and providing high reliability for cooperative vehicular management and control using a set of nodes called PicoCells.","","979-8-3503-3058-8","10.1109/CRC60659.2023.10488509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10488509","6G;Autonomous Driving;Communication Networks;Connected Autonomous Vehicles;Artificial Intelligence;Neural Networks;Edge Computing;Intelligent Transport Systems","6G mobile communication;Training;5G mobile communication;Computer architecture;Hardware;Reliability;Artificial intelligence","","","","65","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"Toward Explainable Reasoning in 6G: A Proof of Concept Study on Radio Resource Allocation","F. Rezazadeh; S. Barrachina-Muñoz; H. Chergui; J. Mangues; M. Bennis; D. Niyato; H. Song; L. Liu","Department of Services as NetworkS, Centre Tecnológic de Telecomunicacions de Catalunya, Barcelona, Spain; Department of Services as NetworkS, Centre Tecnológic de Telecomunicacions de Catalunya, Barcelona, Spain; Department of Software Networks, i2CAT Foundation, Barcelona, Spain; Department of Services as NetworkS, Centre Tecnológic de Telecomunicacions de Catalunya, Barcelona, Spain; Centre for Wireless Communications, University of Oulu, Oulu, Finland; College of Computing and Data Science, Nanyang Technological University, Nanyang Avenue, Singapore; Department of Information Systems, University of Maryland, Baltimore County, Baltimore, MD, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",IEEE Open Journal of the Communications Society,"4 Oct 2024","2024","5","","6239","6260","The move toward artificial intelligence (AI)-native sixth-generation (6G) networks has put more emphasis on the importance of explainability and trustworthiness in network management operations, especially for mission-critical use-cases. Such desired trust transcends traditional post-hoc explainable AI (XAI) methods to using contextual explanations for guiding the learning process in an in-hoc way. This paper proposes a novel graph reinforcement learning (GRL) framework named TANGO which relies on a symbolic subsystem. It consists of a Bayesian-graph neural network (GNN) Explainer, whose outputs, in terms of edge/node importance and uncertainty, are periodically translated to a logical GRL reward function. This adjustment is accomplished through defined symbolic reasoning rules within a Reasoner. Considering a real-world testbed proof-of-concept (PoC), a gNodeB (gNB) radio resource allocation problem is formulated, which aims to minimize under- and over-provisioning of physical resource blocks (PRBs) while penalizing decisions emanating from the uncertain and less important edge-nodes relations. Our findings reveal that the proposed in-hoc explainability solution significantly expedites convergence compared to standard GRL baseline and other benchmarks in the deep reinforcement learning (DRL) domain. The experiment evaluates performance in AI, complexity, energy consumption, robustness, network, scalability, and explainability metrics. Specifically, the results show that TANGO achieves a noteworthy accuracy of 96.39% in terms of optimal PRB allocation in inference phase, outperforming the baseline by  $1.22\times $ .","2644-125X","","10.1109/OJCOMS.2024.3466225","MCIN/AEI/10.13039/501100011033(grant numbers:PID2021-126431OB-I00 (ANEMONE)); Spanish MINECO(grant numbers:TSI-063000-2021-54 (6G-DAWN ELASTIC),TSI-063000-2021-56 (6G-BLUR SMART)); Generalitat de Catalunya(grant numbers:2021 SGR 00770); Horizon Europe through NANCY Project(grant numbers:101096456); COGNIFOG Project(grant numbers:101092968); ERA-NET CHISTERA Project (MUSE-COM2: AI-Enabled Multimodal Semantic Communications and Computing); U.S. National Science Foundation(grant numbers:2229473,2309760,2317117); National Research Foundation, Singapore; Infocomm Media Development Authority under its Future Communications Research and Development Programme; Defence Science Organisation (DSO) National Laboratories through the AI Singapore Programme(grant numbers:FCP-NTU-RG-2022-010,FCP-ASTAR-TG-2022-003); Singapore Ministry of Education (MOE) Tier 1(grant numbers:RG87/22); NTU Centre for Computational Technologies in Finance (NTU-CCTF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10689363","B5G/6G;AI/ML;neuro-symbolic;XAI;GNN;DRL;GRL;resource allocation","Resource management;6G mobile communication;Artificial intelligence;Bayes methods;Measurement;Predictive models;Explainable AI","","1","","111","CCBYNCND","23 Sep 2024","","","IEEE","IEEE Journals"
"Leveraging Network Data Analytics Function and Machine Learning for Data Collection, Resource Optimization, Security and Privacy in 6G Networks","P. K. Gkonis; N. Nomikos; P. Trakadas; L. Sarakis; G. Xylouris; X. Masip-Bruin; J. Martrat","Department of Digital Industry Technologies, National and Kapodistrian University of Athens, Athens, Euboea, Greece; Department of Ports Management and Shipping, National and Kapodistrian University of Athens, Athens, Euboea, Greece; Department of Ports Management and Shipping, National and Kapodistrian University of Athens, Athens, Euboea, Greece; Department of Digital Industry Technologies, National and Kapodistrian University of Athens, Athens, Euboea, Greece; National Center of Scientific Research “Demokritos,”, Athens, Greece; CRAAX Laboratory, Universitat Politècnica de Catalunya (UPC), Vilanova i la Geltrú, Spain; BDS INN R&D (formerly called ATOS), Barcelona, Eviden, Spain",IEEE Access,"12 Feb 2024","2024","12","","21320","21336","The full deployment of sixth-generation (6G) networks is inextricably connected with a holistic network redesign able to deal with various emerging challenges, such as integration of heterogeneous technologies and devices, as well as support of latency and bandwidth demanding applications. In such a complex environment, resource optimization, and security and privacy enhancement can be quite demanding, due to the vast and diverse data generation endpoints and associated hardware elements. Therefore, efficient data collection mechanisms are needed that can be deployed at any network infrastructure. In this context, the network data analytics function (NWDAF) has already been defined in the fifth-generation (5G) architecture from Release 15 of 3GPP, that can perform data collection from various network functions (NFs). When combined with advanced machine learning (ML) techniques, a full-scale network optimization can be supported, according to traffic demands and service requirements. In addition, the collected data from NWDAF can be used for anomaly detection and thus, security and privacy enhancement. Therefore, the main goal of this paper is to present the current state-of-the-art on the role of the NWDAF towards data collection, resource optimization and security enhancement in next generation broadband networks. Furthermore, various key enabling technologies for data collection and threat mitigation in the 6G framework are identified and categorized, along with advanced ML approaches. Finally, a high level architectural approach is presented and discussed, based on the NWDAF, for efficient data collection and ML model training in large scale heterogeneous environments.","2169-3536","","10.1109/ACCESS.2024.3359992","HORSE Project funded by the Smart Networks and Services Joint Undertaking (SNS JU) through the European Union’s Horizon Europe Research and Innovation Program(grant numbers:101096342); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10416824","6G;anomaly detection;machine learning;network data analytics function;open radio access network;resource optimization;security and privacy","Optimization;Security;6G mobile communication;Data collection;Data privacy;Anomaly detection;5G mobile communication;Machine learning;Data analysis;Open Access;Radio access networks","","6","","100","CCBYNCND","30 Jan 2024","","","IEEE","IEEE Journals"
"Towards Intent-based Network Management for the 6G System adopting Multimodal Generative AI","D. Brodimas; K. Trantzas; B. Agko; G. C. Tziavas; C. Tranoris; S. Denazis; A. Birbas","Dept. of Electrical and Computer Engineering, University of Patras, Patras, Greece; Dept. of Electrical and Computer Engineering, University of Patras, Patras, Greece; Dept. of Electrical and Computer Engineering, University of Patras, Patras, Greece; Dept. of Electrical and Computer Engineering, University of Patras, Patras, Greece; Dept. of Electrical and Computer Engineering, University of Patras, Patras, Greece; Dept. of Electrical and Computer Engineering, University of Patras, Patras, Greece; Dept. of Electrical and Computer Engineering, University of Patras, Patras, Greece",2024 Joint European Conference on Networks and Communications & 6G Summit (EuCNC/6G Summit),"19 Jul 2024","2024","","","848","853","The emerging concept of delivering Network-as-a-Service (NaaS) foresees the deployment and reconfiguration of the next-generation networks, such as 6G, in a dynamic and elastic manner, tailored to the respective stakeholder’s intention. Taking this into account, the efficient management and orchestration of both telecommunication and computational resources across the network domains, i.e. access, transport and core presents a considerable challenge, even for network experts. To tackle this complexity, this paper explores the implementation of an intent-based management framework. The framework receives a high-level description of the desired network capabilities along with supplementary files, e.g. deployment descriptors, and translates them into configuration files consumable by the network itself. In order to achieve this, the paper establishes a translation pipeline that leverages the employment of emerging multimodal generative artificial intelligence (GenAI) models, specifically Large Language Models (LLMs), and open industry-ready standard templates. The adoption of those two emerging technologies offers high dynamicity on the interpretation process of the user’s intent, while ensuring that its outcome is compatible with every orchestrator or next-generation Operating Support System (Next-gen OSS) that adheres to those standards.","2575-4912","979-8-3503-4499-8","10.1109/EuCNC/6GSummit60053.2024.10597022","Horizon Europe; CODE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597022","Intent-Based Networking;Large Language Models;Multimodal Generative Artificial Intelligence;Orchestration;Standards","6G mobile communication;Training;Generative AI;Intent recognition;Large language models;Employment;Pipelines","","2","","21","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AI-RAN in 6G Networks: State-of-the-Art and Challenges","N. A. Khan; S. Schmid","Department of Internet Architecture and Management, Technical University Berlin, Berlin, Germany; Department of Internet Architecture and Management, Technical University Berlin, Berlin, Germany",IEEE Open Journal of the Communications Society,"4 Jan 2024","2024","5","","294","311","6G is a next-generation cellular communication technology that builds up on existing 5G networks which are currently rolled out worldwide. Through incorporation of artificial intelligence (AI) and machine learning (ML), the core 5G network is advanced into an intelligent 6G network. The 6G Artificial Intelligence Radio Access Network (AI-RAN) is anticipated to offer advanced features like reduced latency, improved bandwidth, data rates and coverage. Furthermore, AI-RAN is expected to support complex use cases such as extreme connectivity, multi-user communications and dynamic spectrum access. This paper provides a detailed survey and thorough assessment of AI-RAN’s vision and state-of-the-art challenges. We first present a concise introduction to 6G AI-RAN followed by background information on the current 5G RAN and its challenges that must be overcome to implement 6G AI-RAN. The paper then examines trending research issues in AI-RAN, i.e., challenges related to spectrum allocation, network architecture, and resource management. We discuss the methods to overcome these challenges which include the adoption of advanced machine learning and edge computing technologies to boost the performance of 6G AI-RAN. We conclude by stating open research directions.","2644-125X","","10.1109/OJCOMS.2023.3343069","Federal Ministry of Education and Research (BMBF, Germany) as part of the 6G Research and Innovation Cluster 6G-RIC(grant numbers:16KISK020K); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10360202","5G;6G;AI-RAN;AI/ML;radio and future Internet architecture","6G mobile communication;5G mobile communication;Resource management;Millimeter wave communication;Radio frequency;Radio access networks;Optimization","","12","","148","CCBY","14 Dec 2023","","","IEEE","IEEE Journals"
"6G: Technology Evolution in Future Wireless Networks","M. Shafi; R. K. Jha; S. Jain","Department of Electronics and Communication Engineering, Central University of Jammu, Bagla Suchani, Jammu and Kashmir, India; Department of Electronics and Communication Engineering, Central University of Jammu, Bagla Suchani, Jammu and Kashmir, India; Department of Computer Science Engineering, Central University of Jammu, Bagla Suchani, Jammu and Kashmir, India",IEEE Access,"26 Apr 2024","2024","12","","57548","57573","The Sixth Generation (6G) Wireless Communication Network (WCN) is the successive provision to ameliorate the gain with ultra-low latency, and e xtremely high energy efficiency. The 6G WCN enables the specifications of artificial intelligence to optimize the services and capabilities. The vision of the 6G era is expected to address a seamless fusion of communication between the human, physical world, and digital world. The latest 6G WCN standard is a fundamental foundation and requires immense attention in the field of research. This paper presents the framework of 6G WCN with an illustration of its key technologies. The different technologies involved in 6G are well explained with the demonstration of the communication scenario such that the key performance indicators are improved with major differences. The primary contribution of this paper is the explanation of the 6G with the technologies that have a drastic impact on the characteristic aspects of a wireless communication network such as data rate, spectrum efficiency, energy efficiency, connection density, and reliability. All these technologies have the capability to revolutionize the subsequent WCN.","2169-3536","","10.1109/ACCESS.2024.3385230","Central University of Jammu; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491244","6G technologies;SaFi;terahertz communication;VLC;RIS;DICN;AI","Reconfigurable intelligent surfaces;6G mobile communication;Array signal processing;Estimation;Sensors;Channel estimation;Energy efficiency;Terahertz communications;Artificial intelligence;Wireless networks","","8","","201","CCBYNCND","4 Apr 2024","","","IEEE","IEEE Journals"
"Transformative Storage Framework for 6G Smart City Deployments","M. N; B. S; S. T; L. G; A. T; P. D","Department of CSE, CEG, Anna University, Chennai, India; Department of CSE, CEG, Anna University, Chennai, India; Department of CSE, Ramco Institute of Technology, Rajapalayam, India; School of Computer Science Engineering, VIT, Chennai; Department of CSE, Sathyabama Institute of Science, Technology, Chennai, India; Department of CSE, Anna University Regional Campus, Coimbatore, India","2024 Third International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)","23 Oct 2024","2024","","","1","6","The advent of 6G networks is poised to revolutionize the digital landscape by offering unprecedented data transfer speeds, ultra-low latency, and enhanced connectivity capabilities. This paradigm shift necessitates the development of robust and efficient storage solutions to handle the massive influx of data generated by ubiquitous IoT devices, immersive applications, and intelligent systems. In this context, we propose a multilevel storage Algorithm (LRU + OPTIMAL) designed specifically for the 6G networking environment in smart cities. Our algorithm synergizes the Last Recently Used (LRU) and Optimal algorithms to dynamically manage storage resources, thereby ensuring optimal data retrieval and minimizing latency. The deployment of 6G networks introduces complex data storage challenges, driven by the exponential growth of data traffic and the real-time processing is required. By integrating LRU and Optimal algorithms, our multi-level storage framework can effectively prioritize data caching and retrieval operations, thereby enhancing system efficiency and responsiveness. This approach leverages the predictive capabilities of the optimal algorithm to anticipate future data needs, while the LRU algorithm ensures that frequently accessed data remains readily available. Compared to 5G networks, 6G offers significantly higher bandwidth, reduced latency, and increased device density, all of which exacerbate storage demands. Our algorithm addresses these challenges by optimizing storage utilization and ensuring seamless data flow across distributed network nodes. The comparative analysis underscores the superiority of 6G in handling complex, data-intensive applications, thus necessitating advanced storage solutions such as our proposed algorithm. In the Multi-Level Storage Algorithm (LRU + OPTIMAL), a scalable and efficient framework for managing optimal storage space in 6G networks, ensuring that the storage infrastructure can keep pace with the rapid advancements in 6G technology, thereby supporting the seamless operation of next-generation digital services.","","979-8-3503-6908-3","10.1109/ICEEICT61591.2024.10718383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10718383","6G;least recently used;optimal;multi-input multi-output;smart devices","6G mobile communication;Smart cities;Heuristic algorithms;Memory;Prediction algorithms;Real-time systems;Security;Wireless fidelity;Next generation networking;Interoperability","","","","15","IEEE","23 Oct 2024","","","IEEE","IEEE Conferences"
"RL-Based High-Level Radio Unit Clustering and Distributed Unit Assignment in User-Centric Cell-free mMIMO for ORAN-Based 6G","N. Ghafouri; J. S. Vardakas; K. Ramantas; C. Verikoukis","Iquadrat Informatica S.L., Barcelona, Spain; Dept. of Informatics, University of Western Macedonia, Greece; Iquadrat Informatica S.L., Barcelona, Spain; University of Patras, ISI/ATHENA, and Iquadrat Informatica S.L.",ICC 2024 - IEEE International Conference on Communications,"20 Aug 2024","2024","","","2065","2070","Cell- Free (CF) massive Multiple- Input- Multiple-Output (mMIMO) has recently gained significant research attention as a promising technology for future wireless networks. Since the conventional CF mMIMO has been considered unscalable and impractical, user-centric CF systems were proposed to improve its flexibility. While Access Point (AP) clustering has been studied in many research works as a challenging task in Radio Access Network (RAN), the limitations of the connecting links to the servers in a real scenario have not been taken into account. In this work, we consider the innovative combination of Open RAN (ORAN) and CF-RAN architecture that aims to improve the CF network limitations related to the connecting links. Then, we propose two control loops for ORAN Radio Unit (ORU) clustering and ORAN Distributed Unit (O-DU) assignment procedures that are conducted by Reinforcement Learning (RL) agents. Numerical results show that the proposed approach can successfully provide the user's requirements while the network is balanced.","1938-1883","978-1-7281-9054-9","10.1109/ICC51166.2024.10622379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10622379","6G;Cell-free mMIMO;ORAN;Access Point Clustering;Reinforcement Learning","6G mobile communication;Wireless networks;Reinforcement learning;Open RAN;Numerical models;Servers;Resource management","","","","31","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Cell-Free MIMO in 6G NTN with AI-predicted CSI","B. De Filippo; R. Campana; A. Guidotti; C. Amatetti; A. Vanelli-Coralli","Dept. of Electrical, Electronic, and Information Engineering (DEI), Univ. of Bologna, Bologna, Italy; Dept. of Electrical, Electronic, and Information Engineering (DEI), Univ. of Bologna, Bologna, Italy; National Inter-University Consortium for Telecommunications (CNIT), Italy; Dept. of Electrical, Electronic, and Information Engineering (DEI), Univ. of Bologna, Bologna, Italy; Dept. of Electrical, Electronic, and Information Engineering (DEI), Univ. of Bologna, Bologna, Italy",2024 IEEE 25th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),"7 Oct 2024","2024","","","631","635","Non-Terrestrial Networks (NTNs) in 6G are expected to integrate the Terrestrial Networks (TNs) coverage and provide connectivity to a multitude of User Terminals (UTs). In order to cope with the traffic demand, NTNs can employ cell- free MIMO with full frequency reuse schemes to maximize the spectral efficiency of the system. However, such technique can be strongly affected by channel aging, impacting their application to Low Earth Orbit (LEO)-based NTNs. Aiming at counteracting this effect, we present in this paper a lightweight Artificial Intelligence (AI) model for Channel State Information (CSI) prediction. To predict the propagation channel, the proposed algorithm learns its temporal statistics, e.g., the Line-of-Sight (LoS) shadowing correlation, from data. The model then applies the corrections to the feedback CSI, minimizing the difference with respect to the propagation channel encountered at transmission time. System-level analyses on a LEO-based CF-MIMO system report an improvement of the per-user capacity by up to 15% and a reduction of the outage probability when predicted CSI are used instead of aged channel coefficients.","1948-3252","979-8-3503-9318-7","10.1109/SPAWC60668.2024.10694298","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10694298","Cell-free MIMO;Channel Prediction;Artificial Intelligence;Non-Terrestrial Networks","6G mobile communication;Wireless communication;Spectral efficiency;Signal processing algorithms;Probability;Aging;Numerical models;Power system reliability;Artificial intelligence;Capacity planning","","","","14","IEEE","7 Oct 2024","","","IEEE","IEEE Conferences"
"IREE Oriented Green 6G Networks: A Radial Basis Function-Based Approach","T. Yu; P. Huang; S. Zhang; X. Chen; Y. Sun; X. Wang","Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai University, Shanghai, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai University, Shanghai, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai University, Shanghai, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai University, Shanghai, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai University, Shanghai, China; Department of Communication Science and Engineering, Key Laboratory for Information Science of Electromagnetic Waves (MoE), Fudan University, Shanghai, China",IEEE Journal on Selected Areas in Communications,"17 Oct 2024","2024","42","11","3246","3261","In order to provide design guidelines for energy efficient 6G networks, we propose a novel radial basis function (RBF) based optimization framework to maximize the integrated relative energy efficiency (IREE) metric. Different from the conventional energy efficient optimization schemes, we maximize the transformed utility for any given IREE using spectrum efficiency oriented RBF network and gradually update the IREE metric using proposed Dinkelbach’s algorithm. The existence and uniqueness properties of RBF networks are provided, and the convergence conditions of the entire framework are discussed as well. Through some numerical experiments, we show that the proposed IREE outperforms many existing SE or EE oriented designs and find a new Jensen-Shannon (JS) divergence constrained region, which behaves differently from the conventional EE-SE region. Meanwhile, by studying IREE-SE trade-offs under different traffic requirements, we suggest that network operators shall spend more efforts to balance the distributions of traffic demands and network capacities in order to improve the IREE performance, especially when the spatial variations of the traffic distribution are significant.","1558-0008","","10.1109/JSAC.2024.3431521","National Key Research and Development Program of China(grant numbers:2022YFB2902304); National Natural Science Foundation of China (NSFC)(grant numbers:62071284); Innovation Program of Shanghai Municipal Science and Technology Commission(grant numbers:20JC1416400,21ZR1422400,20511106603); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605762","Green networks;energy efficiency;6G networks;radial basis function;EE-SE trade-off","Energy efficiency;Measurement;6G mobile communication;Radial basis function networks;Optimization;Training;Resource management","","","","53","IEEE","22 Jul 2024","","","IEEE","IEEE Journals"
"Distributed Sensing, Computing, Communication, and Control Fabric: A Unified Architecture for New 6G Era","D. Vukobratović; N. Bartzoudis; M. Ghassemian; F. B. Saghezchi; P. Li; A. Aijaz; R. Martinez; X. An; R. R. V. Prasad; H. Lüders; S. Mumtaz","Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Castelldefels, Spain; Huawei Technologies Duesseldorf GmbH, Munich, Germany; Instituto de Telecomunicações, University of Aveiro, Aveiro, Portugal; Bristol Research & Innovation Laboratory, Toshiba Europe Ltd., UK; Bristol Research & Innovation Laboratory, Toshiba Europe Ltd., UK; Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Castelldefels, Spain; Huawei Technologies Duesseldorf GmbH, Munich, Germany; Technical University of Delft, Netherlands; Telefónica Germany GmbH & Co. OHG, Germany; Instituto de Telecomunicações, University of Aveiro, Aveiro, Portugal",2024 IEEE Wireless Communications and Networking Conference (WCNC),"3 Jul 2024","2024","","","1","6","With the advent of the multimodal immersive communication system, people can interact with each other using multiple devices for sensing, communication and/or application level control either onsite or remotely. As a breakthrough concept, a distributed sensing, computing, communications, and control (DS3C) fabric is introduced in this paper for provisioning 6G services in multi-tenant environments in a unified manner. The DS3C fabric can be further enhanced by natively incorporating intelligent algorithms for network automation and managing networking, computing, and sensing resources efficiently to serve vertical use cases with extreme and/or conflicting requirements. As such, the paper proposes a novel end-to-end 6G system architecture with enhanced intelligence spanning across different network, computing, and business domains, identifies vertical use cases and presents an overview of the relevant standardisation and pre-standardisation landscape.","1558-2612","979-8-3503-0358-2","10.1109/WCNC57260.2024.10570746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570746","6G architecture;vertical requirements;multimodal distributed communication;distributed sensing and control;distributed computing;metaverse;DS3C fabric","6G mobile communication;Automation;Communication systems;Systems architecture;Computer architecture;Fabrics;Sensors","","1","","9","IEEE","3 Jul 2024","","","IEEE","IEEE Conferences"
"AIaaS for ORAN-based 6G Networks: Multi-time Scale Slice Resource Management with DRL","S. Mhatre; F. Adelantado; K. Ramantas; C. Verikoukis","Universitat Politecnica de Catalunya, Barcelona, Spain; Universitat Oberta de Catalunya, Barcelona, Spain; Iquadrat Informatica S.L., Barcelona, Spain; University of Patras and ISI Athena, Greece",ICC 2024 - IEEE International Conference on Communications,"20 Aug 2024","2024","","","5407","5412","This paper addresses how to handle slice resources for 6G networks at different time scales in an architecture based on an open radio access network (ORAN). The proposed solution includes artificial intelligence (AI) at the edge of the network and applies two control-level loops to obtain optimal performance compared to other techniques. The ORAN facilitates programmable network architectures to support such multi-time scale management using AI approaches. The proposed algorithms analyze the maximum utilization of resources from slice performance to take decisions at the inter-slice level. Inter-slice intelligent agents work at a non-real-time level to reconfigure resources within various slices. Further than meeting the slice requirements, the intra-slice objective must also include the minimization of maximum resource utilization. This enables smart utilization of the resources within each slice without affecting slice performance. Here, each xApp that is an intra-slice agent aims at meeting the optimal quality of service (QoS) of the users, but at the same time, some inter-slice objectives should be included to coordinate intra- and inter-slice agents. This is done without penalizing the main intra-slice objective. All intelligent agents use deep reinforcement learning (DRL) algorithms to meet their objectives. We have presented results for enhanced mobile broadband (eMBB), ultra-reliable low latency (URLLC), and massive machine type communication (mMTC) slice categories.","1938-1883","978-1-7281-9054-9","10.1109/ICC51166.2024.10622601","Generalitat de Catalunya(grant numbers:2021 SGR 174); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10622601","DRL;ORAN;Slicing;RRM;eMBB;URLLC;mMTC;QoS;KPI","6G mobile communication;Massive machine type communications;Quality of service;Open RAN;Ultra reliable low latency communication;Network architecture;Minimization","","1","","16","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Advancing 6G Network Performance: AI/ML Framework for Proactive Management and Dynamic Optimal Routing","P. M. Tshakwanda; S. T. Arzo; M. Devetsikiotis","University of New Mexico, Albuquerque, NM, USA; University of New Mexico, Albuquerque, NM, USA; University of New Mexico, Albuquerque, NM, USA",IEEE Open Journal of the Computer Society,"3 Jun 2024","2024","5","","303","314","As 6G networks proliferate, they generate vast volumes of data and engage diverse devices, pushing the boundaries of traditional network management techniques. The limitations of these techniques underpin the need for a revolutionary shift towards AI/ML-based frameworks. This article introduces a transformative approach using our novel Speed-optimized LSTM (SP-LSTM) model, an embodiment of this crucial paradigm shift. We present a proactive strategy integrating predictive analytics and dynamic routing, underpinning efficient resource utilization and optimal network performance. This innovative, two-tiered system combines SP-LSTM networks and Reinforcement Learning (RL) for forecasting and dynamic routing. SP-LSTM models, boasting superior speed, predict potential network congestion, enabling preemptive action, while RL capitalizes on these forecasts to optimize routing and uphold network performance. This cutting-edge framework, driven by continuous learning and adaptation, mirrors the evolving nature of 6G networks, meeting the stringent requirements for ultra-low latency, ultra-reliability, and heterogeneity management. The expedited training and prediction times of SP-LSTM are game-changers, particularly in dynamic network environments where time is of the essence. Our work marks a significant stride towards integrating AI/ML in future network management, highlighting AI/ML's exceptional capacity to outperform conventional algorithms and drive innovative performance in 6G network management.","2644-1268","","10.1109/OJCS.2024.3398540","National Science Foundation; New Mexico SMART Grid Center - EPSCoR Cooperative(grant numbers:OIA-175720); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10522874","Artificial intelligence (AI);machine learning (ML);long short-term memory (LSTM);speed-optimized LSTM (SP-LSTM);6G networks;network management;predictive analytics;dynamic routing;reinforcement learning (RL);network congestion forecasting;resource utilization;ultra-low latency;ultra-reliability;heterogeneity management;AI/ML implementation;algorithm performance optimization;network performance optimization;proactive network strategies;next-generation networks;evolutionary network solutions","Routing;6G mobile communication;Long short term memory;Predictive analytics;Heuristic algorithms;Real-time systems;Logic gates","","","","37","CCBY","8 May 2024","","","IEEE","IEEE Journals"
"Toward Bridging the FL Performance-Explainability Tradeoff: A Trustworthy 6G RAN Slicing Use-Case","S. Roy; H. Chergui; C. Verikoukis","Iquadrat Informatica and Universitat Politècnica de Catalunya (UPC), Barcelona, Spain; i2CAT Foundation, Barcelona, Spain; University of Patras and ISI/ATHENA, Patras, Greece",IEEE Transactions on Vehicular Technology,"22 Jul 2024","2024","73","7","10529","10538","In the context of sixth-generation (6G) networks, where diverse network slices coexist, the adoption of AI-driven zero-touch management and orchestration (MANO) becomes crucial. However, ensuring the trustworthiness of AI black-boxes in real deployments is challenging. Explainable AI (XAI) tools can play a vital role in establishing transparency among the stakeholders in the slicing ecosystem. But there is a trade-off between AI performance and explainability, posing a dilemma for trustworthy 6G network slicing because the stakeholders require both highly performing AI models for efficient resource allocation and explainable decision-making to ensure fairness, accountability, and compliance. To balance this trade off and inspired by the closed loop automation and XAI methodologies, this paper presents a novel explanation-guided in-hoc federated learning (FL) approach where a constrained resource allocation model and an explainer exchange—in a closed loop (CL) fashion—soft attributions of the features as well as inference predictions to achieve a transparent 6G network slicing resource management in a RAN-Edge setup under non-independent identically distributed (non-IID) datasets. In particular, we quantitatively validate the faithfulness of the explanations via the so-called attribution-based confidence metric that is included as a constraint to guide the overall training process in the run-time FL optimization task. In this respect, Integrated-Gradient (IG) as well as Input × Gradient and SHAP are used to generate the attributions for our proposed in-hoc scheme, wherefore simulation results under different methods confirm its success in tackling the performance-explainability trade-off and its superiority over the unconstrained Integrated-Gradient post-hoc FL baseline.","1939-9359","","10.1109/TVT.2024.3364363","6G-BRICKS(grant numbers:101096954); ADROIT6G(grant numbers:101095363); MINECO, Spain; EU NextGenerationEU/PRTR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430406","6G;closed-loop;federated learning;game theory;in-hoc;post-hoc;proxy-Lagrangian;resource allocation;XAI;ZSM","Artificial intelligence;6G mobile communication;Resource management;Measurement;Training;Biological system modeling;Optimization","","6","","25","IEEE","9 Feb 2024","","","IEEE","IEEE Journals"
"AI-fuelled Dimensioning and Optimal Resource Allocation of 5G/6G Wireless Communication Networks","P. Papaioannou; I. Pastellas; C. Tranoris; S. Karagiorgou; S. Denazis","Electrical & Computer Eng. Dept., University of Patras, Greece; UBITECH LTD, Thessalias 8 and Etolias 10, Chalandri, Athens, Greece; Electrical & Computer Eng. Dept., University of Patras, Greece; UBITECH LTD, Thessalias 8 and Etolias 10, Chalandri, Athens, Greece; Electrical & Computer Eng. Dept., University of Patras, Greece",2024 IEEE International Mediterranean Conference on Communications and Networking (MeditCom),"12 Aug 2024","2024","","","413","418","The advent of 5G/6G broadband wireless networks brings several challenges with respect to optimal resource planning and allocation. In a heavily interconnected network of wireless devices, and users along with their equipment, all compete for scarce resources which further emphasizes the importance of fair and efficient allocation of those resources for the proper functioning of the networks. This paper tackles a crucial and timely topic, i.e., understand the various factors involved for optimizing network performance and ensuring fair access for different users, applications and devices. Integrating Machine Learning (ML) and Artificial Intelligence (AI) for predictive dimensioning and pattern mining over the network traffic can enable dynamic and intelligent resource allocation, increase network capacity, enhance the underlying capabilities between users and core network, and better correlate the Quality of Service (QoS). The scientific contribution of this paper entails novel AI models harvesting data from real-world 5G/6G testbeds offered through the AI as a Service (AIaaS) paradigm to enable model reuse and seamless exploitation for different 5G/6G application requirements and learning tasks.","","979-8-3503-0948-5","10.1109/MeditCom61057.2024.10621426","Horizon Europe; CODE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10621426","","Wireless networks;User-generated content;Quality of service;Telecommunication traffic;Predictive models;Data models;Planning","","","","16","IEEE","12 Aug 2024","","","IEEE","IEEE Conferences"
"Edge Computation Offloading With Content Caching in 6G-Enabled IoV","X. Zhou; M. Bilal; R. Dou; J. J. P. C. Rodrigues; Q. Zhao; J. Dai; X. Xu","School of Software, Nanjing University of Information Science and Technology, Nanjing, China; Department of Computer Engineering, Hankuk University of Foreign Studies, Yongin-si, Gyeonggi-do, South Korea; Faculty of Mathematics, University of Waterloo, Waterloo, ON, Canada; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; Geospatial Information Engineering Research Center, College of Information Science and Technology, Xinjiang Production and Construction Corps, Shihezi University, Shihezi, China; Geospatial Information Engineering Research Center, College of Information Science and Technology, Xinjiang Production and Construction Corps, Shihezi University, Shihezi, China; School of Software, Nanjing University of Information Science and Technology, Nanjing, China",IEEE Transactions on Intelligent Transportation Systems,"18 Apr 2024","2024","25","3","2733","2747","Using the powerful communication capability of 6G, various in-vehicle services in the Internet of Vehicles (IoV) can be offered with low delay, which provide users with a high-quality driving experience. Edge computing in 6G-enabled IoV utilizes edge servers distributed at the edge of the road, enabling rapid responses to delay-sensitive tasks. However, how to execute computation offloading effectively in 6G-enabled IoV remains a challenge. In this paper, a Computation Offloading method with Demand prediction and Reinforcement learning, named CODR, is proposed. First, a prediction method based on Spatial-Temporal Graph Neural Network (STGNN) is proposed. According to the predicted demand, a caching decision method based on the simplex algorithm is designed. Then, a computation offloading method based on twin delayed deterministic policy gradient (TD3) is proposed to obtain the optimal offloading scheme. Finally, the effectiveness and superiority of CODR in reducing delay are demonstrated through a large number of simulation experiments.","1558-0016","","10.1109/TITS.2023.3239599","Natural Science Foundation of Jiangsu Province of China(grant numbers:BK20211284); Financial and Science Technology Plan Project of Xinjiang Production and Construction Corps(grant numbers:2020DB005); FCT/MCTES National Funds; EU Funds(grant numbers:UIDB/50008/2020); Brazilian National Council for Scientific and Technological Development—CNPq(grant numbers:313036/2020-9); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10034418","Internet of Vehicles;6G;caching;edge computing;computation offloading;reinforcement learning","6G mobile communication;Delays;Servers;Edge computing;Vehicle dynamics;Internet of Vehicles;Reinforcement learning","","24","","42","IEEE","31 Jan 2023","","","IEEE","IEEE Journals"
"Reconfigurable Intelligent Surfaces for 6G Non-Terrestrial Networks: Assisting Connectivity from the Sky","W. U. Khan; A. Mahmood; C. K. Sheemar; E. Lagunas; S. Chatzinotas; B. Ottersten","University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg",IEEE Internet of Things Magazine,"11 Jan 2024","2024","7","1","34","39","Sixth-generation (6G) non-terrestrial networks (NTNs) are advanced wireless communication systems that operate beyond traditional terrestrial networks. These networks utilize various technologies and platforms to provide flexible, enhanced connectivity and coverage. When operating at high frequency, ground user terminals require low-directional antennas, which experience poor link budgets from satellites and thus drive the quest for novel solutions. Reconfigurable Intelligent Surfaces (RISs) have recently emerged as a promising technology for 6G and beyond cellular systems. This article studies the potential of RIS-in-tegrated NTNs to revolutionize next-generation connectivity. First, it discusses the fundamentals of RIS technology. Secondly, it delves into reporting the recent advances in RIS-integrated NTNs. Subsequently, it presents a novel framework based on the current state-of-the-art for IRS-integrated NTNs with classical single connected diagonal RIS and fully connected beyond diagonal RIS architectures. Finally, the article highlights open challenges and future research directions to revolutionize the realm of RIS-integrated NTNs.","2576-3199","","10.1109/IOTM.001.2300208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10396846","","6G mobile communication;Wireless communication;Satellite antennas;Satellites;Low earth orbit satellites;Reconfigurable intelligent surfaces;Propagation losses","","6","","15","IEEE","11 Jan 2024","","","IEEE","IEEE Magazines"
"A Novel DRL Framework for Cross-Domain Network Scaling in 6G Networks","A. Bouroudi; A. Outtagarts; Y. Hadjadj-Aoul","Bell Labs Nokia Networks France, Paris, France; Bell Labs Nokia Networks France, Paris, France; INRIA Univ Rennes CNRS IRISA, Rennes, France",2024 IEEE 25th International Conference on High Performance Switching and Routing (HPSR),"20 Aug 2024","2024","","","118","123","The emergence of 6 G requires efficient management of heterogeneous networks and computational resources to achieve targeted end-to-end network automation, with slice orchestration as a key feature. Despite opportunities offered by the recent advances in network virtualization and distributed cloud infrastructures, these developments introduce complexity in the context of multi-domain networks. This paper presents a distributed horizontal scaling method that leverages deep reinforcement learning (DRL) to enhance network function orchestration (NFO) with intelligent scaling decisions, facilitating seamless cross-domain information exchange. Firstly, we develop a DRL agent designed to handle fluctuating traffic loads and generate scaling actions tailored for the considered network function (NF). The trained DRL agent is then integrated into a multi-domain message exchange scaling framework with traffic prediction capabilities. Moreover, a simulation testbed is developed to manipulate multi-domain topologies, customize network slices, and enable precise per-slice and per-domain scaling decisions. Our DRL-based solution outperforms the Horizontal Pod Autoscaling (HPA) heuristic used by Kubernetes, improving resource utilization and reducing data rate losses.","2325-5609","979-8-3503-6385-2","10.1109/HPSR62440.2024.10635964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10635964","Mutli-Domain Orchestration;Distributed Scaling;6G Network;Deep Reinforcement Learning","6G mobile communication;Training;Telecommunication traffic;Switches;Deep reinforcement learning;Routing;Topology","","","","16","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Proactive Caching With Distributed Deep Reinforcement Learning in 6G Cloud-Edge Collaboration Computing","C. Wu; Z. Xu; X. He; Q. Lou; Y. Xia; S. Huang","Institute of Software, Chinese Academy of Sciences, Beijing, China; College of Computer and Information Engineering, Henan Normal University, Xinxiang, China; College of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; College of Computer and Information Engineering, Henan Normal University, Xinxiang, China",IEEE Transactions on Parallel and Distributed Systems,"17 Jun 2024","2024","35","8","1387","1399","Proactive caching in 6G cloud-edge collaboration scenarios, intelligently and periodically updating the cached contents, can either alleviate the traffic congestion of backhaul link and edge cooperative link or bring multimedia services to mobile users. To further improve the network performance of 6G cloud-edge, we consider the issue of multi-objective joint optimization, i.e., maximizing edge hit ratio while minimizing content access latency and traffic cost. To solve this complex problem, we focus on the distributed deep reinforcement learning (DRL)-based method for proactive caching, including content prediction and content decision-making. Specifically, since the prior information of user requests is seldom available practically in the current time period, a novel method named temporal convolution sequence network (TCSN) based on the temporal convolution network (TCN) and attention model is used to improve the accuracy of content prediction. Furthermore, according to the value of content prediction, the distributional deep Q network (DDQN) seeks to build a distribution model on returns to optimize the policy of content decision-making. The generative adversarial network (GAN) is adapted in a distributed fashion, emphasizing learning the data distribution and generating compelling data across multiple nodes. In addition, the prioritized experience replay (PER) is helpful to learn from the most effective sample. So we propose a multivariate fusion algorithm called PG-DDQN. Finally, faced with such a complex scenario, a distributed learning architecture, i.e., multi-agent learning architecture is efficiently used to learn DRL-based methods in a manner of centralized training and distributed inference. The experiments prove that our proposal achieves satisfactory performance in terms of edge hit ratio, traffic cost and content access latency.","1558-2183","","10.1109/TPDS.2024.3406027","National Key R&D Program of China(grant numbers:2023YFC3008202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10540320","6G;distributed edge computing;proactive caching;deep reinforcement learning;multi-agent learning architecture","Costs;Training;6G mobile communication;Servers;Predictive models;Generative adversarial networks;Optimization","","","","29","IEEE","28 May 2024","","","IEEE","IEEE Journals"
"Advancements in AI for 6G Networks: Technology, Standardization, and Future Prospects","J. Alanya-Beltran; J. Silva-Cueva; B. Hermitaño-Atencio; F. Cardenas-Palominio; F. Alvarez-Huertas; C. Poma-Garcia","Department of Engineering, Universidad San Ignacio de Loyola, Lima; Academic Department of Electronics and Telematics, Universidad Nacional de Educación Enrique Guzmán y Valle, Lima; Department of Electronics and Telematics, Universidad Nacional de Educación, Enrique Guzmán y Valle, Lima; Science Department, Universidad Nacional de Educación, Enrique Guzmán y Valle, Lima; Science Department, Universidad Nacional Mayor de San Marcos, Lima; Postgraduate Department, Universidad Cesar Vallejo","2024 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)","25 Jul 2024","2024","","","1","5","The commercial development of fifth generation (5G) mobile phone networks has begun. These systems provide a plethora of new prospects to a variety of businesses, as well as new services and enhanced user experiences for users. Yet there are still a lot of obstacles for 5G. In order to address these challenges, international industrial, academic, and standards organizations have started researching sixth generation (6G) wireless communication networks. The integration of terrestrial, aerial, with underwater communications into a dependable, fast, and ultra-low latency network capable of supporting a large number of devices is anticipated with the advent of the sixth-generation (6G) communication network. GNDO is compared with numerous recently developed algorithms. Power consumption is a key issue in sustainable green 6G-IBN, and the proposed method is employed to save it. The suggested algorithm exhibits competitive performance and qualities, as evidenced by the experimental results paired with descriptive statistics.","","979-8-3503-8944-9","10.1109/ACCAI61061.2024.10602082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602082","Artificial Intelligence;6G;Networks;Technology;Standardization","6G mobile communication;Wireless communication;Performance evaluation;Underwater communication;Power demand;5G mobile communication;Standards organizations","","","","10","IEEE","25 Jul 2024","","","IEEE","IEEE Conferences"
"Deep-Learning-Based Resource Allocation for 6G NOMA-Assisted Backscatter Communications","V. D. Tuong; S. Cho","School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea",IEEE Internet of Things Journal,"24 Sep 2024","2024","11","19","32234","32243","The proliferation of Internet-of-Things applications has given rise to several challenges, including network congestion and high energy consumption. Among the promising technologies for beyond-5G networks, nonorthogonal multiple access (NOMA) and ambient backscatter communications (BackComs) stand out. These technologies enhance wireless access capacity and enable energy-efficient data sharing. In this study, we propose a novel energy-efficient resource allocation scheme for 6G NOMA-assisted BackCom networks. Our network model comprises a central reader (RD) and distributed backscatter devices (BDs) that harvest energy from incident signals to modulate useful data and reflect it toward the RD. To maximize energy efficiency (EE), we formulated a joint optimization problem of channel resource allocation and BDs’ reflection coefficients. However, solving this problem is challenging because of its nonconvexity and system dynamics. To address this issue, we developed a novel deep-learning-based algorithm that leverages the advantages of deep reinforcement learning. During training, we estimated the state components without relying on exact channel state information (CSI), which is computationally expensive. This estimation reduces the communication overhead raised in collecting CSI data. Extensive simulations were conducted to demonstrate the superiority of the proposed scheme. Simulation results show that the proposed scheme notably enhances EE compared to existing benchmarks. Specifically, improvements of approximately 30.3%, 41.7%, 6.0%, and 4.4% were observed when compared to the greedy approach, random approach, deep Q-Network, and successive convex approximation approach, respectively.","2327-4662","","10.1109/JIOT.2024.3424728","Ministry of Science and ICT (MSIT), Korea, under the Information Technology Research Center (ITRC) support Program Supervised by the Institute for Information Communications (IITP)(grant numbers:IITP-2024-RS-2022-00156353); National Research Foundation of Korea (NRF) Grants; Korean Government (MSIT)(grant numbers:RS-2023-00209125); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10587215","Backscatter communications (BackComs);deep reinforcement learning (DRL);energy-efficient communications;nonorthogonal multiple access (NOMA)","NOMA;Backscatter;Internet of Things;Optimization;Resource management;Throughput;6G mobile communication","","","","35","IEEE","5 Jul 2024","","","IEEE","IEEE Journals"
"Energy Maximization for Wireless Powered Communication Enabled IoT Devices With NOMA Underlaying Solar Powered UAV Using Federated Reinforcement Learning for 6G Networks","A. Jabbari; H. Khan; S. Duraibi; I. Budhiraja; S. Gupta; M. Omar","College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India; School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India; Information Technology and Management, Illinois Institute of Technology, Warrenville, IL, USA",IEEE Transactions on Consumer Electronics,"29 Apr 2024","2024","70","1","3926","3939","The Internet of Things (IoT) depends primarily on low-cost wireless sensors with limited energy capacity to allow pervasive monitoring and intelligent control. Nevertheless, unmanned aerial vehicle (UAV) can be used to connect remote terminals that are outside wireless coverage to IoT networks. This solution provides a means of extending the reach of IoT networks, offering more opportunities for monitoring and control. Despite this benefit, the UAV also suffers from low capacity onboard battery. To overcome these problems, solar energy is integrated with UAV, and wireless-powered communication (WPC) techniques are used for IoT terminals. Also, the non-orthogonal multiple access (NOMA) technique can be employed to address the massive connectivity issue of IoT terminals. By leveraging these advantages, we jointly optimize the three-dimensional UAV trajectory and time allocation for WPC powered IoT devices (IoTDs) underlaying solar-powered UAV. To achieve the target, in this paper, introduces a multiagent federated reinforcement learning (MAFAL) algorithm, which concentrates on maximizing energy efficiency (EE) while minimizing energy consumption, guaranteeing quality of service (QoS), fairness, and trajectory planning. The proposed algorithm aims to optimize the overall performance of the system by learning from the collective experience of multiple agents. Simulation result demonstrated that the proposed method achieves 56.84%, 68.45%, and 73.63% higher EE as compared to MAD2PG, DDPG, and DQN, respectively.","1558-4127","","10.1109/TCE.2024.3357125","Deanship of Scientific Research, Jazan University through the Research Units Support Program(grant numbers:RUP2-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10412001","IoTDs;MAFAL;NOMA;solar energy;trajectory planning;time allocation;UAV;and WPC","Autonomous aerial vehicles;Internet of Things;Trajectory;NOMA;Solar energy;Wireless communication;Throughput","","4","","42","IEEE","22 Jan 2024","","","IEEE","IEEE Journals"
"Federated Learning for Computational Offloading and Resource Management of Vehicular Edge Computing in 6G-V2X Network","M. K. Hasan; N. Jahan; M. Z. A. Nazri; S. Islam; M. Attique Khan; A. I. Alzahrani; N. Alalwan; Y. Nam","Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia; Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia; Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia; Institute of Computer Science and Digital Innovation, UCSI University, Kuala Lumpur, Malaysia; Department of Computer Science, HITEC University, Taxila, Pakistan; Computer Science Department, Community College, King Saud University, Riyadh, Saudi Arabia; Computer Science Department, Community College, King Saud University, Riyadh, Saudi Arabia; Department of Computer Science and Engineering, ICT Convergence Research Center, Soonchunhyang University, Asan, South Korea",IEEE Transactions on Consumer Electronics,"29 Apr 2024","2024","70","1","3827","3847","The Sixth Generation network (6G) can support autonomous driving along with various vehicular applications like Vehicular Edge Computing (VEC), a distributed computing architecture for connected autonomous vehicles. Computational offloading and resource management of Vehicular Edge Computing can help sort out some issues, such as high communication costs, privacy protection, an excessively long training process, etc., by proposing an efficient training model of the Federated Learning for computational offloading and resource management in a vehicular environment. Two research issues are highlighted in this paper. One problem is related to the current offloading system: the smart structure and operating system. Consistent access to cloud computing services, regardless of the installed operating system or used hardware, is still challenging. Another issue is related to security and privacy. Security and privacy are two important features that should be maintained in cloud data centers and data transmission during offloading and resource management. In this survey paper, a system is going to be proposed which will give a partial solution for these issues. The proposed solution, which is found while conducting this review, offers a system that can train a model and help update the edge devices’ information. The entire edge cloud system can provide updated information for edge devices and can solve the difficulties of getting some key information necessary for model-related optimization. This also can enhance the effectiveness of the frameworks of the 6G-V2X network for communication.","1558-4127","","10.1109/TCE.2024.3357530","Researchers Supporting Project(grant numbers:RSP2024R157); King Saud University, Riyadh, Saudi Arabia; National Research Foundation of Korea(NRF); Korea Government (MSIT)(grant numbers:RS-2023-00218176); Soonchunhyang University Research Fund; Universiti Kebangsaan Malysia Under Research(grant numbers:GUP-2023-010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10415079","Computation offloading;resource management;security and privacy;vehicular edge computing;communication costs","Edge computing;6G mobile communication;Resource management;Federated learning;Cloud computing;Vehicle-to-everything;Security","","19","","104","IEEE","26 Jan 2024","","","IEEE","IEEE Journals"
"An Overview of the Architecture and Challenges of RTM System by Integrating 6G Technology with UAV Network","A. A. M. Shah Sadman; A. Kar; A. R. Emon; M. A. Mubin","Department of EECE, Military Institute of Science and Technology, Dhaka, Bangladesh; Department of EECE, Military Institute of Science and Technology, Dhaka, Bangladesh; Department of EECE, Military Institute of Science and Technology, Dhaka, Bangladesh; Department of EECE, Military Institute of Science and Technology, Dhaka, Bangladesh",2024 3rd International Conference on Advancement in Electrical and Electronic Engineering (ICAEEE),"24 Jun 2024","2024","","","1","6","Due to the advent of 6G communication technology, research interest on unmanned aerial vehicle (UAV) has spiked significantly because it has promised to deliver more robust and reliable device-to-device communication. Also, 6G promises to provide better throughput, higher data rates and lower latency than existing technology. By utilizing the offerings of 6G, UAV traffic management (UTM) system is envisioned which covers the aerial as well as ground vehicles. Because of many incidents on the road such as accidents, blockade, traffic jam, proper monitoring is essential but present traffic management systems lack in many aspects due to its static nature. A subset of UTM is the road traffic management (RTM) system that solely focuses on maintaining an optimized and efficient traffic flow of the land vehicles. Proper integration of UAVs with the 6G terrestrial infrastructure and technologies such as digital twin, massive MIMO, artificial intelligence, block chain etc. will lead to a dynamic RTM system. This paper provides an overview of the UAV-RTM system in the presence of 6G technology. In order to do that, a review of the UAV-RTM process and the integration of space and ground devices are presented. The paper also suggests some 6G technologies for RTM architecture that will leverage the performance of RTM. Finally, it describes some technical difficulties that an UAV-RTM system may face in future.","","979-8-3503-8828-2","10.1109/ICAEEE62219.2024.10561778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10561778","6G;road traffic management;ISTN;digital twin;WPT;blockchain;IRS;massive MIMO","6G mobile communication;Autonomous aerial vehicles;Road traffic;Land vehicles;Blockchains;Vehicle dynamics;Artificial intelligence","","","","25","IEEE","24 Jun 2024","","","IEEE","IEEE Conferences"
"Holographic MIMO With Integrated Sensing and Communication for Energy-Efficient Cell-Free 6G Networks","A. Adhikary; A. Deb Raha; Y. Qiao; W. Saad; Z. Han; C. Seon Hong","Department of Computer Science and Engineering, School of Computing, Kyung Hee University, Yongin, Republic of Korea; Department of Artificial Intelligence, School of Computing, Kyung Hee University, Yongin, Republic of Korea; Department of Artificial Intelligence, School of Computing, Kyung Hee University, Yongin, Republic of Korea; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Computer Science and Engineering, School of Computing, Kyung Hee University, Yongin, Republic of Korea",IEEE Internet of Things Journal,"24 Sep 2024","2024","11","19","30617","30635","Sixth-generation wireless networks are required to satisfy the ever-increasing demands of diverse applications to guarantee power savings, energy efficiency (EE), and mass connectivity. To accomplish these goals, in this article, an artificial intelligence (AI)-based holographic MIMO (HMIMO)-empowered cell-free (CF) network is proposed while leveraging integrated sensing and communication (ISAC). The proposed AI-based framework allocates the desired power for beamforming by activating the required number of grids from the serving HMIMO base stations (BSs) in the CF network to serve the users. An optimization problem is formulated that maximizes the sensing utility function, which in turn maximizes the signal-to-interference-plus-noise ratio (SINR) of the received signal, the sensing SINR of the reflected echo signal, and EE, ensuring efficient power allocation. To solve the optimization problem, an AI-based framework is proposed to enable a decomposition of the NP-hard problem into two subproblems: 1) a sensing subproblem and 2) a power allocation subproblem. Initially, a variational autoencoder (VAE)-based scheme is utilized to solve the sensing subproblem that identifies the current location of the users with the sensing information. Then, a transformer-based mechanism is devised to allocate the desired power to users by activating the required grids from the serving HMIMO BSs in the CF network based on the sensing information achieved with the VAE-based scheme. Simulation results demonstrate that the proposed AI-based framework outperforms the long short-term memory and gated recurrent unit-based mechanisms, with cumulative power savings of 8.64% and 16.02%, and cumulative EE of 14.49% and 16.61%, accordingly, considering the ground truth values.","2327-4662","","10.1109/JIOT.2024.3411695","Institute of Information and communications Technology Planning and Evaluation (IITP) Grant; Korea Government (MSIT) (Evolvable Deep Learning Model Generation Platform for Edge Computing); National Research Foundation of Korea (NRF)(grant numbers:2019-0-01287); Grant funded by MSIT(grant numbers:RS-2023-00207816); IITP Grant; MSIT (Artificial Intelligence Innovation Hub)(grant numbers:2021-0-02068); IITP Grant; MSIT [Artificial Intelligence Convergence Innovation Human Resources Development (Kyung Hee University)](grant numbers:RS-2022-00155911); Information Technology Research Center (ITRC) Support Program supervised by the IITP(grant numbers:IITP-2023-RS-2023-00258649); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552365","Cell-free (CF) network;energy efficiency (EE);holographic MIMO (HMIMO);integrated sensing and communication (ISAC);sensing utility function (SUF)","Array signal processing;Energy efficiency;Resource management;MIMO communication;Signal to noise ratio;Internet of Things;Interference","","3","","67","IEEE","10 Jun 2024","","","IEEE","IEEE Journals"
"Intelligent Network Slicing for B5G and 6G: Resource Allocation, Service Provisioning, and Security","J. Wang; Y. Li; J. Liu; N. Kato","Northwestern Polytechnical University, P. R. China; Northwestern Polytechnical University, P. R. China; Northwestern Polytechnical University, P. R. China; Tohoku University, Japan",IEEE Wireless Communications,"14 Jun 2024","2024","31","3","271","277","B5G and 6G are designed to achieve break-throughs in mobile networks, and are expected to have features such as seamless global coverage, full virtualization, and ubiquitous intelligence. These promising features will spawn lots of new verticals and applications, creating an urgent need for on-demand networks. At this point, network slicing has been recognized as an excellent solution to this challenge due to its advantages of flexible customization and logical isolation. Driven by massive data, intelligent network slicing is further endowed with capabilities of real-time perception, accurate prediction, and adaptive decision making, which brings unlimited potential for the development of B5G/6G. To this end, we investigate the application and prospect of intelligent slicing for B5G/6G in three areas, that is, resource allocation, service provisioning, and security. We also list the specific problems in these areas according to each slice lifecycle phase. In addition, a case study of using reinforcement learning for slice admission control is provided to improve the slice admission rate under limited resources and illustrate the advantages of intelligent network slicing.","1558-0687","","10.1109/MWC.021.2200589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10558834","","6G mobile communication;Intelligent networks;Network slicing;Admission control;Decision making;Reinforcement learning;Real-time systems;5G mobile communication;Wireless networks","","","","15","IEEE","14 Jun 2024","","","IEEE","IEEE Magazines"
"A Development of Dynamic End-To-End Slicing Network Along with the Offline SLA-Method Integrated with Deep Learning for 5G/6G Networks","A. Khalid; R. G. Anand; A. Malviya","Department of IT, M. Tech Integrated Noida Institute of Engineering & Technology, Greater Noida, Uttar Pradesh, India; Department of Management, School of Mangement - UG, JAIN (Deemed to be University), Bangalore, Karnataka, India; Department of uGDX, ATLAS SkillTech University, Maharashtra, India","2024 1st International Conference on Innovative Sustainable Technologies for Energy, Mechatronics, and Smart Systems (ISTEMS)","25 Jun 2024","2024","","","1","5","Using SDN, or software-defined networking, and Network Function Virtualization, or (NFV), we address the problem of resource provisioning in fifth-generation (5G) networks to enable end-to-end dynamic slicing. The core of our method is to dynamically assign separate portions of Physical Resource Bricks (PRBs), basic processing resources, transport capacity, and components like The information Forwarding Elements (DFE) plus network connections to tenants, logical operators of different slices. We use large datasets of key performance indicators (also known as KPIs) taken from a live mobile phone network fitted with traffic sensors in order to create a forecast model for the traffic of slices. We offer a technique that makes use of a soft-gated Randomised Unit (GRU) based low-complexity slices traffic prediction. Furthermore, we build joint multi-slice DNN s (deep neural networks) for each virtual network role and train them to predict the needed resources, guaranteeing adherence to two crucial service level contracts (SLAs): resource bounds-based SLA and violation rate-based SLA. We present dataset-dependent generalised non-convex constraints as a solution to the difficulty of optimisation challenges related to DNNs. The offline optimisation procedure of the DNNs, which is solved using a non-zero summing two-player game strategy, smoothly incorporates these limitations. Throughout our methodology, we stress the importance of underlying hyperparameters that in striking a balance between the trade-off between overstocking and preserving slices' isolation. Lastly, we do a thorough closed-form analysis including reliability theory in order to determine the bottom limit of the reliable convergent probability. In addition, we investigate how the violation rate affects this convergence probability, offering important information on the dependability of our suggested system.","","979-8-3503-8424-6","10.1109/ISTEMS60181.2024.10560180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10560180","SDN;NFV;5G Networks;Dynamic Slicing;Resource Provisioning;Physical Resource Bricks (PRBs);Deep Learning;Traffic Prediction;Service Level Agreements (SLAs) and Non-Convex Constraints","Deep learning;Artificial neural networks;Reliability theory;Predictive models;Dynamic scheduling;Aerodynamics;Network function virtualization","","","","44","IEEE","25 Jun 2024","","","IEEE","IEEE Conferences"
"Efficient End–Edge–Cloud Task Offloading in 6G Networks Based on Multiagent Deep Reinforcement Learning","H. She; L. Yan; Y. Guo","College of Telecommunications and Information Engineering, the Engineering Research Center of Health Service System Based on Ubiquitous Wireless Networks, Ministry of Education, Edge Intelligence Research Institute, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China; College of Telecommunications and Information Engineering, the Engineering Research Center of Health Service System Based on Ubiquitous Wireless Networks, Ministry of Education, Edge Intelligence Research Institute, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China; College of Telecommunications and Information Engineering, the Engineering Research Center of Health Service System Based on Ubiquitous Wireless Networks, Ministry of Education, Edge Intelligence Research Institute, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China",IEEE Internet of Things Journal,"22 May 2024","2024","11","11","20260","20270","With the progressive evolution of the sixth-generation (6G) network, an array of diverse application tasks is experiencing a steady surge, consequently intensifying the computational pressure. However, even with highly optimized task offloading approaches, ensuring overall service quality for rapidly expanding network applications remains challenging due to hardware resource limitations. This article proposes a deep reinforcement learning-based algorithm utilizing a multiagent approach in the end–edge–cloud architecture for 6G networks. The offloading issue can be reformulated to a decentralized partially observable Markov decision process, which transfers the NP-hard problem. We design an efficient algorithm based on multiagent deep deterministic policy gradient (MADDPG) to observe the states of user equipments (UEs), edge servers, and cloud servers, thereby reducing offloading delay and energy consumption. Numerical results demonstrate that our proposed algorithm demonstrates superior performance compared to conventional and state-of-the-art approaches.","2327-4662","","10.1109/JIOT.2024.3372614","Frontier Leading Technology Basic Research Project of Jiangsu Province(grant numbers:BK20202001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10477307","6G;end–edge–cloud;multiagent deep reinforcement learning (MADRL);task offloading","Task analysis;6G mobile communication;Servers;Computational modeling;Cloud computing;Resource management;Delays","","","","45","IEEE","20 Mar 2024","","","IEEE","IEEE Journals"
"AI-Enhanced Quantum-Secured IoT Communication Framework for 6G Cognitive Radio Networks","P. Deepanramkumar; A. Helen Sharmila","School of Computer Science and Engineering, VIT-AP University, Amaravati, Andhra Pradesh, India; School of Computer Science and Engineering, VIT-AP University, Amaravati, Andhra Pradesh, India",IEEE Access,"10 Oct 2024","2024","12","","144698","144709","The advent of 6G wireless communication promises improvements in signal coverage, data rates, and latency, addressing increased connectivity demands due to the proliferation of 5G, IoT, and augmented reality. This paper introduces a Quantum-Secured IoT Communication Framework designed for 6G Cognitive Radio Networks (CRNs) in order to cater to the growing need for dependable and protected connectivity. Noteworthy aspects of this framework encompass dual-layer authentication utilizing Quantum Key Distribution (QKD) and Public Key Infrastructure (PKI), secured spectrum access regulations, and efficient beamforming strategies. Moreover, the framework employs a Reinforcement Learning-based Ensemble Regression (RL-ER) model for spectrum sensing and a Multi-Layer Perceptron with Kalman Filter (MLP-KF) for Channel State Information (CSI) prediction. Simulations demonstrate that the framework significantly improves prediction accuracy, encryption and decryption times, and error rates, thereby enhancing IoT network performance with better signal coverage, reduced latency, and robust security.","2169-3536","","10.1109/ACCESS.2024.3471711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10701274","6G wireless communication;cognitive radio networks (CRNs);quantum key distribution (QKD);reinforcement learning-based ensemble regression (RL-ER);multi-layer perceptron with Kalman filter (MLP-KF)","Sensors;6G mobile communication;Wireless communication;Cognitive radio;Signal to noise ratio;Array signal processing;Reliability;Internet of Things;Interference;Accuracy;Quantum key distribution;Reinforcement learning","","","","32","CCBYNCND","1 Oct 2024","","","IEEE","IEEE Journals"
"Challenges and Constraints of 5G: Transformation and Prospects for 6G Era","S. Aggarwal; D. Mehrotra; A. Garg; S. Thakur","Amity School of Engineering and Technology, Amity University, Noida, India; Amity School of Engineering and Technology, Amity University, Noida, India; University of Bolton, Greater Manchester, UK; Amity School of Engineering and Technology, Amity University, Noida, India",2024 1st International Conference on Advanced Computing and Emerging Technologies (ACET),"29 Oct 2024","2024","","","1","7","Fifth generation technology(5G) is available in several countries with more than 1.5 million users. It’s wireless communication through which many applications are integrated. With the rapid growth of more and more of the 5G network, many limitations have been found. Certain limitations regarding security and privacy were familiarized due to which 6G networks of next generation provide the solutions to overcome 5G. Whenever communications take place, human possibilities will depend on a set of security technology enablers. The recent 6G effort is presented in relation to privacy as well as security limitations of 5G. Knowledge extraction was not reliable in 5G, so will work on AI/ML implementation through federated learning. The 6G cyber security threats will be defined. 6G architecture breaks up how it will work when it will have multiple stakeholders. This paper also defines how the various domains of privacy, trust, cyber-resilience are decomposed. In short, here we will explore various 6G security Technologies which are revolutionizing..","","979-8-3503-6772-0","10.1109/ACET61898.2024.10730012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10730012","Knowledge Extraction;Blockchain;federated learning;5G;applications","6G mobile communication;Wireless communication;Privacy;5G mobile communication;Federated learning;Security;Stakeholders;Reliability;Computer crime;Next generation networking","","","","15","IEEE","29 Oct 2024","","","IEEE","IEEE Conferences"
"Split Learning in 6G Edge Networks","Z. Lin; G. Qu; X. Chen; K. Huang","University of Hong Kong, China; University of Hong Kong, China; University of Hong Kong, China; University of Hong Kong, China",IEEE Wireless Communications,"6 Aug 2024","2024","31","4","170","176","With the proliferation of distributed edge computing resources, the 6G mobile network will evolve into a network for connected intelligence. Along this line, the proposal to incorporate federated learning into the mobile edge has gained considerable interest in recent years. However, the deployment of federated learning faces substantial challenges as massive resource-limited loT devices can hardly support on-device model training. This leads to the emergence of split learning (SL) which enables servers to handle the major training workload while still enhancing data privacy. In this article, we offer a brief overview of SL and articulate its seamless integration with wireless edge networks. We begin by illustrating the tailored 6G architecture to support split edge learning (SEL). Then, we examine the critical design issues for SEL, including resource-efficient learning frameworks and resource management strategies under a single edge server. Furthermore, from a networking perspective, we expand the scope to multi-edge scenarios, exploring multi-edge collaboration and model placement/migration. Finally, we discuss open problems for SEL, including convergence analysis, asynchronous SL, and label privacy preservation.","1558-0687","","10.1109/MWC.014.2300319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10529950","","Computational modeling;Training;6G mobile communication;Data models;Servers;Resource management;Federated learning","","9","","15","IEEE","13 May 2024","","","IEEE","IEEE Magazines"
"Task-Oriented 6G Native-AI Network Architecture","Y. Yang; J. Wu; T. Chen; C. Peng; J. Wang; J. Deng; X. Tao; G. Liu; W. Li; L. Yang; Y. He; T. Yang; A. H. Aghvami; F. Eliassen; S. Dustdar; D. Niyato; W. Sun; Y. Xu; Y. Yuan; J. Xie; R. Li; C. Dai","The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Huawei Technologies Company, Ltd., Shenzhen, China; China Mobile Research Institute, Beijing, China; Huawei Technologies Company, Ltd., Shenzhen, China; Huawei Technologies Company, Ltd., Shenzhen, China; China Mobile Research Institute, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; China Mobile Research Institute, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; ZTE Corporation, Nanjing, China; Research Institute of China Telecom, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; King’s College London, London, U.K; University of Oslo, Oslo, Norway; TU Wien, Vienna, Austria; Nanyang Technological University, Jurong West, Singapore; CICT Mobile Communication Technology Company, Ltd., Beijing, China; Beijing OPPO Telecommunications Corporation, Dongguan, China; Vivo Mobile Communication Company, Ltd., Dongguan, China; University of North Carolina at Charlotte, Charlotte, NC, USA; Zhejiang University, Hangzhou, China; Chongqing University of Posts and Telecommunications, Chongqing, China",IEEE Network,"19 Apr 2024","2024","38","1","219","227","The vision for 6G networks is to offer pervasive intelligence and internet of intelligence, in which the networks natively support artificial intelligence (AI), empower smart applications and scenarios in various fields, and create a “ubiquitous-intelligence” world. In this vision, the traditional session-oriented architecture cannot achieve flexible per-user customization, ultimate performance, security and reliability required by future AI services.","1558-156X","","10.1109/MNET.2023.3321464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10273257","","Artificial intelligence;Task analysis;6G mobile communication;Collaboration;Quality of service;Computational modeling;Computer architecture","","5","","15","IEEE","6 Oct 2023","","","IEEE","IEEE Magazines"
"Deep Learning Based Energy, Spectrum, and SINR-Margin Tradeoff Enabled Resource Allocation Strategies for 6G","V. Pathak; R. Chethan; R. J. Pandya; S. Iyer; V. Bhatia","Indian Institute of Technology Dharwad, Dharwad, Karnataka, India; Indian Institute of Technology Kanpur, Kanpur, Uttar Pradesh, India; Indian Institute of Technology Dharwad, Dharwad, Karnataka, India; Department of Electronics and Communication, KLE Technological University Dr. MSSCET, Belagavi, Karnataka, India; School of Electronic and Information Engineering, Soochow University, Suzhou, China",IEEE Access,"30 May 2024","2024","12","","74024","74044","In the rapidly evolving landscape of wireless communication systems, the forthcoming sixth-generation technology aims to achieve remarkable milestones, including ultra-high data rates and improved Spectrum Efficiency (SE), Energy Efficiency (EE), and quality of service. However, a key challenge lies in the transmission at Terahertz frequencies, which entails significant signal loss, resulting in reduced signal-to-interference and noise ratio margins ( $\Gamma $ ). Increased transmit power can ameliorate  $\Gamma $  and SE, thereby sacrificing EE. Consequently, it necessitates strategic Resource Allocation (RA) to uphold an optimal trade-off amid SE, EE and  $\Gamma $ . In this paper, we propose a series of RA strategic algorithms harnessing the Transfer Learning, Growth-Share (GS) matrix, Game Theory (GT), and service priorities to tailor the aforementioned trade-off. This endeavour renders the network more intelligent, self-sufficient, and resilient. Furthermore, we have seamlessly integrated Device-to-Device communication scenarios into our proposed algorithms, enhancing SE and network capacity. The proposed integration aims to strengthen overall system performance and accommodate the evolving demands of future wireless networks. Our primary contribution lies in the development of the GS-GT-based Optimal PathFinder (GS-GTOPF) algorithm to identify optimal paths based on SE using Deep Neural Networks. Thereafter, we formulate an enhanced version of it by integrating service priorities (GS-GTOPF-SP). This refinement has been further advanced by reducing the Computational Time (CT), resulting in GS-GTOPF-SP-rCT. Further improvement is achieved by introducing the angle criterion (GS-GTOPF-SP-rCT- $\theta $ ). Extensive simulations demonstrate that angle criterion integrated algorithm, showcases a remarkable 76.12% reduction in CT while maintaining an accuracy surpassing 95% compared to GS-GTOPF. Moreover, prioritizing high-priority services leads to a significant enhancement of 12.97% and 62.95% in SE, 16.14% and 81.97% in EE, and 12.27% and 25.95% in  $\Gamma $  when compared to medium and low-priority services.","2169-3536","","10.1109/ACCESS.2024.3404473","Science and Engineering Research Board (SERB)(grant numbers:EEQ/2020/000047,SIR/2022/00095); University of Hradec Kralove, Faculty of Informatics and Management, Czech Republic Agency of Excellence(grant numbers:2204/2023); International Institute of Information Technology, Bangalore, Communications Enterprise Technologies (IIITB COMET) Foundation, established under the Advanced Communication Systems Vertical of the National Mission on Interdisciplinary Cyber-Physical Systems (NM-ICPS), Department of Science and Technology, Government of India, Chair Professorship from Driving Innovation through Simulation Hub for Technologies in Interdisciplinary Cyber-Physical Systems (DRISHTI CPS), Ministry of Education, Scheme for Promotion of Academic and Research Collaboration (MoE SPARC)(grant numbers:SPARC/2019-2020/P2264/SL); Soochow University, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537167","Terahertz (THz) communication;transferred learning (TL);energy efficiency (EE);spectrum efficiency (SE);signal to interference and noise ratio-margin (Γ);residual battery indicator (RBI)","6G mobile communication;Interference;Device-to-device communication;Energy efficiency;Wireless networks;Resource management;Terahertz communications;Transfer learning;Signal to noise ratio","","4","","56","CCBY","23 May 2024","","","IEEE","IEEE Journals"
"Multi-agent Cross-domain Traffic Engineering for Diverse Service Requirements in 6G Networks","Y. Ren; X. Lyu; X. Tao","National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Beijing, China",2024 IEEE/CIC International Conference on Communications in China (ICCC),"24 Sep 2024","2024","","","455","460","Cross-domain traffic engineering, which aims to optimize traffic flow across various network domains, is the key technique for meeting the diverse Quality of Service (QoS) requirements of various emerging 6 G applications, such as holographic communication, immersive XR, and intelligent interaction. Existing researches on traffic engineering have leveraged reinforcement learning to foster efficient traffic routing and resource management. However, these techniques typically require full knowledge of network conditions at a centralized coordinator. Such a centralized setting may not be readily applicable to the cross-domain characteristic of large-scale 6G networks. This paper proposes a collaborative multi-agent reinforcement learning approach for multi-priority traffic engineering. The joint optimization of cross-domain traffic routing is decomposed into two sub-problems: inter-domain traffic planning and intra-domain routing. We develop an A3C-based multi-agent reinforcement learning approach for solving the inter-domain sub-problem, and design a heuristic algorithm for the intra-domain sub-problem to reduce computational time complexity. Extensive experiments validate that our proposed algorithm can outperform the state-of-the-art in terms of routing effectiveness and implementability. We observed that our proposed approach can achieve up to a $\mathrm{1 2 . 5 \%}$ higher traffic successful delivery rate than the typical Border Gateway Protocol (BGP).","2377-8644","979-8-3503-7841-2","10.1109/ICCC62479.2024.10681865","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10681865","traffic engineering;deep reinforcement learning;distributed network","6G mobile communication;Reinforcement learning;Quality of service;Routing;Scheduling;Border Gateway Protocol;Planning","","","","13","IEEE","24 Sep 2024","","","IEEE","IEEE Conferences"
"Innovation Management in 6G Research: The Case of Hexa-X Project","D. Sabella; G. Nardini; P. Demestichas; S. Barmpounakis; D. -T. Phan-Huy; M. Merluzzi; E. G. Gamazo; A. Ramos; G. Landi; M. E. Leinonen; A. Pärssinen; A. Wolfgang","Intel Corporation, Italy; University of Pisa, Italy; WINGS ICT Solutions, Greece; WINGS ICT Solutions, Greece; Orange, France; Univ. Grenoble Alpes, France; ATOS, Spain; ATOS, Spain; Nextworks, Italy; University of Oulu, Finland; University of Oulu, Finland; Qamcom Research and Technology AB, Sweden",IEEE Communications Magazine,"19 Feb 2024","2024","62","2","142","149","Very often in the past, innovations from research communities have been disconnected from industry adoption, leading to a lack of exploitation of research projects. To overcome this issue, in the view of future 6G systems, the Hexa-X project is putting in place an innovation management (IM) process, aiming to facilitate and promote innovation opportunities based on project outcomes and ensure that all the ideas emerging from the project are captured and tracked, not “lost.” The focus of IM is on supporting the project to promptly identify innovations and engage with emerging innovation needs in the sector, for identifying gaps and potentials with strategic value. This article presents the IM approach in Hexa-X and selected innovations (some of which also awarded by the EC Innovation Radar), with particular emphasis on the technical aspects of these findings coupled with their identified strategic value for future 6G market exploitation.","1558-1896","","10.1109/MCOM.018.2300040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138338","","Technological innovation;6G mobile communication;Artificial intelligence;Innovation management;Business;Stakeholders;Industries","","3","","15","IEEE","29 May 2023","","","IEEE","IEEE Magazines"
"Network-Aided Intelligent Traffic Steering in 6G O-RAN: A Multi-Layer Optimization Framework","V. -D. Nguyen; T. X. Vu; N. T. Nguyen; D. C. Nguyen; M. Juntti; N. C. Luong; D. T. Hoang; D. N. Nguyen; S. Chatzinotas","College of Engineering and Computer Science, Hanoi, Vietnam; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg, Luxembourg; Centre for Wireless Communications, University of Oulu, Oulu, Finland; Department of Electrical and Computer Engineering, The University of Alabama in Huntsville, Huntsville, AL, USA; Centre for Wireless Communications, University of Oulu, Oulu, Finland; Faculty of Computer Science, Phenikaa University, Hanoi, Vietnam; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg, Luxembourg",IEEE Journal on Selected Areas in Communications,"16 Jan 2024","2024","42","2","389","405","To enable an intelligent, programmable and multi-vendor radio access network (RAN) for 6G networks, considerable efforts have been made in standardization and development of open RAN (O-RAN). So far, however, the applicability of O-RAN in controlling and optimizing RAN functions has not been widely investigated. In this paper, we jointly optimize the flow-split distribution, congestion control and scheduling (JFCS) to enable an intelligent traffic steering application in O-RAN. Combining tools from network utility maximization and stochastic optimization, we introduce a multi-layer optimization framework that provides fast convergence, long-term utility-optimality and significant delay reduction compared to the state-of-the-art and baseline RAN approaches. Our main contributions are three-fold:  $i$ ) we propose the novel JFCS framework to efficiently and adaptively direct traffic to appropriate radio units;  $ii$ ) we develop low-complexity algorithms based on the reinforcement learning, inner approximation and bisection search methods to effectively solve the JFCS problem in different time scales; and  $iii$ ) the rigorous theoretical performance results are analyzed to show that there exists a scaling factor to improve the tradeoff between delay and utility-optimization. Collectively, the insights in this work will open the door towards fully automated networks with enhanced control and flexibility. Numerical results are provided to demonstrate the effectiveness of the proposed algorithms in terms of the convergence rate, long-term utility-optimality and delay reduction.","1558-0008","","10.1109/JSAC.2023.3336183","VinUniversity Seed Grant Program; European Research Council (ERC) AGNOSTIC Project(grant numbers:EC/H2020/ERCAdG/742648/AGNOSTIC); Australian Research Council under the Discovery Early Career Researcher Award (DECRA) Project(grant numbers:DE210100651); Research Council of Finland under 6G Flagship(grant numbers:346208); Infotech Oulu; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10330565","Open radio access network;intelligent resource management;traffic steering;reinforcement learning;resource sharing","Optimization;Computer architecture;Resource management;Delays;6G mobile communication;Radio access networks;Microprocessors","","12","","49","IEEE","28 Nov 2023","","","IEEE","IEEE Journals"
"Low-Cost Green Computing-as-a-Service Testbed for SMEs: Leveraging AI and 6G for Enhanced Productivity","M. N. Patwary; S. Khan; S. J. Nawaz","Faculty of Science and Engineering, University of Wolverhampton, Wolverhampton, UK; School of Computing and Mathematical Sciences, University of Greenwich, London, UK; Department of Electrical & Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan","2024 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics","31 Oct 2024","2024","","","400","407","The exponential growth in computing devices and the emergence of high-computing-dependent applications have led to a significant increase in energy demand. In response, this paper proposes the development of a novel green computing testbed aimed at addressing energy efficiency and sustainability in computing infrastructure. The testbed integrates highly energy-efficient computing infrastructure, a virtual machine-driven on-demand computing ecosystem, and Green AI model development as a service. The state-of-the-art 5G/6G infrastructure and services, such as ultra-low-latency communications, are investigated and identified as suitable for connecting the zero clients (with minimal capabilities) to remote computing and other facilities. Through a comprehensive measurement campaign, the testbed’s energy efficiency and sustainability have been evaluated. This research presents a pioneering effort towards achieving sustainability in computing to support Small and Medium-sized Enterprises (SMEs) to enhance productivity with AI, with reduced cost, energy, and minimizing e-waste.","2836-3701","979-8-3503-5163-7","10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics62450.2024.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10731769","6G;AI;computing-as-a-Service;green computing;testbed","Productivity;6G mobile communication;Social computing;Costs;Green products;Graphics processing units;Green computing;Sustainable development;Artificial intelligence;Low latency communication","","","","22","IEEE","31 Oct 2024","","","IEEE","IEEE Conferences"
"AI-Driven Integration of Sensing and Communication in the 6G Era","X. Liu; H. Zhang; K. Sun; K. Long; G. K. Karagiannidis","Beijing Engineering and Technology Research Center for Convergence Networks and Ubiquitous Services, University of Science and Technology Beijing, Beijing, China; Beijing Engineering and Technology Research Center for Convergence Networks and Ubiquitous Services, University of Science and Technology Beijing, Beijing, China; College of Electronic Information Engineering, Inner Mongolia University, Hohhot, China; Beijing Engineering and Technology Research Center for Convergence Networks and Ubiquitous Services, University of Science and Technology Beijing, Beijing, China; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece",IEEE Network,"30 May 2024","2024","38","3","210","217","Attributing to the rapid growth of AI, the integration of sensing and communication (ISAC) networks has embraced AI in the upcoming new-style mobile communication networks. A FedFog network architecture for ISAC networks is proposed in this article, which consists of the terminal perception layer, the edge base station processing layer, and the cloud data layer. In the context of multiple base stations (BSs), the handover between BSs and user equipment is worthy to be studied. Referring to the concept of coordinated multiples BSs, we design a handover procedures in the ISAC networks. Meanwhile, a federated reinforcement learning scheme of user control is designed. However, due to new unlicensed spectrum bands such as millimeter wave band and Terahertz band, the hybrid beamforming can reduce the expenses of hardware. A learning-based interference management utilizing the hybrid beamforming is designed. Meanwhile, we consider self-interference and mutual interference cancellation with deep neural networks. Simulation results show the performance of AI-driven ISAC networks in terms of mobility and interference management, and further prove that services are boosted for 6G networks.","1558-156X","","10.1109/MNET.2023.3326064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291004","","Sensors;Handover;6G mobile communication;Network architecture;Federated learning;Base stations;Array signal processing;Artificial intelligence;Communication systems","","1","","15","IEEE","23 Oct 2023","","","IEEE","IEEE Magazines"
"Joint Optimization Algorithm of Training Delay and Energy Efficiency for Wireless Large-Scale Distributed Machine Learning Combined With Blockchain for 6G Networks","X. Zhang; X. Zhu","College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China",IEEE Internet of Things Journal,"24 Sep 2024","2024","11","19","31602","31618","In 6G, the communication cost of large-scale distributed machine learning (DML) will be much higher than the computing cost, which will become a bottleneck restricting the development of DML. To solve this problem, a wireless large-scale DML architecture combined with blockchain (WLDMLB) for 6G networks is proposed, where the distributed nodes involved in DML are divided into shards and a layered adaptive cascaded architecture is used in each shard to reduce the communication overhead. To reduce the system energy, improve training efficiency and achieve on-demand networking, a joint optimization model of the number of shards, network topology, and allocation of computing resources is established to ensure that the model can run efficiently on different devices. Then, a closed-form expression of one-round training delay and energy is derived. The optimal number of shards, the optimal network topology and the optimal computing resource allocation are further analysed. In addition, a main-shards blockchain architecture with the directed acyclic graph (DAG) and practical Byzantine fault tolerance (PBFT) consensus is proposed to ensure the trusted sharing of model and ensure system scalability. Simulation results show that the algorithm can greatly reduce the communication overhead, one round-training delay and energy of DML.","2327-4662","","10.1109/JIOT.2024.3418463","Natural Science Foundation of China(grant numbers:92367102); Key Research and Development Plan of Jiangsu Province(grant numbers:BE2021013-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570346","6G;blockchain;directed acyclic graph (DAG);distributed machine learning (DML);practical Byzantine fault tolerance (PBFT);wireless largescale DML architecture combined with blockchain (WLDMLB)","Training;Blockchains;Computational modeling;6G mobile communication;Delays;Servers;Network topology","","","","30","IEEE","24 Jun 2024","","","IEEE","IEEE Journals"
"Advancing Mobility Enhanced Edge Intelligence for 6G Networks","M. K. Vanteru","Department of ECE, Balaji Institute of Technology and Science, Warangal, Telangana",2024 IEEE International Conference on Big Data & Machine Learning (ICBDML),"2 Jul 2024","2024","","","44","49","Edge intelligence emerges as a novel paradigm facilitating real-time training and inference at the wireless edge, empowering critical applications. This necessitates the dense deployment of base stations (BSs) and edge servers (ESs), leading to significant deployment and operational expenses, particularly in energy consumption. Presenting a groundbreaking framework, Mobility-Enhanced Edge Intelligence (MEET), leverages the sensing, communication, computing, and self-powering capabilities of intelligent connected vehicles to optimize 6G networks for intelligence and sustainability. Operators can integrate infrastructural vehicles as mobile BSs or ESs, strategically scheduling them to align with communication and computation traffic fluctuations. Additionally, idle compute resources of opportunistic vehicles are harnessed for edge training and inference, utilizing mobility to augment edge intelligence through increased compute resources, communication opportunities, and diverse data. This innovative approach efficiently distributes deployment and operational costs across a multitude of vehicles, ensuring cost-effective and sustainable realization of edge intelligence. Moreover, these vehicles can be powered by renewable energy, mitigating carbon emissions, or charged during off-peak hours for flexibility in electricity consumption.","","979-8-3503-7410-0","10.1109/ICBDML60909.2024.10577395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10577395","Mobility-Enhanced Edge Intelligence;6G Networks;Edge Servers;Base Stations;Sustainable Deployment;Energy Consumption;Edge Training;Opportunistic Vehicles;Renewable Energy;Green Communication","Training;6G mobile communication;Base stations;Wireless sensor networks;Wireless networks;Sensors;Telecommunication computing","","","","17","IEEE","2 Jul 2024","","","IEEE","IEEE Conferences"
"Energy-Efficient Communication Protocols for 6G Wireless Sensor Network","K. L. Ranganayagi; S. P. Kumar; D. Lingaraja; T. Aravind; S. Ramya; G. D. Ram","Department of Electronics and Communication Engineering, Saveetha Engineering College, Chennai, India; Department of Electronics and Communication Engineering, Saveetha Engineering College, Chennai, India; Department of Electronics and Communication Engineering, Saveetha Engineering College, Chennai, India; Department of Electronics and Communication Engineering, Saveetha Engineering College, Chennai, India; Department of Electronics and Communication Engineering, Saveetha Engineering College, Chennai, India; Department of Electronics and Communication Engineering, Saveetha Engineering College, Chennai, India",2024 2nd International Conference on Networking and Communications (ICNWC),"28 May 2024","2024","","","1","6","As wireless communication evolves towards 6G, energy-efficient methods are essential for wireless sensor networks (WSNs). The research discusses the limitations of existing systems, which frequently lack optimization for 6G technologies. Inefficiencies in these systems include suboptimal energy consumption, higher latency, and reduced reliability. In response, a novel communication protocol suited for 6G-enabled WSNs is proposed in the study. The system integrates adaptive duty cycling, context-aware routing, and machine learning, considerably boosting energy efficiency, lowering latency, and increasing overall reliability. The simulation results obtained from NS-3 indicate the superiority of proposed protocol. The average energy consumption is reduced from 173 to 108 units/joule, the average latency is reduced from 37 to 21.7 milliseconds, and the average reliability is increased from 85% to 90.3%. The results highlight the feasibility of the proposed system for practical application, providing a promising solution for energy-efficient communication in the 6G era.","","979-8-3503-6526-9","10.1109/ICNWC60771.2024.10537356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537356","Energy-Efficient Communication;6G;Wireless Sensor Networks;Communication Protocols;Machine Learning;Network Performance Optimization","6G mobile communication;Wireless communication;Wireless sensor networks;Energy consumption;Protocols;Simulation;Energy efficiency","","","","18","IEEE","28 May 2024","","","IEEE","IEEE Conferences"
"Proximal Policy Optimization for RIS-Assisted Full Duplex 6G-V2X Communications","P. Saikia; S. Pala; K. Singh; S. K. Singh; W. -J. Huang","Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan",IEEE Transactions on Intelligent Vehicles,"25 Sep 2024","2024","9","7","5134","5149","In this work, we consider a novel reconfigurable intelligent surface (RIS)-assisted full-duplex (FD) sixth generation (6G)-vehicle-to-everything (V2X) communication network having a FD base station (BS) simultaneously communicating with an uplink (UL) and a downlink (DL) mobile vehicles with the aid of two RISs, one for each link. We provide an analytical framework to investigate the performance of this network and, consequently, formulate an optimization problem to jointly optimize the phase shift matrices at both the RISs that maximize the achievable sum-rate. Thereafter, due to the non-convex nature of the problem, we propose a low complexity proximal policy optimization (PPO)-based deep reinforcement learning (DRL) algorithm that solves the problem in continuous action spaces by reducing the overall training overhead and provides optimum values of phase-shift matrix at each RIS. Further, we extend the analysis considering multiple transmit and receive antennas at the BS that simultaneously serves multiple UL and DL vehicles. We present exhaustive simulations-based graphical results to validate the effectiveness and accuracy of the proposed algorithm compared to deep deterministic policy gradient (DDPG) and successive refinement (SR)-based solutions. Accordingly, we demonstrate the dominance of the considered FD system over its half-duplex (HD) counterpart. We also discuss the impact of the number of elements at each RIS, each vehicle's velocity and their distance from the RIS and the BS on the performance of the respective links. Moreover, we also highlight the impact of imperfect self-interference cancellation and discuss the trade-off between the UL and DL performances due to this imperfection.","2379-8904","","10.1109/TIV.2023.3275632","Qualcomm; Taiwan University Research Collaboration Project; National Science and Technology Council(grant numbers:NSTC 111-3114-E-110-001,NSTC-111-2221-E-110-029-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123981","Full duplex (FD);reconfigurable intelligent surface (RIS);self interference (SI);6G-vehicle-to-everything (V2X);deep reinforcement learning (DRL)","Optimization;6G mobile communication;Wireless communication;Training;Resource management;Interference cancellation;Uplink","","23","","50","IEEE","12 May 2023","","","IEEE","IEEE Journals"
"Traffic Control in 6G-Mobile Internet of Things Using Recurrent Neural Networks and Fuzzy Logic","S. S. Sefati; A. M. Nor; O. Fratu; S. Halunga","Telecommunications Department, National University for Science and Technology POLITEHNICA Bucharest, Bucharest, Romania; Telecommunications Department, National University for Science and Technology POLITEHNICA Bucharest, Bucharest, Romania; Telecommunications Department, National University for Science and Technology POLITEHNICA Bucharest, Bucharest, Romania; Telecommunications Department, National University for Science and Technology POLITEHNICA Bucharest, Bucharest, Romania",2024 10th International Conference on Smart Computing and Communication (ICSCC),"1 Oct 2024","2024","","","519","523","The Mobile Internet of Things (MIoT) refers to a network of interconnected, internet-enabled devices that can communicate and share data together through mobile and wireless networks. This paper presents a novel framework for congestion management in MIoT networks by integrating Long Short-Term Memory (LSTM) networks with fuzzy logic to enhance predictive and adaptive decision-making capabilities for 6G networks. With the proliferation of MIoT devices, network congestion is becoming increasingly problematic, necessitating advanced solutions to maintain efficient data flow and network stability. The approach begins with systematic data collection, capturing essential traffic metrics. This data undergoes to a preprocessing step to facilitate Long Short-Term Memory (LSTM) analysis, focusing on normalization and time-series structuring. The LSTM models are trained to accurately predict traffic patterns, employing strategies such as regularization and dropout to prevent overfitting and enhance model reliability. Subsequently, a fuzzy logic system interprets these predictions, applying a set of linguistic rules to refine the forecasts further. This methodology enables dynamic, proactive management of network congestion, and improves data transmission efficiency and network resource optimization.","","979-8-3503-6310-4","10.1109/ICSCC62041.2024.10690801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690801","Congestion Management;LSTM;Fuzzy Logic;Network Traffic Management;Mobile Internet of Things","Fuzzy logic;6G mobile communication;Wireless networks;Traffic control;Predictive models;Stability analysis;Internet of Things;Reliability;Long short term memory;Optimization","","","","13","IEEE","1 Oct 2024","","","IEEE","IEEE Conferences"
"6G on the Horizon:Technologies, Requirements, Trends, and Potential Techniques","N. A. M. Yunus; Z. M. Hanapi; S. Kamarudin","Dept. of Communication Technology and Network, Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Selangor, Malaysia; Dept. of Communication Technology and Network, Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Selangor, Malaysia; Dept. of Communication Technology and Network, Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Selangor, Malaysia","2024 International Conference on Electrical, Computer and Energy Technologies (ICECET","8 Oct 2024","2024","","","1","6","The advance of sixth generation (6G) wireless communication technology represents a paradigm shift in the field of telecommunications, promising unprecedented levels of connectivity, speed, and reliability. This review delves into the fundamental requirements driving the development of $6\mathrm{G}$, highlighting the need for ultra-reliable and low latency. By examining cutting-edge technologies such as terahertz communication, massive Multiple-Input Multiple-Output (MIMO), and Artificial Intelligence (AI) driven network optimization, this paper identifies key trends shaping the future of wireless communication networks. Moreover, it explores potential innovations including holographic communication, self-organizing networks, and quantum communication that have the potential to redefine the capabilities of $6\mathrm{G}$ networks and unlock new opportunities for connectivity and collaboration.","","979-8-3503-9591-4","10.1109/ICECET61485.2024.10698610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698610","6G technologies;requirements;trends;potential techniques","6G mobile communication;Industries;Technological innovation;Computer network reliability;UHF antennas;Market research;Telecommunication network reliability;Low latency communication;Artificial intelligence;Quantum communication","","","","29","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"Self-supervised Contrastive Learning for 6G UM-MIMO THz Communications: Improving Robustness Under Imperfect CSI","R. U. Murshed; M. S. Ullah; M. Saquib; M. Z. Win","Department of Electrical and Computer Engineering, The University of Texas, Dallas, Texas, USA; Department of Electrical and Computer Engineering, University of Delaware, Delaware, USA; Department of Electrical and Computer Engineering, The University of Texas, Dallas, Texas, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Massachusetts, USA",2024 IEEE International Conference on Communications Workshops (ICC Workshops),"12 Aug 2024","2024","","","220","226","This paper investigates the potential of contrastive learning in 6G ultra-massive multiple-input multiple-output (UM-MIMO) communication systems, specifically focusing on hybrid beamforming under imperfect channel state information (CSI) conditions at THz. UM-MIMO systems are promising for future 6G wireless communication networks due to their high spectral efficiency and capacity. The accuracy of CSI significantly influences the performance of UM-MIMO systems. However, acquiring perfect CSI is challenging due to various practical constraints such as channel estimation errors, feedback delays, and hardware imperfections. To address this issue, we propose a novel self-supervised contrastive learning-based approach for hybrid beamforming, which is robust against imperfect CSI. We demonstrate the power of contrastive learning to tackle the challenges posed by imperfect CSI and show that our proposed method results in improved system performance in terms of achievable rate compared to traditional methods.","2694-2941","979-8-3503-0405-3","10.1109/ICCWorkshops59551.2024.10615313","National Science Foundation(grant numbers:CNS-2148251); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615313","Contrastive Learning;Hybrid Beamforming;Imperfect CSI;NYUSIM;Rain Fade;THz;UM-MIMO;6G","6G mobile communication;Wireless communication;Array signal processing;Heuristic algorithms;Conferences;System performance;Contrastive learning","","1","","20","IEEE","12 Aug 2024","","","IEEE","IEEE Conferences"
"Next-Generation 6G Networks: Deploying Cybertwin Technology for Enhanced Healthcare Solutions","A. Kaliwo; C. Nyirenda","Department of Computer Science, University of the Western Cape, Cape Town, South Africa; Department of Computer Science, University of the Western Cape, Cape Town, South Africa","2024 International Conference on Electrical, Computer and Energy Technologies (ICECET","8 Oct 2024","2024","","","1","6","This paper explores the integration of Cybertwin technology within 6G networks to revolutionize healthcare delivery. It aims to enhance real-time monitoring, decision-making, and resource management through the Service-based Hierarchical Framework for Cybertwins in sixth-generation networks. The paper addresses the deployment challenges and proposes system theory as a comprehensive framework for designing complex interactions among healthcare-assigned Cybertwins. The article highlights the role of Cybertwin technology in advancing healthcare solutions, promising improved patient care and operational efficiency. It examines the current network setups and the potential of 6G infrastructure, discussing network topology optimization, theoretical modelling, and future directions. The paper underlines the transformative impact of combining 6G and Cybertwin technologies on healthcare, from high-definition telemedicine to large-scale patient monitoring. The paper further acknowledges the implementation challenges, such as technical complexity, security, and interoperability.","","979-8-3503-9591-4","10.1109/ICECET61485.2024.10698054","University of the Western Cape; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698054","6G;Cybertwin;healthcare;service-based;hierarchical","6G mobile communication;Patient monitoring;Network topology;Telemedicine;Medical services;Real-time systems;Resource management;Optimization;Next generation networking;Interoperability","","","","19","IEEE","8 Oct 2024","","","IEEE","IEEE Conferences"
"ROBUST-6G: Smart, Automated, and Reliable Security Service Platform for 6G","B. Siniarski; C. Sandeepa; S. Wang; M. Liyanage; C. Ayyildiz; V. C. Yildirim; H. Alakoca; F. G. Kesik; B. G. Paltun; G. Perin; M. Rossi; S. Tomasin; A. Chorti; P. G. Giardina; A. G. Pércz; J. M. Jorquera Valero; T. Svensson; N. Pappas; M. Kountouris","University College, Dublin, Ireland; University College, Dublin, Ireland; University College, Dublin, Ireland; University College, Dublin, Ireland; GOHM, Muğla, Turkey; GOHM, Muğla, Turkey; Ericsson Research, Turkey; Ericsson Research, Turkey; Ericsson Research, Turkey; University of Padova, Italy; University of Padova, Italy; University of Padova, Italy; ENSEA, CNRS, France; Nextworks, Italy; University of Murcia, Spain; University of Murcia, Spain; Chalmers University of Technology, Sweden; Linkoping University, Sweden; EURECOM, France",2024 Fifteenth International Conference on Ubiquitous and Future Networks (ICUFN),"20 Aug 2024","2024","","","384","389","In the progressive development towards 6G, the ROBUST-6G initiative aims to provide fundamental contributions to developing data-driven, AIIML-based security solutions to meet the new concerns posed by the dynamic nature of forth-coming 6G services and networks in the future cyber-physical continuum. This aim has to be accompanied by the transversal objective of protecting AIIML systems from security attacks and ensuring the privacy of individuals whose data are used in AI-empowered systems. ROBUST-6G will essentially investigate the security and robustness of distributed intelligence, enhancing privacy and providing transparency by leveraging explainable AIIML (XAI). Another objective of ROBUST-6G is to promote green and sustainable AIIML methodologies to achieve energy efficiency in 6G network design. The vision of ROBUST-6G is to optimize the computation requirements and minimize the consumed energy while providing the necessary performance for AIIML-driven security functionalities; this will enable sustainable solutions across society while suppressing any adverse effects. This paper aims to initiate the discussion and to highlight the key goals and milestones of ROBUST-6G, which are important for investigation towards a trustworthy and secure vision for future 6G networks.","2165-8536","979-8-3503-8529-8","10.1109/ICUFN61752.2024.10624832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10624832","","6G mobile communication;Privacy;Automation;Systematics;Security management;Robustness;Security","","","","11","IEEE","20 Aug 2024","","","IEEE","IEEE Conferences"
"Satellite-Based ITS Data Offloading & Computation in 6G Networks: A Cooperative Multi-Agent Proximal Policy Optimization DRL With Attention Approach","S. S. Hassan; Y. M. Park; Y. K. Tun; W. Saad; Z. Han; C. S. Hong","Department of Computer Science and Engineering, Kyung Hee University, Yongin, Gyeonggi-do, Republic of Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin, Gyeonggi-do, Republic of Korea; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Computer Science and Engineering, Kyung Hee University, Yongin, Gyeonggi-do, Republic of Korea",IEEE Transactions on Mobile Computing,"4 Apr 2024","2024","23","5","4956","4974","The proliferation of intelligent transportation systems (ITS) has led to increasing demand for diverse network applications. However, conventional terrestrial access networks (TANs) are inadequate in accommodating various applications for remote ITS nodes, i.e., airplanes and ships. In contrast, satellite access networks (SANs) offer supplementary support for TANs, in terms of coverage flexibility and availability. In this study, we propose a novel approach to ITS data offloading and computation services based on SANs. We use low-Earth orbit (LEO) and cube satellites (CubeSats) as independent mobile edge computing (MEC) servers that schedule the processing of data generated by ITS nodes. To optimize offloading task selection, computing, and bandwidth resource allocation for different satellite servers, we formulate a joint delay and rental price minimization problem that is mixed-integer non-linear programming (MINLP) and NP-hard. We propose a cooperative multi-agent proximal policy optimization (Co-MAPPO) deep reinforcement learning (DRL) approach with an attention mechanism to deal with intelligent offloading decisions. We also decompose the remaining subproblem into three independent subproblems for resource allocation and use convex optimization techniques to obtain their optimal closed-form analytical solutions. We conduct extensive simulations and compare our proposed approach to baselines, resulting in performance improvements of 9.9%, 5.2%, and 4.2%, respectively.","1558-0660","","10.1109/TMC.2023.3300314","National Research Foundation of Korea(grant numbers:RS-2023-00207816); Institute of Information and Communications Technology Planning and Evaluation(grant numbers:2021-0-02068,RS-2022-00155911); Kyung Hee University(grant numbers:2019-0-01287); Evolvable Deep Learning Model Generation Platform for Edge Computing; Ministry of Science and ICT, South Korea(grant numbers:IITP-2023-RS-2023-00258649); IITP; National Science Foundation(grant numbers:CNS-2107216,CNS-2128368,CMMI-2222810,ECCS-2302469); U.S. Department of Transportation; Toyota Motor Corporation; Amazon; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10198334","Satellite access networks;intelligent transportation systems;mobile edge computing;cooperative multi-agent proximal policy optimization;attention mechanism;deep reinforcement learning","Resource management;Task analysis;Satellite broadcasting;Servers;Satellites;Optimization;Low earth orbit satellites","","17","","61","IEEE","1 Aug 2023","","","IEEE","IEEE Journals"
"Knowledge-Collaboration-Based Resource Allocation in 6G IoT: A Graph Attention RL Approach","Z. Huang; F. R. Yu; J. Cai","School of Computer Science and Engineering, Macau University of Science and Technology, Macau, China; School of Information Technology, Carleton University, Ottawa, ON, Canada; School of Cyber Security, Guangdong Polytechnic Normal University, Guangzhou, China",IEEE Internet of Things Journal,"7 Nov 2024","2024","11","22","36581","36595","In future 6G-enabled Internet of Things (IoT), users and devices will be divided into numerous distributed domains with smaller base station coverage due to the utilization of terahertz high-frequency band communication. Deep reinforcement learning (DRL) agents will be increasingly deployed in the domain to achieve intelligent service provisioning and resource allocation. However, the existing DRL-based method faces the problem of repeated model training and poor generalization ability when service demand fluctuates and environmental changes occur. In addition, limited training samples in each domain also lead to insufficient model training. Inspired by the collaborative learning of human knowledge, we propose a knowledge collaboration-based resource allocation mechanism for future 6G-enabled IoT and address two basic issues: 1) which agent should collaborate with and 2) how to collaborate. Specifically, we first model the distributed network as a graph and use graph attention (GAT) to capture the fluctuant service demands and time-varying resource capacities in temporal and spatial domains, and then calculate the similarity between the agents. We further propose a collective reinforcement learning (CRL) algorithm that facilitates knowledge collaboration between the agents through the policy distribution. Simulation results verify that the proposed GAT-CRL achieves fast convergence as deep deterministic policy gradient (DDPG) in 4K steps, computing the similarity score more accurately with the increasing attention heads, and achieves higher successful flow than the soft actor-critic (about 3.6%–5.4%) and DDPG (about 14.6%–21%) when adapting to unseen traffic patterns/loads and increasing topology scales.","2327-4662","","10.1109/JIOT.2024.3416054","National Natural Science Foundation of China(grant numbers:61902080,61972104,62002072,61702120); National Key Research and Development Program of China(grant numbers:2019YFB1804403,2018YFB1802200); Special Projects in Key Areas of Guangdong Province(grant numbers:2019B010118001); Science and Technology Project in Guangzhou(grant numbers:201803010081); Foshan Science and Technology Innovation Project, China(grant numbers:2018IT100283); Guangzhou Key Laboratory(grant numbers:202102100006); Science and Technology Program of Guangzhou, China(grant numbers:202002020035); Research Projects in Guangdong Province(grant numbers:2021ZDJS026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10560516","Collective reinforcement learning (CRL);graph attention (GAT);knowledge collaboration;resource allocation","Training;Collaboration;6G mobile communication;Resource management;Heuristic algorithms;Servers;Computational modeling","","","","50","IEEE","18 Jun 2024","","","IEEE","IEEE Journals"
"Fair Communication Resource Scheduling in 6G and Digital Twin-Driven Virtual Power Plants","X. Liu; P. Yu; H. Fang; C. Tan; F. Zhou; W. Li","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China",2024 IEEE/CIC International Conference on Communications in China (ICCC Workshops),"4 Oct 2024","2024","","","271","276","A virtual power plant (VPP) is a technology and management system that integrates distributed energy resources, offering significant advantages for the access and management of these distributed energy resources. With the development of distributed energy, higher requirements are being placed on the communication resource scheduling capabilities of virtual power plants. For dense source-load-storage devices, the high bandwidth, low latency, and high energy efficiency characteristics of 6G networks can meet the control requirements of virtual power plants for these devices. Digital twins are currently widely used in the industrial sector, providing positive effects such as real-time monitoring, prediction, and performance optimization. Applying digital twins to the communication resource scheduling of virtual power plants enables real-time perception of resource allocation and timely resource scheduling. This paper proposes a communication resource scheduling algorithm based on deep reinforcement learning, leveraging digital twin technology and the 6G distributed subnet architecture. This algorithm aims to efficiently utilize limited resources such as resource blocks, spectrum, and power to balance system throughput, fairness, and scheduling latency, thereby ensuring the QoS of source-load-storage device scheduling tasks. Simulation results demonstrate that the proposed resource scheduling algorithm enhances system throughput and fairness while meeting scheduling latency requirements, thereby satisfying the QoS needs of scheduling tasks.","2474-9141","979-8-3503-7767-5","10.1109/ICCCWorkshops62562.2024.10693737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10693737","virtual power plants;Digital Twin;channel resource scheduling;power allocation;6G;deep reinforcement learning","6G mobile communication;Job shop scheduling;Scheduling algorithms;Computational modeling;Quality of service;Virtual power plants;Throughput;Real-time systems;Digital twins;Resource management","","","","17","IEEE","4 Oct 2024","","","IEEE","IEEE Conferences"
